<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Michael Stapelbergs Website</title>
  <link href="https://michael.stapelberg.ch/feed.xml" rel="self"/>
  <link href="https://michael.stapelberg.ch/"/>

    <updated>2020-10-01T08:22:49+02:00</updated>
    
  <id>https://michael.stapelberg.ch/</id>
  <generator>Hugo -- gohugo.io</generator>
  <entry>
    <title type="html"><![CDATA[Nuki Opener with an SCS bus intercom (bTicino 344212)]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-09-28-nuki-scs-bticino-decoding/"/>
    <id>https://michael.stapelberg.ch/posts/2020-09-28-nuki-scs-bticino-decoding/</id>
    <published>2020-09-28T08:43:00+02:00</published>
    <updated>2020-10-01T08:22:49+02:00</updated>
    <content type="html"><![CDATA[

<p>I have long been looking for a way to make my intercom a little more pleasant.</p>

<p>Recently, a friend made me aware of the <a href="https://nuki.io/opener">Nuki Opener</a>,
which promises to make existing intercom systems smart, and claims to be
compatible with the specific intercom I have!</p>

<p>So I got one and tried setting it up, but could not get it to work.</p>

<p>This post documents how I have analyzed what goes over the intercom’s <a href="https://en.wikipedia.org/wiki/Bus_SCS">SCS
bus</a>. Perhaps the technique is
interesting, or perhaps you want to learn more about SCS :)</p>

<p>Note that I have <strong>not yet used</strong> the Nuki Opener, so I can’t say anything about
it yet. What I have seen so far makes a good impression, but it just does not
seem to work at all with my intercom. I will update this article after working
with the Nuki support to fix this.</p>

<h2 id="connecting-the-nuki-opener-to-the-bticino-344212">Connecting the Nuki Opener to the bTicino 344212</h2>

<p>First, I identified which wires are used for the bus: between BUS- and BUS+, the
internet tells me that I would expect to measure ≈27V, and indeed a multimeter
shows:</p>

<p><a href="../../Bilder/2020-09-27-bticino-multimeter.jpg"><img src="../../Bilder/2020-09-27-bticino-multimeter.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-bticino-multimeter.thumb.2x.jpg 2x,../../Bilder/2020-09-27-bticino-multimeter.thumb.3x.jpg 3x" width="200" height="264" alt="bTicino wiring" style="border: 1px solid #000" loading="lazy"></a></p>

<p>I then connected the Nuki Opener as described in <a href="https://developer.nuki.io/uploads/short-url/3naDfQDFbzh3Je7ytrNzRDscvFz.pdf">“Connect the Nuki Opener to an
unknown
intercom”</a>,
Page 8, Bus intercoms → Basic setup without doorbell suppression:</p>

<table>
<thead>
<tr>
<th>Nuki wire</th>
<th>Intercom</th>
<th>Signal</th>
</tr>
</thead>

<tbody>
<tr>
<td>black</td>
<td>BUS-</td>
<td>GND</td>
</tr>

<tr>
<td>red</td>
<td>BUS+</td>
<td>SCS (+27V)</td>
</tr>

<tr>
<td>orange</td>
<td>BUS+</td>
<td>SCS (+27V)</td>
</tr>
</tbody>
</table>

<p><a href="../../Bilder/2020-09-27-bticino-wiring.jpg"><img src="../../Bilder/2020-09-27-bticino-wiring.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-bticino-wiring.thumb.2x.jpg 2x,../../Bilder/2020-09-27-bticino-wiring.thumb.3x.jpg 3x" width="200" height="264" alt="bTicino wiring" style="border: 1px solid #000" loading="lazy"></a></p>

<p>I had previously tried the enhanced setup with doorbell suppression, as the Nuki
app recommends, but switched to the <strong>simplest setup possible</strong> when capturing
the signal.</p>

<h2 id="configuring-the-nuki-opener">Configuring the Nuki Opener</h2>

<p>With the Nuki app, I configured the Opener either as:</p>

<ul>
<li>bTicino → 344212</li>
<li>Generic → Bus (SCS)</li>
<li>Unknown intercom</li>
</ul>

<p>Unfortunately, with all configurations:</p>

<ol>
<li>The app says it learned the door open signal successfully.</li>
<li>The device/app does react to door rings.</li>
<li>The device <strong>never successfully opens the door</strong>.</li>
</ol>

<h2 id="capturing-the-scs-bus-with-sigrok">Capturing the SCS bus with sigrok</h2>

<p>The logic analyzer that I have at home only works with signals under 5V. As the
SCS bus is running at 27V, I’m capturing the signal with my <a href="https://www.aliexpress.com/popular/hantek-6022be.html">Hantek 6022BE USB
oscilloscope</a>.</p>

<p><a href="https://sigrok.org/">sigrok</a> is a portable, cross-platform, free open source
signal analysis software suite and <a href="https://sigrok.org/wiki/Hantek_6022BE">supports the Hantek
6022BE</a> out of the box, provided you have
at least version 0.1.4 of the the sigrok fx2lafw package installed.</p>

<p>Check out <a href="https://sigrok.org/wiki/Getting_started_with_a_logic_analyzer">sigrok’s “Getting started with a logic
analyzer”</a> if
you’re new to sigrok!</p>

<p>The Nuki Opener has 3 different pin headers you can use, depending on where you
want to attach it on your wall. These are connected straight through, so I used
them to conveniently grab BUS+ and BUS- just like the Nuki sees it:</p>

<p><a href="../../Bilder/2020-09-27-bticino-capture.jpg"><img src="../../Bilder/2020-09-27-bticino-capture.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-bticino-capture.thumb.2x.jpg 2x,../../Bilder/2020-09-27-bticino-capture.thumb.3x.jpg 3x" width="200" height="264" alt="bTicino capture" style="border: 1px solid #000" loading="lazy"></a></p>

<p>I set the oscilloscope probe head to its 10X divider setting, so that I had the
full value range available, then started sampling 5M samples at 500 kHz:</p>

<p><a href="../../Bilder/2020-09-27-scs-pulseview.jpg"><img src="../../Bilder/2020-09-27-scs-pulseview.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-scs-pulseview.thumb.2x.jpg 2x,../../Bilder/2020-09-27-scs-pulseview.thumb.3x.jpg 3x" width="600" height="260" alt="sigrok PulseView screenshot" style="border: 1px solid #000" loading="lazy"></a></p>

<p>You can see 10s worth of signal. The three bursts are transmissions on the SCS
bus.</p>

<p>The labeling didn’t quite match for me: it shows e.g. 3.2V instead of 27V, but
as long as the signal comes in clearly, it doesn’t matter if it is offset or
scaled.</p>

<h2 id="scs-bus-decoding-with-sigrok-voltage-levels">SCS bus decoding with sigrok: voltage levels</h2>

<p>Let’s tell sigrok what voltage level corresponds to a low or high signal:</p>

<ol>
<li>left-click on channel <code>CH1</code></li>
<li>set “conversion” to “to logic via threshold”</li>
<li>set “conversion threshold” to 3.0V</li>
</ol>

<p>Now you’ll see not only the captured signal, but also the logical signal below
in green:</p>

<p><a href="../../Bilder/2020-09-27-scs-pulseview-logic.jpg"><img src="../../Bilder/2020-09-27-scs-pulseview-logic.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-scs-pulseview-logic.thumb.2x.jpg 2x,../../Bilder/2020-09-27-scs-pulseview-logic.thumb.3x.jpg 3x" width="600" height="228" alt="sigrok PulseView screenshot" style="border: 1px solid #000" loading="lazy"></a></p>

<h2 id="scs-bus-decoding-with-sigrok-scs-decoder">SCS bus decoding with sigrok: SCS decoder</h2>

<p>Now that we have obtained a logical/digital signal (low/high), we can write a
sigrok decoder for the SCS bus. See <a href="https://sigrok.org/wiki/Protocol_decoder_HOWTO">sigrok’s Protocol decoder
HOWTO</a> for an introduction.</p>

<p>In general, I strongly recommend investing into tooling, in particular when
decoding protocols. Spending a few minutes to an hour at this stage will
minimize mistakes and save lots of time later, and—when you contribute your
tooling—enable others to do more interesting work!</p>

<p>I found it easy to write a sigrok decoder, having never used their API
before. It was quick to get something onto the screen, mistakes were easy to
correct, and the whole process was nicely iterative.</p>

<p>Until it is merged and released with a new version of <code>libsigrokdecode</code>, you can
find <a href="https://github.com/stapelberg/libsigrokdecode/commit/7f12be634628d52222eb879f5b076c256ab8ba08">my SCS decoder on
GitHub</a>.</p>

<p>The decoder looks at every layer of an SCS telegram: the start/stop bits, the
data bits, the value and the value’s logical position/function in the SCS
telegram.</p>

<p><a href="../../Bilder/2020-09-28-pulseview-scs-full.jpg"><img src="../../Bilder/2020-09-28-pulseview-scs-full.thumb.1x.jpg" srcset="../../Bilder/2020-09-28-pulseview-scs-full.thumb.2x.jpg 2x,../../Bilder/2020-09-28-pulseview-scs-full.thumb.3x.jpg 3x" width="600" height="173" alt="SCS full" style="border: 1px solid #000" loading="lazy"></a></p>

<p>Our SCS decoder displays the 3 bursts on the SCS bus when we ring the doorbell:</p>

<p><a href="../../Bilder/2020-09-27-anlern-klingel-burst1.jpg"><img src="../../Bilder/2020-09-27-anlern-klingel-burst1.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-anlern-klingel-burst1.thumb.2x.jpg 2x,../../Bilder/2020-09-27-anlern-klingel-burst1.thumb.3x.jpg 3x" width="600" height="90" alt="SCS bus door ring" style="border: 1px solid #000" loading="lazy"></a></p>

<p><a href="../../Bilder/2020-09-27-anlern-klingel-burst2.jpg"><img src="../../Bilder/2020-09-27-anlern-klingel-burst2.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-anlern-klingel-burst2.thumb.2x.jpg 2x,../../Bilder/2020-09-27-anlern-klingel-burst2.thumb.3x.jpg 3x" width="600" height="90" alt="SCS bus door ring" style="border: 1px solid #000" loading="lazy"></a></p>

<p><a href="../../Bilder/2020-09-27-anlern-klingel-burst3.jpg"><img src="../../Bilder/2020-09-27-anlern-klingel-burst3.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-anlern-klingel-burst3.thumb.2x.jpg 2x,../../Bilder/2020-09-27-anlern-klingel-burst3.thumb.3x.jpg 3x" width="600" height="90" alt="SCS bus door ring" style="border: 1px solid #000" loading="lazy"></a></p>

<p>Only the middle burst sets a destination address of <code>0x3</code>, the configured number
of my intercom system. I am not sure what the first and last burst indicate!</p>

<p>The SCS bus activity when opening the door seems more clear:</p>

<p><a href="../../Bilder/2020-09-27-anlern-open-burst1.jpg"><img src="../../Bilder/2020-09-27-anlern-open-burst1.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-anlern-open-burst1.thumb.2x.jpg 2x,../../Bilder/2020-09-27-anlern-open-burst1.thumb.3x.jpg 3x" width="600" height="90" alt="SCS bus door ring" style="border: 1px solid #000" loading="lazy"></a></p>

<p><a href="../../Bilder/2020-09-27-anlern-open-burst2.jpg"><img src="../../Bilder/2020-09-27-anlern-open-burst2.thumb.1x.jpg" srcset="../../Bilder/2020-09-27-anlern-open-burst2.thumb.2x.jpg 2x,../../Bilder/2020-09-27-anlern-open-burst2.thumb.3x.jpg 3x" width="600" height="90" alt="SCS bus door ring" style="border: 1px solid #000" loading="lazy"></a></p>

<p>These 2 bursts are sent one second apart, and only differ in the request
parameter field: my guess is that <code>0xa4</code> means “start buzzing the door open” and
<code>0xa0</code> means “stop buzzing the door open”.</p>

<p>I’m not sure why all these bursts repeat their SCS telegrams 3 times. My
understanding was that SCS telegrams are repeated only when they are not
acknowledged, and I indeed see no acknowledgement telegrams in my captures. Does
that mean something is wrong with our intercom and it only works due to
retransmissions?</p>

<h2 id="scs-bus-decoding-with-sigrok-git-uart-scs-decoder">SCS bus decoding with sigrok git: UART+SCS decoder</h2>

<p>As <a href="https://sourceforge.net/p/sigrok/mailman/message/37118252/">Gerhard Sittig pointed
out</a>, in the git
version of libsigrokdecode, one can use the existing UART decoder to decode SCS:</p>

<ol>
<li>Set <code>Baud rate</code> to <code>9600</code></li>
<li>Set <code>Sample point</code> to <code>20%</code></li>
</ol>

<p>This seems a little more robust than my cobbled-together SCS decoder from above :)</p>

<p>In addition to the UART decoder, we can still use a custom SCS decoder to label
individual bytes within an SCS telegram according to their function, and do CRC
checks.</p>

<h2 id="captured-scs-telegrams">Captured SCS telegrams</h2>

<p>You can find my most recent captures in <a
href="../../2020-09-27-rohdaten-klingel-rev2.zip">2020-09-27-rohdaten-klingel-rev2.zip</a>:</p>

<ul>
<li><code>2020-09-27-anlern-01-open-PUR-filtered.srzip</code> is the door buzzer</li>
<li><code>2020-09-27-anlern-02-klingel-PUR-filtered.srzip</code> is the bell ringing</li>
</ul>

<p>To extract the interesting parts from the sigrok files, I:</p>

<ol>
<li>Click the <code>Show Cursors</code> icon in PulseView’s toolbar.</li>
<li>Position the left and right cursor edges such that the signal of interest is selected.</li>
<li>Click the drop-down next to the <code>Save</code> icon and select <code>Save Selected Range As</code>.</li>
</ol>

<h2 id="further-reading">Further reading</h2>

<p>I used the following sources; please let me know of any others!</p>

<ul>
<li><a href="https://it.wikipedia.org/wiki/Bus_SCS">https://it.wikipedia.org/wiki/Bus_SCS</a></li>
<li><a href="http://guidopic.altervista.org/alter/eibscsgt.html">http://guidopic.altervista.org/alter/eibscsgt.html</a></li>
<li><a href="https://www.mikrocontroller.net/topic/493823">https://www.mikrocontroller.net/topic/493823</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Adding a fiber link to my home network]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-08-09-fiber-link-home-network/"/>
    <id>https://michael.stapelberg.ch/posts/2020-08-09-fiber-link-home-network/</id>
    <published>2020-08-09T14:53:53+02:00</published>
    <updated>2020-08-28T07:47:54+02:00</updated>
    <content type="html"><![CDATA[

<h2 id="motivation">Motivation</h2>

<p>Despite using a FTTH internet connection since 2014, aside from the one fiber
uplink, I had always used network gear with 1 Gbit/s links over regular old rj45
cat5(e) cables.</p>

<hr />

<p>I liked the simplicity and uniformity of that setup, but decided it’s time to
add at least one fiber connection, to <strong>get rid of a temporary ethernet cable</strong>
that connected my kitchen with the rest of my network that is largely in the
living room and office.</p>

<p>The temporary ethernet cable was an experiment to verify that running a server
or two in my kitchen actually works (it does!). I used a <a href="https://www.digitec.ch/de/s1/product/hama-cat-6-flach-we-1000cm-netzwerkkabel-7465292">flat ethernet
cable</a>,
which is great for test setups like that, as you can often tape it onto the
walls and still close the doors.</p>

<p>So, we will replace one ethernet cable with one fiber cable and converters at
each end:</p>

<p><a href="../../Bilder/2020-08-04-media-converters.jpg"><img src="../../Bilder/2020-08-04-media-converters.thumb.1x.jpg" srcset="../../Bilder/2020-08-04-media-converters.thumb.2x.jpg 2x,../../Bilder/2020-08-04-media-converters.thumb.3x.jpg 3x" width="600" height="216" alt="0.9mm thin fiber cables" style="border: 1px solid #000" loading="lazy"></a></p>

<p>Why is it good to switch from copper ethernet cables to fiber in this case?
Fiber cables are <strong>smaller and hence easier to fit</strong> into existing cable
ducts. While regular ethernet cable is way too thick to fit into any of the
existing ducts in my flat, I was hoping that fiber might fit!</p>

<p>When I actually received the cables, I was surprised <strong>how much thinner</strong> fiber
cables actually can be: there are 0.9mm cables, which are so thin, they can be
hidden in plain sight! I had only ever seen 2mm fiber cables before, and the
0.9mm cables are incredibly light, flexible and thin! Even pasta is typically
thicker:</p>

<p><a href="../../Bilder/2020-08-04-glasnudeln.jpg"><img src="../../Bilder/2020-08-04-glasnudeln.thumb.jpg" srcset="../../Bilder/2020-08-04-glasnudeln.thumb.2x.jpg 2x,../../Bilder/2020-08-04-glasnudeln.thumb.3x.jpg 3x" width="600" height="450" alt="0.9mm thin fiber cables" style="border: 1px solid #000" loading="lazy"></a></p>

<p><small><em>Preparing a delicious pot of glass noodles ;)</em></small></p>

<hr />

<p>The cable shown above comes from <a href="https://www.FS.COM/company/about_us.html">the fiber store
FS.COM</a>, which different people have
praised on multiple occasions, so naturally I was curious to give them a shot
myself.</p>

<p>Also, for the longest time, it was my understanding that fiber connectors can
only be put onto fiber cables using expensive (≫2000 CHF) machines. A while ago
I heard about <strong>field assembly connectors</strong> so I wanted to verify that those
indeed work.</p>

<hr />

<p>Aside from practical reasons, playing around with fiber networking also makes
for a good hobby during a pandemic :)</p>

<h2 id="hardware-selection">Hardware Selection</h2>

<p>I ordered all my fiber equipment at <a href="https://www.FS.COM">FS.COM</a>: everything
they have is very affordable, and products in stock at their German warehouse
arrive in Switzerland (and presumably other European countries) within the same
week.</p>

<p>If you are in the luxurious position to have enough physical space and agility
to pull through an entire fiber cable, <strong>without having to remove any
connectors</strong>, you can make a new network connection with just a few parts:</p>

<table>
<thead>
<tr>
<th>amt</th>
<th>price</th>
<th>total</th>
<th>article</th>
<th>note</th>
</tr>
</thead>

<tbody>
<tr>
<td>2x</td>
<td>36 CHF</td>
<td>72 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/17237.html">#17237</a></td>
<td><a href="https://www.FS.COM/de-en/products/17237.html">1 Gbit/s media converter RJ45/SFP</a></td>
</tr>

<tr>
<td>1x</td>
<td>8.5 CHF</td>
<td>8.5 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/75339.html">#39135</a></td>
<td><a href="https://www.FS.COM/de-en/products/75339.html">1 Gbit/s BiDi SFP 1310nm-TX/1550nm-RX</a></td>
</tr>

<tr>
<td>1x</td>
<td>11 CHF</td>
<td>11 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/75340.html">#39138</a></td>
<td><a href="https://www.FS.COM/de-en/products/75340.html">1 Gbit/s BiDi SFP 1550nm-TX/1310nm-RX</a></td>
</tr>

<tr>
<td>1x</td>
<td>2.3 CHF</td>
<td>2.3 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/12285.html">#12285</a></td>
<td><a href="https://www.FS.COM/de-en/products/12285.html">fiber cable, 0.9mm LC UPC/LC UPC simplex</a></td>
</tr>
</tbody>
</table>

<p>I recommend buying an extra fiber cable or two so that you can accidentally
damage a cable and still have enough spares.</p>

<p>Total cost thus far: just under 100 CHF. If you have existing switches with a
free SFP slot, you can use those instead of the media converters and save most
of the cost.</p>

<hr />

<p>If you need to <strong>temporarily remove</strong> one or both of the fiber cable connector(s),
you also need field assembly connectors and a few tools in addition:</p>

<table>
<thead>
<tr>
<th>amt</th>
<th>price</th>
<th>total</th>
<th>article</th>
<th>note</th>
</tr>
</thead>

<tbody>
<tr>
<td>2x</td>
<td>4 CHF</td>
<td>8 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/35165.html">#35165</a></td>
<td><a href="https://www.FS.COM/de-en/products/35165.html">LC/UPC 0.9mm pre-polished field assembly connector</a></td>
</tr>

<tr>
<td>1x</td>
<td>110 CHF</td>
<td>110 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/14341.html">#14341</a></td>
<td><a href="https://www.FS.COM/de-en/products/14341.html">High Precision Fibre Optic Cleaver FS-08C</a></td>
</tr>

<tr>
<td>1x</td>
<td>26 CHF</td>
<td>26 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/14346.html">#14346</a></td>
<td><a href="https://www.FS.COM/de-en/products/14346.html">Fibre Optic Kevlar Cutter</a></td>
</tr>

<tr>
<td>1x</td>
<td>14 CHF</td>
<td>14 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/72812.html">#72812</a></td>
<td><a href="https://www.FS.COM/de-en/products/72812.html">Fibre Optical Stripper</a></td>
</tr>
</tbody>
</table>

<p>I recommend buying twice the number of field assembly connectors, for practicing.</p>

<p>Personally, I screwed up two connectors before figuring out <a href="#field-assembly-connectors">how the process
goes</a>.</p>

<p>Total cost: about 160 CHF for the field assembly equipment, so 260 CHF in total.</p>

<hr />

<p>To boost your confidence in the resulting fiber, the following items are nice to
have, but you can get by without, if you’re on a budget.</p>

<table>
<thead>
<tr>
<th>price</th>
<th>article</th>
<th>note</th>
</tr>
</thead>

<tbody>
<tr>
<td>18 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/35388.html">#35388</a></td>
<td><a href="https://www.FS.COM/de-en/products/35388.html">FVFL-204 Visual Fault Locator</a></td>
</tr>

<tr>
<td>9.40 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/82730.html">#82730</a></td>
<td><a href="https://www.FS.COM/de-en/products/82730.html">2.5mm to 1.25mm adapter for Visual Fault Locator</a></td>
</tr>

<tr>
<td>4.10 CHF</td>
<td><a href="https://www.FS.COM/de-en/products/14010.html">#14010</a></td>
<td><a href="https://www.FS.COM/de-en/products/14010.html">1.25mm fiber clean swabs (100pcs)</a></td>
</tr>
</tbody>
</table>

<p>With the visual fault locator, you can shine a light through your fiber. You can
verify correct connector assembly by looking at how the light comes out of the
connector.</p>

<p>The fiber cleaning swabs are good to have in general, but for the field assembly
connector, you need to use alcohol-soaked wipes anyway (which FS.COM does not
stock).</p>

<p>The total cost for everything is just under 300 CHF.</p>

<h3 id="hardware-selection-process">Hardware Selection Process</h3>

<p>The large selection at FS.COM can be overwhelming to navigate at first. My
selection process went something like this:</p>

<p>My first constraint is using bi-directional (BiDi) fiber optics modules so that
I only need to lay a single fiber cable, as opposed to two fiber cables.</p>

<p>The second constraint is to use field assembly connectors.</p>

<p>If possible, I wanted to use <a href="https://community.FS.COM/blog/why-not-use-bend-insensitive-fiber-optic-cable-to-reduce-bend-radius.html">bend-insensitive
fiber</a>
so that I wouldn’t need to pay so much attention to the bend radius and have
more flexibility in where and how I can lay fiber.</p>

<p>With these constraints, there aren’t too many products left to combine. An
obvious and good choice are 0.9mm fiber cable using LC/UPC connectors.</p>

<h3 id="fs-com-details">FS.COM details</h3>

<p>As of 2020-08-05, FS.COM states they have 5 warehouses in 4 locations:</p>

<ul>
<li>Delaware (US)</li>
<li>Munich (Germany)</li>
<li>Melbourne (Australia)</li>
<li>Shenzhen (China)</li>
</ul>

<p>They recently built another, bigger (7 km²) warehouse in Shenzhen, and now
produce inventory for the whole year.</p>

<p>By 2019, FS.COM had over 300,000 registered corporate customers, reaching nearly
200 million USD yearly sales.</p>

<h2 id="delivery-times">Delivery times</h2>

<p>As mentioned before, delivery times are quick when the products are in stock at
FS.COM’s German warehouse.</p>

<p>In my case, I put in my order on 2020-Jun-26.</p>

<p>The items that shipped from the German warehouse arrived on 2020-Jul-01.</p>

<p>Some items had to be manufactured and/or shipped from Asia. Those items arrived
after 3 more weeks, on 2020-Jul-24.</p>

<p>Unfortunately, FS.COM doesn’t stock any 0.9mm fiber cables in their German
warehouse right now, so be prepared for a few weeks of waiting time.</p>

<h2 id="laying-the-fiber">Laying The Fiber</h2>

<p>Use a cable puller to pull the fiber through existing cable ducts where
possible.</p>

<ul>
<li><p>In general, buy the thinnest one you can find. I have <a href="https://www.distrelec.ch/en/cable-pull-strap-10m-tools-495005/p/18092626">this 4mm diameter cable
puller</a>,
but a 3mm or even 2mm one would work in more situations.</p></li>

<li><p>I found it worthwhile to buy a brand one. It is distinctly better to handle
(less stiff, i.e. more flexible) than the cheap one I got, and thinner, too,
which is always good.</p></li>
</ul>

<p>In my experience, it generally did not work well to <strong>push</strong> the fiber into an
existing duct or alongside an existing cable. I really needed a cable
<strong>puller</strong>.</p>

<p>If you’re lucky and have enough space in your duct(s), you can leave the
existing connectors on the fiber. I have successfully just used a piece of tape
to fix the fiber connector on the cable puller, pushing down the nose
temporarily:</p>

<p><a href="../../Bilder/2020-08-04-cable-puller.jpg"><img src="../../Bilder/2020-08-04-cable-puller.thumb.jpg" srcset="../../Bilder/2020-08-04-cable-puller.thumb.2x.jpg 2x,../../Bilder/2020-08-04-cable-puller.thumb.3x.jpg 3x" width="600" height="450" alt="fiber cable taped to cable puller" style="border: 1px solid #000" loading="lazy"></a></p>

<p>Where there are no existing ducts, you may need to lay the fiber on top of the
wall. Obviously, this is tricky as soon as you need to make a connection going
through a wall: whereas copper ethernet cables can be bent and squeezed into
door frames, you quickly risk breaking fiber cables.</p>

<p>Luckily, the fiber is very light, so it’s very easy to fix to the wall with a
piece of tape:</p>

<p><a href="../../Bilder/2020-08-04-wand-kabel.jpg"><img src="../../Bilder/2020-08-04-wand-kabel.thumb.1x.jpg" srcset="../../Bilder/2020-08-04-wand-kabel.thumb.2x.jpg 2x,../../Bilder/2020-08-04-wand-kabel.thumb.3x.jpg 3x" width="600" height="450" alt="fiber cables on the wall" style="border: 1px solid #000" loading="lazy"></a></p>

<p>You can see the upstream internet fiber in the top right corner, which is rather
thick in comparison to my 0.9mm yellow fiber that’s barely visible in the middle
of the picture.</p>

<p>Note how the fiber entirely disappears behind the existing duct atop the
door!</p>

<p>Above, you can see the flat ethernet cable I have been using as a temporary
experiment.</p>

<hr />

<p>Where there is an existing cable that you can temporarily remove, it might be
possible to remove it, put the fiber in, and put the old cable back in,
too. This is possible because the 0.9mm fiber cable is so thin!</p>

<p>I’m using this technique to cross another wall where the existing cable duct is
too full, but there is a cable that can be removed and put back after pulling
the fiber through:</p>

<p><a href="../../Bilder/2020-08-04-loch.jpg"><img src="../../Bilder/2020-08-04-loch.thumb.1x.jpg" srcset="../../Bilder/2020-08-04-loch.thumb.2x.jpg 2x,../../Bilder/2020-08-04-loch.thumb.3x.jpg 3x" width="600" height="450" alt="fiber cable next to existing cable" style="border: 1px solid #000" loading="lazy"></a></p>

<p>…and on the other side of the wall:</p>

<p><a href="../../Bilder/2020-08-04-dose.jpg"><img src="../../Bilder/2020-08-04-dose.thumb.1x.jpg" srcset="../../Bilder/2020-08-04-dose.thumb.2x.jpg 2x,../../Bilder/2020-08-04-dose.thumb.3x.jpg 3x" width="600" height="450" alt="fiber cable next to existing socket" style="border: 1px solid #000" loading="lazy"></a></p>

<p>Note how the fiber is thin enough to fit between the socket and duct!</p>

<hr />

<p><strong>Note:</strong> despite measuring how long a fiber cable I would need, my cable turned
out too short! While the cable was just as long as I had measured, with
distances exceeding 10m, it is a good idea to <strong>add a few meters spare</strong> on each
side of the connection.</p>

<h2 id="field-assembly-connectors">Field assembly connectors</h2>

<p>To give you an overview, these are the required steps at a high level:</p>

<ol>
<li>Cut the fiber with the <a href="https://www.FS.COM/de-en/products/14346.html">Fibre Optic Kevlar Cutter</a></li>
<li>Strip the fiber with the <a href="https://www.FS.COM/de-en/products/72812.html">Fibre Optical Stripper</a></li>
<li>Put the field assembly <em>jacket</em> onto the fiber</li>
<li>Cut the stripped fiber cleanly with the <a href="https://www.FS.COM/de-en/products/14341.html">High Precision Fibre Optic Cleaver FS-08C</a></li>
<li>Put the field assembly <em>connector</em> onto the fiber</li>
</ol>

<hr />

<p>I thought the following resources were useful:</p>

<ol>
<li>Pictograms: <a href="https://img-en.fs.com/file/user_manual/lc-field-assembly-connector-quick-start-guide-v1.0.pdf">PDF: FS.COM LC UPC field assembley connectors quick start
guide</a></li>
<li>Pictures: <a href="https://www.fs.com/de-en/products/35165.html">Installation Procedure on
FS.COM</a></li>
<li>Video: <a href="https://www.youtube.com/watch?v=epTzemeJjAw">YouTube: Terminate Fiber in 5
Minutes</a>: this video shows a
different product, but I found it helpful to see any field assembly connector
on video, and this is one of the better videos I could find.</li>
</ol>

<!-- TODO: include a link to my own video once published -->

<hr />

<p><strong>Beware:</strong> the little paper booklet that comes with the field assembly
connector contains measurements which are <strong>not to scale</strong>. I have suggested to
FS.COM that they fix this, but until then, you’ll need to use e.g. a tape
measure.</p>

<hr />

<p>For establishing an intuition of their different sizes, here are the different connectors:</p>

<p><a href="../../Bilder/2020-08-07-fiber-cable-connector-size.jpg"><img src="../../Bilder/2020-08-07-fiber-cable-connector-size.thumb.1x.jpg" srcset="../../Bilder/2020-08-07-fiber-cable-connector-size.thumb.2x.jpg 2x,../../Bilder/2020-08-07-fiber-cable-connector-size.thumb.3x.jpg 3x" width="600" height="450" alt="fiber cable next to existing socket" style="border: 1px solid #000" loading="lazy"></a></p>

<p>From left to right:</p>

<ul>
<li>2.0mm fiber cable</li>
<li>cat6 ethernet cable</li>
<li>0.9mm fiber cable (LC/UPC factory)</li>
<li>0.9mm fiber cable (LC/UPC field assembly connector)</li>
</ul>

<p>The 0.9mm fiber cables come with smaller connectors than the 2.0mm fiber cables,
and that alone might be a reason to prefer them in some situations.</p>

<p>The field assembly connectors are pretty bulky in comparison, but since you can
attach them yourself after pulling only the cable through the walls and/or
ducts, you usually don’t care too much about their size.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Modern fiber cables available at FS.COM are:</p>

<ul>
<li>thinner than I expected</li>
<li>more robust than I expected</li>
<li>cheaper than I expected</li>
<li>survive tighter bend radiuses than I expected</li>
</ul>

<p>Replacing this particular connection with a fiber connection was a smooth
process overall, and I would recommend it in other situations as well.</p>

<hr />

<p>I would claim that it is <strong>totally feasible</strong> for anyone with an hour of
patience to learn how to put a field assembly connector onto a fiber cable.</p>

<p>If labor cost is expensive in your country or you just like doing things
yourself, I can definitely recommend this approach. In case you mess the
connector up and don’t want to fix it yourself, you can always call an
electrician!</p>

<hr />

<p>Stay tuned for the next part, where I upgrade the 1G link to a 10G link!</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Introducing the kinT kinesis keyboard controller]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-07-09-kint-kinesis-keyboard-controller/"/>
    <id>https://michael.stapelberg.ch/posts/2020-07-09-kint-kinesis-keyboard-controller/</id>
    <published>2020-07-09T09:25:00+02:00</published>
    <updated>2020-08-12T10:08:02+02:00</updated>
    <content type="html"><![CDATA[

<p><a href="../../Bilder/2020-05-22-desk-setup-kinesis.jpg"><img
src="../../Bilder/2020-05-22-desk-setup-kinesis.jpg"
alt="Kinesis Advantage ergonomic keyboard"
width="200" align="right" style="border: 1px solid #ccc; margin-left: 1em"></a></p>

<p>Back <a href="../2013-03-21-kinesis_custom_controller/">in 2013, I published a replacement
controller</a> for the Kinesis Advantage
ergonomic keyboard. In the community, it is often referred to simply as the
“stapelberg”, and became quite popular.</p>

<p>Many people like to use the feature-rich <a href="https://docs.qmk.fm/">QMK firmware</a>,
which supports my replacement controller out of the box.</p>

<p><a href="../../Bilder/kinesis-pcb-mounted.jpg"><img
src="../../Bilder/kinesis-pcb-mounted.jpg"
alt="kinesis pcb mounted"
width="200" align="right" style="border: 1px solid #ccc; margin-left: 1em"></a></p>

<p>On eBay, you can frequently find complete stapelberg kits or even
already-modified Kinesis keyboards including the stapelberg board for sale.</p>

<p>In 2017, Kinesis released the Kinesis Advantage 2, which uses a different
connector (an FPC connector) for connecting the two thumb pad PCBs to the
controller PCB, instead of the soldered cable the older Kinesis Advantage
used. Aside from the change in connector and cable type, the newer keyboard uses
the same pinout as the old one.</p>

<p>I wanted to at least update my project to support the Kinesis Advantage 2. While
doing so, I decided to also make a bunch of improvements to make the project
more approachable and usable for beginners. Among many other improvements, the
project switched from Eagle to <a href="https://kicad-pcb.org/">KiCad</a>, which is FOSS
and means no more costly license fees!</p>

<h2 id="kint-t-for-teensy">kinT (T for Teensy!)</h2>

<p>I am hereby announcing the <a href="https://github.com/kinx-project/kint">kinT kinesis keyboard
controller</a>: a replacement keyboard
controller for your Kinesis Advantage or Advantage 2 ergonomic keyboards.</p>

<p><a href="../../Bilder/kint-pcb-3d-render-back-v2020-06-30.png"><img
src="../../Bilder/kint-pcb-3d-render-back-v2020-06-30.png"
alt="kinT keyboard controller"
width="600" style="border: 1px solid #ccc; margin-left: 1em"></a></p>

<p>The Teensy footprint looks a bit odd, but it’s a combined footprint so that you
can use the same board with many different Teensy microcontrollers, giving you
full flexibility regarding cost and features. See <a href="https://github.com/kinx-project/kint#compatibility-which-teensy-to-use">“Compatibility: which Teensy
to
use?”</a>
for more details.</p>

<hr />

<p>I <a href="../2013-03-21-kinesis_custom_controller/">originally replaced the controller of my Kinesis Advantage to work around a
bug</a>, but these days I do most of it
just because I enjoy tinkering with keyboards.</p>

<p>You might consider to replace your keyboard controller for example…</p>

<ul>
<li>to build or modify your own keyboard</li>
<li>to <a href="https://michael.stapelberg.ch/posts/2013-03-21-kinesis_custom_controller/">work around bugs in the standard controller</a></li>
<li>because you prefer to run open source software such as the <a href="https://docs.qmk.fm/">QMK firmware</a>, even on your keyboard</li>
</ul>

<h2 id="building-your-own-kint-keyboard-controller">Building your own kinT keyboard controller</h2>

<ol>
<li><p>Follow <a href="https://github.com/kinx-project/kint#buying-the-board-and-components-bill-of-materials">“Buying the board and components (Bill of
materials)”</a>. When
ordering from OSH Park (board) and Digi-Key (components), you’ll get the
minimum quantity of 3 boards for 72 USD (24 USD per board), and one set of
components for 49 USD.</p>

<ul>
<li>If you have any special requirements regarding which Teensy microcontroller
to use, this is the step where you would replace the Teensy 3.6 with your
choice.</li>
</ul></li>

<li><p>Wait for the components to arrive. When ordering from big shops like Digi-Key
or Mouser, this typically takes 2 days to many places in the world.</p></li>

<li><p>Wait for the boards to arrive. This takes 6 days in the best case when
ordering from OSH Park with their Super Swift Service option. In general, the
longer you are willing to wait, the cheaper it is going to get.</p></li>

<li><p>Follow <a href="https://github.com/kinx-project/kint#soldering">the soldering
guide</a>. This will take about
an hour.</p></li>

<li><p><a href="https://github.com/kinx-project/kint#installing-the-firmware">Install the firmware</a></p></li>
</ol>

<h2 id="improvements-over-the-older-replacement-board">Improvements over the older replacement board</h2>

<p>In case you’re familiar with the older replacement board and are wondering what
changed, here is a complete list:</p>

<ul>
<li><p>The kinT supports both, the older Kinesis Advantage (KB500) <strong>and</strong> the newer
Kinesis Advantage 2 (KB600) keyboards. They differ in how the thumb pads are
connected. See the soldering instructions below.</p></li>

<li><p>The kinT is made for the newer Teensy 3.x and 4.x series, which will remain
widely available for years to come, whereas <a href="https://www.pjrc.com/store/teensypp.html">the future of the Teensy++ 2.0 is
not as certain</a>.</p></li>

<li><p>The kinT is a smaller PCB (4.25 x 3.39 inches, or 108.0 x 86.1 mm), which makes it:</p>

<ul>
<li><p>more compact: can be inserted/removed without having to unscrew a key well.</p></li>

<li><p>cheaper: 72 USD for 3 boards at oshpark, instead of 81 USD.</p></li>
</ul></li>

<li><p>The kinT silkscreen
(<a href="https://raw.githubusercontent.com/kinx-project/kint/44e6c8be96a0e1e13ada5eafdeba8c51a2d6c9e8/pcb-3d-render-front-v2020-06-23.png">front</a>,
<a href="https://raw.githubusercontent.com/kinx-project/kint/44e6c8be96a0e1e13ada5eafdeba8c51a2d6c9e8/pcb-3d-render-back-v2020-06-23.png">back</a>)
and
<a href="https://github.com/kinx-project/kint/blob/44e6c8be96a0e1e13ada5eafdeba8c51a2d6c9e8/schematic-v2020-06-23.pdf">schematic</a>
are much much clearer, making assembly a breeze.</p></li>

<li><p>The kinT is a good starting point for your own project:</p>

<ul>
<li><p>kinT was designed in the open source <a href="https://kicad-pcb.org/">KiCad</a>
program, meaning you do not need any license subscriptions.</p></li>

<li><p>The clear silkscreen and schematic make development and debugging easier.</p></li>
</ul></li>

<li><p>On the kinT, the Teensy no longer has to be soldered onto the board upside down.</p></li>

<li><p>On the kinT, the FPC connectors have been moved for less strain on the cables.</p></li>

<li><p>The kinT makes possible lower-cost builds: if you don’t need the scroll lock,
num lock and keypad LEDs, you can use a Teensy LC for merely 11 USD.</p></li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>I’m very excited to release this new keyboard controller, and I can’t wait to
see all the custom builds and modifications!</p>

<p>By the way, there is also a (4-hour!) <a href="https://youtu.be/I0kwQbnhlfk">stream
recording</a> in case you are interested in some more
history and context, and want to see me solder a kinT controller live on stream!</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Using the iPhone camera as a Linux webcam with v4l2loopback]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-06-06-iphone-camera-linux-v4l2loopback/"/>
    <id>https://michael.stapelberg.ch/posts/2020-06-06-iphone-camera-linux-v4l2loopback/</id>
    <published>2020-06-06T11:18:00+02:00</published>
    <updated>2020-08-12T10:08:02+02:00</updated>
    <content type="html"><![CDATA[

<p><a href="../../Bilder/2020-06-06-iphone-cam.jpg"><img
src="../../Bilder/2020-06-06-iphone-cam.thumb.jpg"
srcset="../../Bilder/2020-06-06-iphone-cam.thumb.2x.jpg 2x,../../Bilder/2020-06-06-iphone-cam.thumb.3x.jpg 3x"
alt="iPhone camera setup"
width="200" align="right" style="border: 1px solid #ccc; margin-left: 1em"></a></p>

<p>For my <a href="https://www.twitch.tv/stapelberg">programming stream at
twitch.tv/stapelberg</a>, I wanted to add an
additional camera to show test devices, electronics projects, etc. I couldn’t
find my old webcam, and new ones are hard to come by currently, so I figured I
would try to include a phone camera somehow.</p>

<p>The setup that I ended up with is:</p>

<p>iPhone camera<br>
→ Instant Webcam<br>
→ WiFi<br>
→ gstreamer<br>
→ v4l2loopback<br>
→ OBS</p>

<p>Disclaimer: I was only interested in a video stream! I don’t think this setup
would be helpful for video conferencing, due to lacking audio/video
synchronization.</p>

<h3 id="iphone-software-instant-webcam-app">iPhone Software: Instant Webcam app</h3>

<p>I’m using the <a href="https://instant-webcam.com/">PhobosLab Instant Webcam</a> (install
from the <a href="https://apps.apple.com/us/app/instant-webcam/id683949930">Apple App
Store</a>) app on an old
iPhone 8 that I bought used.</p>

<p>There are three interesting related blog posts by app author Dominic Szablewski:</p>

<ol>
<li><a href="https://phoboslab.org/log/2013/05/mpeg1-video-decoder-in-javascript">MPEG1 Video Decoder in JavaScript</a> (2013-May)</li>
<li><a href="https://phoboslab.org/log/2013/09/html5-live-video-streaming-via-websockets">HTML5 Live Video Streaming via WebSockets</a> (2013-Sep)</li>
<li><a href="https://phoboslab.org/log/2017/02/decode-it-like-its-1999">Decode it like it’s 1999</a> (2017-Feb)</li>
</ol>

<p>As hinted at in the blog posts, the way the app works is by streaming MPEG1
video from the iPhone (presumably via ffmpeg?) to the <a href="https://jsmpeg.com/">jsmpeg JavaScript
library</a> via WebSockets.</p>

<p>After some git archeology, I figured out that <a href="https://github.com/phoboslab/jsmpeg/commit/7bf420fd0c176d626a50494bfe32135dd911483d">jsmpeg was rewritten in commit
7bf420fd just after
v0.2</a>. You
can <a href="https://github.com/phoboslab/jsmpeg/tree/186666dd9c2d1fd3430d41f15f695d4a78ed1e42">browse the old version on
GitHub</a>.</p>

<p>Notably, the Instant Webcam app seems to <strong>still use the older v0.2 version</strong>,
which <a href="https://github.com/phoboslab/jsmpeg/blob/186666dd9c2d1fd3430d41f15f695d4a78ed1e42/stream-server.js">starts WebSocket streams with a custom 8-byte
header</a>
that we need to strip.</p>

<h3 id="linux-software">Linux Software</h3>

<p>Install the <a href="https://github.com/umlaeute/v4l2loopback"><code>v4l2loopback</code></a> kernel
module, e.g.
<a href="https://www.archlinux.org/packages/community/any/v4l2loopback-dkms/"><code>community/v4l2loopback-dkms</code></a>
on Arch Linux or
<a href="https://packages.debian.org/bullseye/v4l2loopback-dkms"><code>v4l2loopback-dkms</code></a> on
Debian. I used version 0.12.5-1 at the time of writing.</p>

<p>Then, install <a href="https://gstreamer.freedesktop.org/">gstreamer</a> and required
plugins. I used version 1.16.2 for all of these:</p>

<ul>
<li><a href="https://www.archlinux.org/packages/extra/x86_64/gstreamer/"><code>gstreamer</code></a></li>
<li><a href="https://www.archlinux.org/packages/extra/x86_64/gst-plugins-bad/"><code>gst-plugins-bad</code></a> for <code>mpegvideoparse</code></li>
<li><a href="https://www.archlinux.org/packages/extra/x86_64/gst-libav/"><code>gst-libav</code></a> for <code>avdec_mpeg2video</code></li>
</ul>

<p>Lastly, install either <a href="https://github.com/vi/websocat"><code>websocat</code></a> or
<a href="https://github.com/esphen/wsta"><code>wsta</code></a> for accessing WebSockets. I
successfully tested with <code>websocat</code> 1.5.0 and <code>wsta</code> 0.5.0.</p>

<h3 id="streaming">Streaming</h3>

<p>First, load the <code>v4l2loopback</code> kernel module:</p>

<pre><code>% sudo modprobe v4l2loopback video_nr=10 card_label=v4l2-iphone
</code></pre>

<p>Then, we’re going to use gstreamer to decode the WebSocket MPEG1 stream (after
stripping the custom 8-byte header) and send it into the <code>/dev/video10</code> V4L2
device, to the <code>v4l2loopback</code> kernel module:</p>

<pre><code>% websocat --binary ws://iPhone.lan/ws | \
  dd bs=8 skip=1 | \
  gst-launch-1.0 \
    fdsrc \
    ! queue \
    ! mpegvideoparse \
    ! avdec_mpeg2video \
    ! videoconvert \
    ! videorate \
    ! 'video/x-raw, format=YUY2, framerate=30/1' \
    ! v4l2sink device=/dev/video10 sync=false
</code></pre>

<p>Here are a couple of notes about individual parts of this pipeline:</p>

<ul>
<li><p>You must set <code>websocat</code> (or the alternative
<a href="https://github.com/esphen/wsta"><code>wsta</code></a>) into binary mode, otherwise they
will garble the output stream with newline characters, resulting in a
seemingly kinda working stream that just displays garbage. Ask me how I know.</p></li>

<li><p>The <code>queue</code> element uncouples decoding from reading from the network socket,
which should help in case the network has intermittent troubles.</p></li>

<li><p>Without enforcing <code>framerate=30/1</code>, you cannot cancel and restart the
gstreamer pipeline: subsequent invocations will fail with <code>streaming stopped,
reason not-negotiated (-4)</code></p></li>

<li><p>Setting format <code>YUY2</code> allows <code>ffmpeg</code>-based decoders to play the
stream. Without this setting, e.g. <code>ffplay</code> will fail with <code>[ffmpeg/demuxer]
video4linux2,v4l2: Dequeued v4l2 buffer contains 462848 bytes, but 460800 were
expected. Flags: 0x00000001.</code></p></li>

<li><p>The <code>sync=false</code> property on <code>v4l2sink</code> plays frames as quickly as possible
without trying to do any synchronization.</p></li>
</ul>

<p>Now, consumers such as <a href="https://obsproject.com/">OBS (Open Broadcaster
Software)</a>, <code>ffplay</code> or <code>mpv</code> can capture from
<code>/dev/video10</code>:</p>

<pre><code>% ffplay /dev/video10
% mpv av://v4l2:/dev/video10 --profile=low-latency
</code></pre>

<h3 id="debugging">Debugging</h3>

<p>Hopefully the instructions above just work for you, but in case things go wrong,
maybe the following notes are helpful.</p>

<p>To debug issues, I used the <code>GST_DEBUG_DUMP_DOT_DIR</code> environment variable as
described on <a href="https://gstreamer.freedesktop.org/documentation/tutorials/basic/debugging-tools.html?gi-language=c#getting-pipeline-graphs">Debugging tools: Getting pipeline
graphs</a>. In
these graphs, you can quickly see which pipeline elements negotiate which caps.</p>

<p>I also used the <a href="https://github.com/phoboslab/pl_mpeg">PL_MPEG</a> example program
to play the <a href="https://phoboslab.org/files/bjork-all-is-full-of-love.mpg">supplied MPEG test
file</a>. PL_MPEG is
written by Dominic Szablewski as well, and you can read more about it in
Dominic’s blog post <a href="https://phoboslab.org/log/2019/06/pl-mpeg-single-file-library">MPEG1 Single file C
library</a>. I
figured the codec and parameters might be similar between the different projects
of the same author and used this to gain more confidence into the stream
parameters.</p>

<p>I also used <a href="https://www.wireshark.org/">Wireshark</a> to look at the stream
traffic to discover that <code>websocat</code> and <code>wsta</code> garble the stream output by
default unless the <code>--binary</code> flag is used.</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[stapelberg uses this: my 2020 desk setup]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-05-23-desk-setup/"/>
    <id>https://michael.stapelberg.ch/posts/2020-05-23-desk-setup/</id>
    <published>2020-05-23T15:22:00+02:00</published>
    <updated>2020-08-28T07:47:54+02:00</updated>
    <content type="html"><![CDATA[

<p><a href="../../Bilder/2020-05-22-desk-setup.jpg"><img
src="../../Bilder/2020-05-22-desk-setup.thumb.jpg"
srcset="../../Bilder/2020-05-22-desk-setup.thumb.2x.jpg 2x,../../Bilder/2020-05-22-desk-setup.thumb.3x.jpg 3x"
alt="Desk setup"
width="600"
style="border: 1px solid #ccc"></a></p>

<p>I generally enjoy reading the <a href="https://usesthis.com/">uses this</a> blog, and
recently people have been talking about desk setups in my bubble (and <a href="https://www.twitch.tv/stapelberg">on my
Twitch stream</a>), so I figured I’d write a post
about my current setup!</p>

<h2 id="desk-setup">Desk setup</h2>

<p>I’m using a desk I bought at IKEA well over 10 years ago. I’m not using a
standing desk: while I have one at work, I never change its height. Just never
could get into the habit.</p>

<p>I was using an IKEA chair as well for many years.</p>

<p>Currently, I’m using a <a href="https://eu.haworth.com/home/seating/executive/zody">Haworth Comforto
89</a> chair that I bought
second-hand. Unfortunately, the arm rests are literally crumbling apart and the
lumbar back support and back rest in general are not as comfortable as I would
like.</p>

<p>Hence, I recently ordered a <a href="https://www.vitra.com/en-ch/office/product/details/id-mesh">Vitra ID
Mesh</a> chair, which I
have used for a couple of years at the office before moving office buildings. It
will take a few weeks before the chair arrives.</p>

<p><details><summary>Full Vitra ID Mesh chair configuration details</summary>
<ul>
<li>ID Mesh</li>
<li>Chair type: office swivel chair</li>
<li>Backrest: ID Mesh</li>
<li>Colours and materials</li>
<li>- Cover material: seat and backrest Silk Mesh</li>
<li>- Colour of back cover: dim grey/ like frame colour</li>
<li>- Colour of seat cover: dim grey</li>
<li>- Frame colour: soft grey</li>
<li>Armrests: 2D armrests</li>
<li>Base: five-star base, polished aluminium</li>
<li>Base on: castors hard, braked for carpet</li>
<li>Ergonomics</li>
<li>Seat and seat depth adjustment: seat with seat depth adjustment</li>
<li>Forward tilt: with forward tilt</li>
</ul>
</details></p>

<p>The most important aspect of the desk/chair setup for me are the arm rests. I
align them with the desk height so that I can <a href="https://de.wikipedia.org/wiki/Datei:Ergonomic_workstation.png">place my arms at a 90 degree
angle, eliminating
strain</a>.</p>

<h2 id="peripherals">Peripherals</h2>

<p>Note: all of my peripherals are Plug &amp; Play under Linux and generally work with
standard drivers across Windows, macOS and Linux.</p>

<h3 id="monitor-dell-8k4k-monitor-up3218k">Monitor: Dell 8K4K monitor (UP3218K)</h3>

<p>The most important peripheral of a computer is the monitor: you stare at it all
the time. Even when you’re not using your keyboard or mouse, you’re still
looking at your monitor.</p>

<p>Ever since I first used a MacBook Pro with Retina display back in 2013, I’ve
been madly in love with hi-DPI displays, and have gradually replaced all
displays in my day-to-day with hi-DPI displays.</p>

<p>My current monitor is the <a href="/posts/2017-12-11-dell-up3218k/">Dell UP3218K, an 8K4K monitor (blog post)</a>.</p>

<p>Dell introduced the UP3218K in January 2017. It is the world’s first available
8K monitor, meaning it has a resolution of 7680x4320 pixels at a refresh rate of
60 Hz. The display’s dimensions are 698.1mm by 392.7mm (80cm diagonal, or 31.5
inches), meaning the display shows 280 dpi.</p>

<p>I run it in 300% scaling mode (<code>Xft.dpi: 288</code>), resulting in incredibly crisp
text.</p>

<p>Years ago, I used multiple monitors (sometimes 3, usually 2). I stopped doing
that in 2011/2012, when I lived in Dublin for half a year and decided to get
only one external monitor for practical and cost reasons.</p>

<p>I found that using only one monitor allows me to focus more on what I’m doing,
and I don’t miss anything about a multi-monitor setup.</p>

<h3 id="keyboard-kinesis-advantage-keyboard">Keyboard: Kinesis advantage keyboard</h3>

<p><a href="../../Bilder/2020-05-22-kinesis-advantage.jpg"><img
src="../../Bilder/2020-05-22-kinesis-advantage.thumb.jpg"
srcset="../../Bilder/2020-05-22-kinesis-advantage.thumb.2x.jpg 2x,../../Bilder/2020-05-22-kinesis-advantage.thumb.3x.jpg 3x"
alt="Kinesis advantage keyboard"
loading="lazy"
width="600"
style="border: 1px solid #ccc"></a></p>

<p>The Kinesis is my preferred commercially available ergonomic keyboard. I like
its matrix layout, ergonomic key bowls, thumb pads and split hands.</p>

<p>I find typing on it much more comfortable than regular keyboards, and I value
the Kinesis enough to usually carry one with me when I travel. When I need to
use a laptop keyboard for longer periods of time, my hands and arms get tired.</p>

<p>I bought my first one in 2008 for ≈250 EUR, but have since cleaned up and
repaired two more Kinesis keyboards that were about to be trashed. Now I have
one for home, one for work, and one for traveling (or keyboard development).</p>

<p>Over the years, I have modified my Kinesis keyboards in various ways:</p>

<p>The first modification I did was to put in <a href="https://www.cherrymx.de/en/mx-original/mx-blue.html">Cherry MX blue key
switches</a> (tactile and
audible), replacing the default <a href="https://www.cherrymx.de/en/mx-original/mx-brown.html">Cherry MX
browns</a>. I like the quick
feedback of the blues better, possibly because I was used to them from my
previous keyboards. Without tons of patience and good equipment, it’s virtually
impossible to unsolder the key switches, so I reached out to Kinesis, and they
agreed to send me unpopulated PCBs into which I could solder my preferred
key switches! Thank you, Kinesis.</p>

<p>I later <a href="/posts/2013-03-21-kinesis_custom_controller/">replaced the keyboard controller to address a stuck modifier
bug</a>. The
PCB I made for this remains popular in the Kinesis modification community to
this day.</p>

<p>In 2018, I got interested in keyboard input latency and developed <a href="/posts/2018-04-17-kinx/">kinX, a new
version of my replacement keyboard controller</a>. With
this controller, the keyboard has an input latency of merely 0.225ms in the
worst case.</p>

<p>Aside from the keyboard hardware itself, I’m <a href="/posts/2009-01-01-neo_kinesis/">using the NEO Ergonomically
Optimized keyboard layout</a>. It’s optimized for
German, English, Programming and Math, in that order. Especially its upper
layers are really useful: <a href="https://neo-layout.org/">hover over “Ebene 3”</a> to
see.</p>

<p>I used to remap keys in hardware, but that doesn’t cover the upper layers, so
nowadays I prefer just enabling the NEO layout included in operating systems.</p>

<h3 id="pointing-device-logitech-mx-ergo">Pointing device: Logitech MX Ergo</h3>

<p>During my student years (2008 to 2013), I carried a ThinkPad X200 and used its
TrackPoint (“red dot”) in combination with trying to use lots of keyboard
shortcuts.</p>

<p>The concept of relative inputs for mouse movement made sense to me, so I
switched from a mouse to a trackball on the desktop, specifically the <a href="https://www.logitech.com/en-us/product/wireless-trackball-m570">Logitech
Trackball M570</a>.</p>

<p>I was using the M570 for many years, but have switched to the <a href="https://www.logitech.com/en-ch/product/mx-ergo-wireless-trackball-mouse">Logitech MX
Ergo</a> a
few months ago. It is more comfortable to me, so I replaced all 3 trackballs
(home, office, travel) with the MX Ergo.</p>

<p>In terms of precision, a trackball will not be as good as a mouse can be. To me,
it more than makes up for the fact by reducing the strain on my hands and
wrists.</p>

<p>For comparison: a few years ago, I was playing a shooter with a regular mouse
for one evening (mostly due to nostalgia), and I could feel pain from that for
weeks afterwards.</p>

<h3 id="microphone-røde-podcaster">Microphone: RØDE Podcaster</h3>

<p>To record screencasts for the <a href="https://i3wm.org/">i3 window manager</a> with decent
audio, I bought a <a href="http://www.rode.com/microphones/podcaster">RØDE Podcaster USB Broadcast
Mic</a> in 2012 and have been using it
ever since.</p>

<p>The big plus is that the setup couldn’t be easier: you connect it via USB, and
it is Plug &amp; Play on Linux. This is much easier than getting a working setup
with <a href="https://en.wikipedia.org/wiki/XLR_connector">XLR audio gear</a>.</p>

<p>The audio quality is good: much better than headsets or cheap mics, but probably
not quite as good as a more expensive studio mic. For my usage, this is fine: I
don’t record radio broadcasts regularly, so I don’t need the absolutely highest
quality, and for video conferences or the occasional podcast, the RØDE Podcaster
is superb.</p>

<h3 id="webcam-logitech-c920">Webcam: Logitech C920</h3>

<p>In the past, I have upgraded my webcam every so often because higher resolutions
at higher frame rates became available for a reasonably low price.</p>

<p>I’m currently using the <a href="https://www.logitech.com/en-ch/product/hd-pro-webcam-c920">Logitech HD Pro Webcam
C920</a>, and I’m pretty
happy with it. The picture quality is good, the device is Plug &amp; Play under
Linux and the picture quality is good out of the box. No fumbling with UVC
parameters or drivers required :-)</p>

<p>Note: to capture at 30 fps at the highest resolution, you may need to specify
the pixel format: <a href="https://wiki.archlinux.org/index.php/webcam_setup#mpv">https://wiki.archlinux.org/index.php/webcam_setup#mpv</a></p>

<h3 id="headphones-sony-wh-1000xm3">Headphones: Sony WH-1000XM3</h3>

<p>At work, I have been using the <a href="https://www.bose.ch/de_ch/support/products/bose_headphones_support/bose_around_ear_headphones_support/qc15.html">Bose QuietComfort 15 Noise Cancelling
headphones</a>
for many years, as they were considered the gold standard for noise cancelling
headphones.</p>

<p>I decided to do some research and give bluetooth headphones a try, in the hope
that the technology has matured enough.</p>

<p>I went with the <a href="https://www.sony.com/electronics/headband-headphones/wh-1000xm3">Sony
WH-1000XM3</a>
bluetooth headphones, and am overall quite happy with them. The lack of a cable
is very convenient indeed, and the <strong>audio quality and noise cancellation are
both superb</strong>. A single charge lasts me for multiple days.</p>

<p>Switching devices is a bit cumbersome: when I have the headphones connected to
my phone and want to switch to my computer, I need to explicitly disconnect on
my phone, then explicitly connect on my computer. I guess this is just how
bluetooth works.</p>

<p>One issue I ran into is that when the headphones re-connected to my computer,
they <a href="https://gitlab.freedesktop.org/pulseaudio/pulseaudio/issues/525#note_373471">would not select the high-quality audio
profile</a>
until you explicitly disconnect and re-connect again. This <a href="https://git.kernel.org/pub/scm/bluetooth/bluez.git/patch/?id=477ecca127c529611adbc53f08039cefaf86305d">was
fixed</a>
in BlueZ 5.51, so make sure you run at least that version.</p>

<h3 id="usb-memory-stick-sandisk-extreme-pro-ssd-usb-3-1">USB memory stick: Sandisk Extreme PRO SSD USB 3.1</h3>

<p>USB memory sticks are useful for all sorts of tasks, but I mostly use them to
boot Linux distributions on my laptop or computer, for development, recovery,
updates, etc.</p>

<p>A year ago, I was annoyed by my USB memory sticks being slow, and I found the
<a href="https://shop.westerndigital.com/products/usb-flash-drives/sandisk-extreme-pro-usb-3-1">Sandisk Extreme PRO SSD USB
3.1</a>
which is essentially a little SSD in USB memory stick form factor. It is spec'd
at ≈400 MB/s read and write speed, and I do reach about ≈350 MB/s in practice,
which is a welcome upgrade from the &lt; 10 MB/s my previous sticks did.</p>

<p>A quick USB memory stick lowers the hurdle for testing
<a href="https://distr1.org/">distri</a> images on real hardware.</p>

<h3 id="audio-teufel-sound-system">Audio: teufel sound system</h3>

<p>My computer is connected to a <a href="https://www.teufelaudio.com/pc/motiv-2-p167.html">Teufel Motiv
2</a> stereo sound system I
bought in 2009.</p>

<p>The audio quality is superb, and when I tried to replace them with the <a href="https://www.qacoustics.co.uk/q-acoustics-3020-bookshelf-speakers-pair.html">Q
Acoustics 3020 Speakers
(Pair)</a>
I ended up selling the Q Acoustics and going back to the Teufel. Maybe I’m just
very used to its sound at this point :-)</p>

<h3 id="physical-paper-notebook-for-sketches">Physical paper notebook for sketches</h3>

<p>I also keep a paper notebook on my desk, but don’t use it a lot. It is good to
have it for ordering my thoughts when the subject at hand is more visual rather
than textual. For example, my <a href="/posts/2019-02-05-turbopfor-analysis/">analysis of the TurboPFor integer compression
scheme</a> started out on a bunch of
notebook pages.</p>

<p>I don’t get much out of hand writing into a notebook (e.g. for task lists), so I
tend to do that in <a href="https://orgmode.org/">Emacs Org mode</a> files instead (1 per
project). I’m only a very light Org mode user.</p>

<h3 id="laptop-tbd">Laptop: TBD</h3>

<p>I’m writing a separate article about my current laptop and will reference the
post here once published.</p>

<p>I will say that I mostly use laptops for traveling (to conferences or events)
these days, and there is not much travel happening right now due to COVID-19.</p>

<p>Having a separate computer is handy for some debugging activities,
e.g. single-stepping X11 applications in a debugger, which needs to be done via
SSH.</p>

<h3 id="internet-router-and-wifi-router7-and-unifi-ap-hd">Internet router and WiFi: router7 and UniFi AP HD</h3>

<p>Mostly for fun, I decided to write <a href="https://github.com/rtr7/router7">router7, a highly reliabile, automatically
updating internet router entirely in Go</a>,
primarily targeting the <a href="https://www.init7.net/">fiber7</a> internet service.</p>

<p>While the router could go underneath my desk, I currently keep it on top of my
desk. Originally, I placed it in reach to lower the hurdle for debugging, but
after the initial development phase, I never had to physically power cycle it.</p>

<p>These days, I only keep it on top of my desk because I like the physical
reminder of what I accomplished :-)</p>

<p>For WiFi, I use a <a href="https://unifi-hd.ui.com/">UniFi AP HD</a> access point from
Ubiquiti. My apartment is small enough that this single access point covers all
corners with great WiFi. I’m configuring the access point with the mobile app so
that I don’t need to run the controller app somewhere.</p>

<p>In general, I try to connect most devices via ethernet to remove WiFi-related
issues from the picture entirely, and reduce load on the WiFi.</p>

<h3 id="switching-peripherals-between-home-and-work-computer">Switching peripherals between home and work computer</h3>

<p>Like many, I am currently working from home due to COVID-19.</p>

<p>Because I only have space for one 32&quot; monitor and peripherals on my desk, I
decided to share them between my personal computer and my work computer.</p>

<p>To make this easy, I got an active <a href="https://www.anker.com/products/variant/anker-10-port-60w-data-hub/A7515111">Anker 10-port USB3
hub</a>
and two USB 3 cables for it: one connected to my personal computer, one to my
work computer. Whenever I need to switch, I just re-plug the one cable.</p>

<h2 id="software-setup">Software setup</h2>

<h3 id="linux">Linux</h3>

<p>I have been using Linux as my primary operating system since 2005. The first
Linux distribution that I installed in 2005 was Ubuntu-based. Later, I switched
to Gentoo, then to Debian, which I used and contributed to until <a href="https://michael.stapelberg.ch/posts/2019-03-10-debian-winding-down/">quitting the
project in March
2019</a>.</p>

<p>I had briefly tried Fedora before, and decided to give Arch Linux a shot now, so
that’s what I’m running on my desktop computer right now. My servers remain on
<a href="https://www.flatcar-linux.org/">Flatcar Container Linux</a> (the successor to
CoreOS) or Debian, depending on their purpose.</p>

<p>For me, all <a href="/posts/2019-08-17-linux-package-managers-are-slow/">Linux package managers are too
slow</a>, which is why I
started <a href="/posts/2019-08-17-introducing-distri/">distri: a Linux distribution to research fast package
management</a>. I’m testing distri on my
laptop, and I’m using distri for a number of development tasks. I don’t want to
run it on my desktop computer, though, because of its experimental nature.</p>

<h3 id="window-manager-i3">Window Manager: i3</h3>

<p>It won’t be a surprise that I am using the <a href="https://i3wm.org/">i3 tiling window
manager</a>, which I created in 2009 and still maintain.</p>

<p><a href="https://github.com/stapelberg/configfiles/blob/master/config/i3/config">My i3 configuration
file</a> is
pretty close to the i3 default config, with only two major modifications: I use
<code>workspace_layout stacked</code> and usually arrange two stacked containers next to
each other on every workspace. Also, I configured a <a href="https://github.com/stapelberg/configfiles/blob/5a3703a8c0fca06242d936c13e4fcc2761f3a58b/config/i3/config#L170">volume
mode</a>
which allows for easily changing the default sink’s volume.</p>

<p>One way in which my usage might be a little unusual is that I always have at
least 10 workspaces open.</p>

<h3 id="go">Go</h3>

<p>Over time, I have moved all new development work to Go, which is by far <a href="https://michael.stapelberg.ch/posts/2017-08-19-golang_favorite/">my
favorite programming
language</a>. See
the article for details, but in summary, Go’s values align well with my own: the
tooling is quick and high-quality, the language well thought-out and operating
at roughly my preferred level of abstraction vs. clarity.</p>

<p>Here is a quick description of a few notable Go projects I started:</p>

<p><a href="https://codesearch.debian.net/">Debian Code Search</a> is a regular expression
source code search engine covering all software available in Debian.</p>

<p><a href="https://robustirc.net/">RobustIRC</a> is an IRC network without netsplits, based
on <a href="https://en.wikipedia.org/wiki/Raft_(computer_science)">the Raft consensus
algorithm</a>.</p>

<p><a href="https://gokrazy.org/">gokrazy</a> is a pure-Go userland for your Raspberry Pi 3
appliances. It allows you to overwrite an SD card with a Linux kernel, Raspberry
Pi firmware and Go programs of your chosing with just one command.</p>

<p><a href="https://github.com/rtr7/router7">router7</a> is a pure-Go small home internet
router.</p>

<p><a href="https://github.com/debian/debiman">debiman</a> generates a static manpage HTML
repository out of a Debian archive and powers
<a href="https://manpages.debian.org/">manpages.debian.org</a>.</p>

<p>The <a href="https://distr1.org/">distri research linux distribution project</a> was
started in 2019 to research whether a few architectural changes could enable
drastically faster package management. While the package managers in common
Linux distributions (e.g. apt, dnf, …) <a href="/posts/2019-08-17-linux-package-managers-are-slow/">top out at data rates of only a few
MB/s</a>, distri effortlessly
saturates 1 Gbit, 10 Gbit and even 40 Gbit connections, resulting in superior
installation and update speeds.</p>

<h3 id="editor-emacs">Editor: Emacs</h3>

<p>In my social circle, everyone used Vim, so that’s what I learnt. I used it for
many years, but eventually gave Emacs a shot so that I could try the best
<a href="https://notmuchmail.org/">notmuch</a> frontend.</p>

<p>Emacs didn’t immediately click, and I haven’t used notmuch in many years, but it
got me curious enough that I tried getting into the habit of using Emacs a few
years ago, and now I prefer it over Vim and other editors.</p>

<p>Here is a non-exhaustive list of things I like about Emacs:</p>

<ol>
<li><p>Emacs is not a modal editor. You don’t need to switch into insert mode before
you can modify the text. This might sound like a small thing, but I feel more
of a direct connection to the text this way.</p></li>

<li><p>I like Emacs’s built-in buffer management. I could never get used to using
multiple tabs or otherwise arranging my Vim editor window, but with Emacs,
juggling multiple things at the same time feels very natural.
<br />
I make heavy use of Emacs’s compile mode (similar to Vim’s quick fix window):
I will compile not only programs, but also config files (e.g. <code>M-x compile i3
reload</code>) or <code>grep</code> commands, allowing me to go through matches via <code>M-g M-n</code>.</p></li>

<li><p>The <a href="https://magit.vc/">Magit</a> package is <strong>by far</strong> my most favorite Git
user interface. Staging individual lines or words comes very naturally, and
many operations are much quicker to accomplish compared to using Git in a
terminal.</p></li>

<li><p>The <a href="https://github.com/joaotavora/eglot">eglot</a> package is a good
<a href="https://en.wikipedia.org/wiki/Language_Server_Protocol">LSP</a> client, making
available tons of powerful cross-referencing and refactoring features.</p></li>

<li><p>The possible customization is impressive, including the development
experience: Emacs’s built-in help system is really good, and allows jumping
to the definition of variables or functions out of the box. Emacs is the only
place in my day-to-day where I get a little glimpse into what it must have
been like to use a <a href="https://en.wikipedia.org/wiki/Lisp_machine">Lisp
machine</a>…</p></li>
</ol>

<p>Of course, not everything is great about Emacs. Here are a few annoyances:</p>

<ol>
<li><p>The Emacs default configuration is very old, and a number of settings need to
be changed to make it more modern. I have been tweaking my Emacs config since
2012 and still feel like I’m barely scratching the surface. Many beginners
find their way into Emacs by using a pre-configured version of it such as
<a href="https://github.com/hlissner/doom-emacs">Doom Emacs</a> or
<a href="https://www.spacemacs.org/">Spacemacs</a>.</p></li>

<li><p>Even after going through great lengths to keep startup fast, Emacs definitely
starts much more slowly than e.g. Vim. This makes it not a great fit for
trivial editing tasks, such as commenting out a line of configuration on a
server via SSH.</p></li>
</ol>

<p>For consistency, I eventually switched my shell and readline config from vi key
bindings to the default Emacs key bindings. This turned out to be a great move:
the Emacs key bindings are generally better tested and more closely resemble the
behavior of the editor. With vi key bindings, sooner or later I always ran into
frustrating feature gaps (e.g. zsh didn’t support the
delete-until-next-x-character Vim command) or similar.</p>

<h2 id="hardware-setup-desktop-computer">Hardware setup: desktop computer</h2>

<p>I should probably publish a separate blog post with PC hardware recommendation,
so let me focus on the most important points here only:</p>

<p>I’m using an Intel i9-9900K CPU. I briefly switched to an AMD Ryzen 3900X based
on tech news sites declaring it faster. I eventually found out that the Intel
i9-9900K actually benchmarks better in browser performance and incremental Go
compilation, so I switched back.</p>

<p>To be able to drive the Dell 8K4K monitor, I’m using a nVidia GeForce
RTX 2070. I don’t care for its 3D performance, but more video RAM and memory
bandwidth make a noticeable difference in how many Chrome tabs I can work with.</p>

<p>To avoid running out of memory, I usually max out memory based on mainboard
support and what is priced reasonably. Currently, I’m using 64 GB of Corsair
RAM.</p>

<p>For storage, I currently use a Phison Force MP600 PCIe 4 NVMe disk, back from
when I tried the Ryzen 3900X. When I’m not trying out PCIe 4, I usually go with
the latest Samsung Consumer SSD PRO, e.g. the <a href="https://www.samsung.com/semiconductor/minisite/ssd/product/consumer/970pro/">Samsung SSD 970
PRO</a>. Having
a lot of bandwidth and IOPS available is great in general, but especially
valuable when e.g. <a href="https://github.com/Debian/debiman/">re-generating all
manpages</a> or compiling a new
<a href="https://distr1.org/">distri</a> version from scratch.</p>

<p>I’m a fan of Fractal Design’s Define case series (e.g. the <a href="https://www.fractal-design.com/products/cases/define/define-r6-usb-c/blackout/">Define
R6</a>)
and have been using them for many years in many different builds. They are great
to work with: no sharp edges, convenient screws and mechanisms, and they result
in a quiet computer.</p>

<p>For fans, my choice is Noctua. Specifically, their
<a href="https://noctua.at/en/products/cpu-cooler-retail/nh-u14s">NH-U14S</a> makes for a
great CPU fan, and their <a href="https://noctua.at/en/nf-a12x25-pwm">NF-A12x25</a> are
great case fans. They cool well and are super quiet!</p>

<h2 id="network-storage">Network storage</h2>

<p>For redundancy, I am backing up my computers to 2 separate network storage devices.</p>

<p>My devices are <a href="/posts/2019-10-23-nas/">built from PC Hardware</a> and run <a href="/posts/2016-11-21-gigabit-nas-coreos/">Flatcar
Linux (previously CoreOS)</a> for automated
updates. I put in one hard disk per device for maximum redundancy: any hardware
component can fail and I can just use the other device.</p>

<p>The software setup is intentionally kept very simple: I use <code>rsync</code> (with
hardlinks) over SSH for backups, and serve files using Samba. That way, backups
are just files, immediately available, and accessible from another computer if
everything else fails.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope this was interesting! If you have any detail questions, feel free to
reach out <a href="https://michael.stapelberg.ch/">via email</a> or
<a href="https://twitter.com/zekjur">twitter</a>.</p>

<p>If you’re looking for more product recommendations (tech or otherwise), one of
my favorite places is the <a href="https://thewirecutter.com/">wirecutter</a>.</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[a new distri linux (fast package management) release]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-05-16-distri-release/"/>
    <id>https://michael.stapelberg.ch/posts/2020-05-16-distri-release/</id>
    <published>2020-05-16T09:13:00+02:00</published>
    <updated>2020-05-16T09:14:11+02:00</updated>
    <content type="html"><![CDATA[<p>I just <a href="https://distr1.org/release-notes/supersilverhaze/">released a new version of distri</a>.</p>

<p>The focus of this release lies on:</p>

<ul>
<li><p>a better developer experience, allowing users to debug any installed package
without extra setup steps</p></li>

<li><p>performance improvements in all areas (starting programs, building distri
packages, generating distri images)</p></li>

<li><p>better tooling for keeping track of upstream versions</p></li>
</ul>

<p>See the <a href="https://distr1.org/release-notes/supersilverhaze/">release notes</a> for
more details.</p>

<p>The <a href="https://distr1.org/">distri research linux distribution</a> project <a href="/posts/2019-08-17-introducing-distri/">was started in
2019</a> to research whether a few
architectural changes could enable drastically faster package management.</p>

<p>While the package managers in common Linux distributions (e.g. apt, dnf, …) <a href="/posts/2019-08-17-linux-package-managers-are-slow/">top
out at data rates of only a few
MB/s</a>, distri effortlessly
saturates 1 Gbit, 10 Gbit and even 40 Gbit connections, resulting in fast
installation and update speeds.</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Hermetic packages (in distri)]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-05-09-distri-hermetic-packages/"/>
    <id>https://michael.stapelberg.ch/posts/2020-05-09-distri-hermetic-packages/</id>
    <published>2020-05-09T18:48:00+02:00</published>
    <updated>2020-08-12T10:08:02+02:00</updated>
    <content type="html"><![CDATA[

<p>In <a href="https://distr1.org/">distri</a>, packages (e.g. <code>emacs</code>) are hermetic. By
hermetic, I mean that the dependencies a package uses (e.g. <code>libusb</code>) don’t
change, even when newer versions are installed.</p>

<p>For example, if package <code>libusb-amd64-1.0.22-7</code> is available at build time, the
package will always use that same version, even after the newer
<code>libusb-amd64-1.0.23-8</code> will be installed into the package store.</p>

<p>Another way of saying the same thing is: <em>packages in distri are always
co-installable</em>.</p>

<p>This makes the package store more robust: additions to it will not break the
system. On a technical level, the package store is implemented as a directory
containing distri SquashFS images and metadata files, into which packages are
installed in an atomic way.</p>

<h2 id="out-of-scope-plugins-are-not-hermetic-by-design">Out of scope: plugins are not hermetic by design</h2>

<p>One exception where hermeticity is not desired are plugin mechanisms: optionally
loading out-of-tree code at runtime obviously is not hermetic.</p>

<p>As an example, consider <a href="https://www.gnu.org/software/libc/manual/html_node/Name-Service-Switch.html">glibc’s Name Service Switch
(NSS)</a>
mechanism. Page <a href="https://www.gnu.org/software/libc/manual/html_node/Adding-another-Service-to-NSS.html#Adding-another-Service-to-NSS">29.4.1 Adding another Service to
NSS</a>
describes how glibc searches <code>$prefix/lib</code> for shared libraries at runtime.</p>

<p>Debian <a href="https://packages.debian.org/search?suite=buster&amp;arch=amd64&amp;mode=filename&amp;searchon=contents&amp;keywords=libnss_%20.so.2">ships about a dozen NSS
libraries</a>
for a variety of purposes, and enterprise setups might add their own into the
mix.</p>

<p>systemd (as of v245) accounts for 4 NSS libraries,
e.g. <a href="https://www.freedesktop.org/software/systemd/man/nss-systemd.html">nss-systemd</a>
for user/group name resolution for users allocated through <a href="https://www.freedesktop.org/software/systemd/man/systemd.exec.html">systemd’s
<code>DynamicUser=</code></a>
option.</p>

<p>Having packages be as hermetic as possible remains a worthwhile goal despite any
exceptions: I will gladly use a 99% hermetic system over a 0% hermetic system
any day.</p>

<p>Side note: Xorg’s driver model (which can be characterized as a plugin
mechanism) does not fall under this category because of its tight API/ABI
coupling! For this case, where drivers are only guaranteed to work with
precisely the Xorg version for which they were compiled, distri uses per-package
exchange directories.</p>

<h2 id="implementation-of-hermetic-packages-in-distri">Implementation of hermetic packages in distri</h2>

<p>On a technical level, the requirement is: all paths used by the program must
always result in the same contents. This is implemented in distri via the
read-only package store mounted at <code>/ro</code>, e.g. files underneath
<code>/ro/emacs-amd64-26.3-15</code> never change.</p>

<p>To change all paths used by a program, in practice, three strategies cover most
paths:</p>

<h3 id="elf-interpreter-and-dynamic-libraries">ELF interpreter and dynamic libraries</h3>

<p>Programs on Linux use the <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">ELF file
format</a>, which
contains two kinds of references:</p>

<p>First, <strong>the ELF interpreter</strong> (<code>PT_INTERP</code> segment), which is used to start the
program. For dynamically linked programs on 64-bit systems, this is typically
<a href="https://manpages.debian.org/testing/manpages/ld.so.8.en.html"><code>ld.so(8)</code></a>.</p>

<p>Many distributions use system-global paths such as
<code>/lib64/ld-linux-x86-64.so.2</code>, but distri compiles programs with
<code>-Wl,--dynamic-linker=/ro/glibc-amd64-2.31-4/out/lib/ld-linux-x86-64.so.2</code> so
that the full path ends up in the binary.</p>

<p>The ELF interpreter is shown by <code>file(1)</code>, but you can also use <code>readelf -a
$BINARY | grep 'program interpreter'</code> to display it.</p>

<p>And secondly, <a href="https://en.wikipedia.org/wiki/Rpath"><strong>the rpath</strong>, a run-time search
path</a> for dynamic libraries. Instead of
storing full references to all dynamic libraries, we set the rpath so that
<code>ld.so(8)</code> will find the correct dynamic libraries.</p>

<p>Originally, we used to just set a long rpath, containing one entry for each
dynamic library dependency. However, we have since <a href="https://github.com/distr1/distri/commit/19f342071283f4d78353bdbac8d6849809927f93">switched to using a single
<code>lib</code> subdirectory per
package</a>
as its rpath, and placing symlinks with full path references into that <code>lib</code>
directory, e.g. using <code>-Wl,-rpath=/ro/grep-amd64-3.4-4/lib</code>. This is better for
performance, as <code>ld.so</code> uses a per-directory cache.</p>

<p>Note that program load times are significantly influenced by how quickly you can
locate the dynamic libraries. distri uses a FUSE file system to load programs
from, so <a href="https://github.com/distr1/distri/commit/b6a0e43368d54d5ed0e03af687158dc3e2106e38">getting proper <code>-ENOENT</code> caching into
place</a>
drastically sped up program load times.</p>

<p>Instead of compiling software with the <code>-Wl,--dynamic-linker</code> and <code>-Wl,-rpath</code>
flags, one can also modify these fields after the fact using <code>patchelf(1)</code>. For
closed-source programs, this is the only possibility.</p>

<p>The rpath can be inspected by using e.g. <code>readelf -a $BINARY | grep RPATH</code>.</p>

<h3 id="environment-variable-setup-wrapper-programs">Environment variable setup wrapper programs</h3>

<p>Many programs are influenced by environment variables: to start another program,
said program is often found by checking each directory in the <code>PATH</code> environment
variable.</p>

<p>Such search paths are prevalent in scripting languages, too, to find
modules. Python has <code>PYTHONPATH</code>, Perl has <code>PERL5LIB</code>, and so on.</p>

<p>To set up these search path environment variables at run time, distri employs an
indirection. Instead of e.g. <code>teensy-loader-cli</code>, you run a small wrapper
program that calls precisely one <code>execve</code> system call with the desired
environment variables.</p>

<p>Initially, I used shell scripts as wrapper programs because they are easily
inspectable. This turned out to be too slow, so I switched to <a href="https://github.com/distr1/distri/blob/3ee4437f88605174fd82144381cfa726fc683ccb/internal/build/build.go#L1085-L1112">compiled
programs</a>. I’m
linking them statically for fast startup, and I’m linking them against <a href="https://musl.libc.org/">musl
libc</a> for significantly smaller file sizes than glibc
(per-executable overhead adds up quickly in a distribution!).</p>

<p>Note that the wrapper programs prepend to the <code>PATH</code> environment variable, they
don’t replace it in its entirely. This is important so that users have a way to
extend the <code>PATH</code> (and other variables) if they so choose. This doesn’t hurt
hermeticity because it is only relevant for programs that were not present at
build time, i.e. plugin mechanisms which, by design, cannot be hermetic.</p>

<h3 id="shebang-interpreter-patching">Shebang interpreter patching</h3>

<p>The <a href="https://en.wikipedia.org/wiki/Shebang_(Unix)">Shebang</a> of scripts contains
a path, too, and hence needs to be changed.</p>

<p><a href="https://github.com/distr1/distri/issues/67">We don’t do this in distri yet</a>
(the number of packaged scripts is small), but we should.</p>

<h3 id="performance-requirements">Performance requirements</h3>

<p>The performance improvements in the previous sections are not just good to have,
but practically required when many processes are involved: without them, you’ll
encounter second-long delays in <a href="https://magit.vc/">magit</a> which spawns many git
processes under the covers, or in
<a href="https://en.wikipedia.org/wiki/Dracut_(software)">dracut</a>, which spawns one
<code>cp(1)</code> process per file.</p>

<h2 id="downside-rebuild-of-packages-required-to-pick-up-changes">Downside: rebuild of packages required to pick up changes</h2>

<p>Linux distributions such as Debian consider it an advantage to roll out security
fixes to the entire system by updating a single shared library package
(e.g. <code>openssl</code>).</p>

<p>The flip side of that coin is that changes to a single critical package can
break the entire system.</p>

<p>With hermetic packages, all reverse dependencies must be rebuilt when a
library’s changes should be picked up by the whole system. E.g., when <code>openssl</code>
changes, <code>curl</code> must be rebuilt to pick up the new version of <code>openssl</code>.</p>

<p>This approach trades off using more bandwidth and more disk space (temporarily)
against reducing the blast radius of any individual package update.</p>

<h2 id="downside-long-env-variables-are-cumbersome-to-deal-with">Downside: long env variables are cumbersome to deal with</h2>

<p>This can be partially mitigated by <a href="https://github.com/distr1/distri/commit/6ac53cac4a5027622ae8622be2a208778dd54e74">removing empty directories at build
time</a>,
which will result in shorter variables.</p>

<p>In general, there is no getting around this. One little trick is to use <code>tr :
'\n'</code>, e.g.:</p>

<pre><code>distri0# echo $PATH
/usr/bin:/bin:/usr/sbin:/sbin:/ro/openssh-amd64-8.2p1-11/out/bin

distri0# echo $PATH | tr : '\n'
/usr/bin
/bin
/usr/sbin
/sbin
/ro/openssh-amd64-8.2p1-11/out/bin
</code></pre>

<h2 id="edge-cases">Edge cases</h2>

<p>The implementation outlined above works well in hundreds of packages, and only a
small handful exhibited problems of any kind. Here are some issues I encountered:</p>

<h3 id="issue-accidental-abi-breakage-in-plugin-mechanisms">Issue: accidental ABI breakage in plugin mechanisms</h3>

<p>NSS libraries built against glibc 2.28 and newer <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=928769">cannot be loaded by glibc
2.27</a>. In all
likelihood, such changes do not happen too often, but it does illustrate that
glibc’s <a href="https://www.gnu.org/software/libc/manual/html_node/Adding-another-Service-to-NSS.html#Adding-another-Service-to-NSS">published interface
spec</a>
is not sufficient for forwards and backwards compatibility.</p>

<p>In distri, we could likely use a per-package exchange directory for glibc’s NSS
mechanism to prevent the above problem from happening in the future.</p>

<h3 id="issue-wrapper-bypass-when-a-program-re-executes-itself">Issue: wrapper bypass when a program re-executes itself</h3>

<p>Some programs try to arrange for themselves to be re-executed outside of their
current process tree. For example, consider building a program with the <code>meson</code>
build system:</p>

<ol>
<li><p>When <code>meson</code> first configures the build, it generates <code>ninja</code> files (think
Makefiles) which contain command lines that run the <code>meson --internal</code>
helper.</p></li>

<li><p>Once <code>meson</code> returns, <code>ninja</code> is called as a separate process, so it will not
have the environment which the <code>meson</code> wrapper sets up. <code>ninja</code> then runs the
previously persisted <code>meson</code> command line. Since the command line uses the
full path to <code>meson</code> (not to its wrapper), it bypasses the wrapper.</p></li>
</ol>

<p>Luckily, not many programs try to arrange for other process trees to run
them. Here is a table summarizing how affected programs might try to arrange for
re-execution, whether the technique results in a wrapper bypass, and what we do
about it in distri:</p>

<table>
<thead>
<tr>
<th>technique to execute itself</th>
<th>uses wrapper</th>
<th>mitigation</th>
</tr>
</thead>

<tbody>
<tr>
<td>run-time: find own basename in <code>PATH</code></td>
<td>yes</td>
<td>wrapper program</td>
</tr>

<tr>
<td>compile-time: embed expected path</td>
<td>no; bypass!</td>
<td>configure or patch</td>
</tr>

<tr>
<td>run-time: <code>argv[0]</code> or <code>/proc/self/exe</code></td>
<td>no; bypass!</td>
<td><a href="https://github.com/distr1/distri/commit/f45ee9ac1121da284f2943c80e2c30afa24ca80d">patch</a></td>
</tr>
</tbody>
</table>

<p>One might think that setting <code>argv[0]</code> to the wrapper location seems like a way
to side-step this problem. We tried doing this in distri, but <a href="https://github.com/distr1/distri/commit/b517cb33ed827d358b00737434c7a09dd75583b7">had to
revert</a>
and <a href="https://github.com/distr1/distri/commit/9fd34936d4415f9963202bbb9ee454c970874b18">go the other
way</a>.</p>

<h3 id="misc-smaller-issues">Misc smaller issues</h3>

<ul>
<li>Login shells are <a href="https://unix.stackexchange.com/a/46856/181634">started by convention with a <code>-</code> character prepended to
<code>argv[0]</code></a>, so <a href="https://github.com/distr1/distri/commit/3c3a9d6ef4fc76edca6fb8351a716b18b83ff3af">shells like
bash or zsh cannot use wrapper
programs</a>.</li>
<li><a href="https://github.com/distr1/distri/commit/cefded2b2ce39407cc2d75936ec6cb018d533846">LDFLAGS leaked to
pkgconfig</a>
(<a href="https://github.com/distr1/distri/commit/434b7298ad7ef8d4ae229df84dd2353badf48fa1">upstream
reports</a>)</li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1635036">mozjs tries to run autoconf with the shell directly, but should use
autoconf’s wrapper</a></li>
</ul>

<h2 id="appendix-could-other-distributions-adopt-hermetic-packages">Appendix: Could other distributions adopt hermetic packages?</h2>

<p>At a very high level, adopting hermetic packages will require two steps:</p>

<ol>
<li><p>Using fully qualified paths whose contents don’t change
(e.g. <code>/ro/emacs-amd64-26.3-15</code>) generally requires rebuilding programs,
e.g. with <code>--prefix</code> set.</p></li>

<li><p>Once you use fully qualified paths you need to make the packages able to
exchange data. distri solves this with exchange directories, implemented in the
<code>/ro</code> file system which is backed by a FUSE daemon.</p></li>
</ol>

<p>The first step is pretty simple, whereas the second step is where I expect
controversy around any suggested mechanism.</p>

<h2 id="appendix-demo-in-distri">Appendix: demo (in distri)</h2>

<p>This appendix contains commands and their outputs, run on upcoming distri
version <code>supersilverhaze</code>, but verified to work on older versions, too.</p>

<p>Large outputs have been collapsed and can be expanded by clicking on the output.</p>

<p>The <code>/bin</code> directory contains symlinks for the union of all package’s <code>bin</code> subdirectories:
<details class="output" open><summary><code>distri0# readlink -f /bin/teensy_loader_cli</code></summary><pre><code>/ro/teensy-loader-cli-amd64-2.1+g20180927-7/bin/teensy_loader_cli</code></pre></details></p>

<p>The wrapper program in the <code>bin</code> subdirectory is small:
<details class="output" open><summary><code>distri0# ls -lh $(readlink -f /bin/teensy_loader_cli)</code></summary><pre><code>-rwxr-xr-x 1 root root 46K Apr 21 21:56 /ro/teensy-loader-cli-amd64-2.1+g20180927-7/bin/teensy_loader_cli</code></pre></details></p>

<p>Wrapper programs execute quickly:
<details class="output"><summary><code>distri0# strace -fvy /bin/teensy_loader_cli |&amp; head | cat -n</code></summary><pre><code>     1  execve(&quot;/bin/teensy_loader_cli&quot;, [&quot;/bin/teensy_loader_cli&quot;], [&quot;USER=root&quot;, &quot;LOGNAME=root&quot;, &quot;HOME=/root&quot;, &quot;PATH=/ro/bash-amd64-5.0-4/bin:/r&quot;..., &quot;SHELL=/bin/zsh&quot;, &quot;TERM=screen.xterm-256color&quot;, &quot;XDG_SESSION_ID=c1&quot;, &quot;XDG_RUNTIME_DIR=/run/user/0&quot;, &quot;DBUS_SESSION_BUS_ADDRESS=unix:pa&quot;..., &quot;XDG_SESSION_TYPE=tty&quot;, &quot;XDG_SESSION_CLASS=user&quot;, &quot;SSH_CLIENT=10.0.2.2 42556 22&quot;, &quot;SSH_CONNECTION=10.0.2.2 42556 10&quot;..., &quot;SSH<em>TTY=/dev/pts/0&quot;, &quot;SHLVL=1&quot;, &quot;PWD=/root&quot;, &quot;OLDPWD=/root&quot;, &quot;</em>=/usr/bin/strace&quot;, &quot;LD_LIBRARY_PATH=/ro/bash-amd64-5&quot;..., &quot;PERL5LIB=/ro/bash-amd64-5.0-4/ou&quot;..., &quot;PYTHONPATH=/ro/bash-amd64-5.b0-4/&quot;...]) = 0
     2  arch_prctl(ARCH_SET_FS, 0x40c878)       = 0
     3  set_tid_address(0x40ca9c)               = 715
     4  brk(NULL)                               = 0x15b9000
     5  brk(0x15ba000)                          = 0x15ba000
     6  brk(0x15bb000)                          = 0x15bb000
     7  brk(0x15bd000)                          = 0x15bd000
     8  brk(0x15bf000)                          = 0x15bf000
     9  brk(0x15c1000)                          = 0x15c1000
    10  execve(&quot;/ro/teensy-loader-cli-amd64-2.1+g20180927-7/out/bin/teensy_loader_cli&quot;, [&quot;/ro/teensy-loader-cli-amd64-2.1+&quot;...], [&quot;USER=root&quot;, &quot;LOGNAME=root&quot;, &quot;HOME=/root&quot;, &quot;PATH=/ro/bash-amd64-5.0-4/bin:/r&quot;..., &quot;SHELL=/bin/zsh&quot;, &quot;TERM=screen.xterm-256color&quot;, &quot;XDG_SESSION_ID=c1&quot;, &quot;XDG_RUNTIME_DIR=/run/user/0&quot;, &quot;DBUS_SESSION_BUS_ADDRESS=unix:pa&quot;..., &quot;XDG_SESSION_TYPE=tty&quot;, &quot;XDG_SESSION_CLASS=user&quot;, &quot;SSH_CLIENT=10.0.2.2 42556 22&quot;, &quot;SSH_CONNECTION=10.0.2.2 42556 10&quot;..., &quot;SSH<em>TTY=/dev/pts/0&quot;, &quot;SHLVL=1&quot;, &quot;PWD=/root&quot;, &quot;OLDPWD=/root&quot;, &quot;</em>=/usr/bin/strace&quot;, &quot;LD_LIBRARY_PATH=/ro/bash-amd64-5&quot;..., &quot;PERL5LIB=/ro/bash-amd64-5.0-4/ou&quot;..., &quot;PYTHONPATH=/ro/bash-amd64-5.0-4/&quot;...]) = 0</code></pre></details></p>

<p>Confirm which ELF interpreter is set for a binary using <code>readelf(1)</code>:
<details class="output" open><summary><code>distri0# readelf -a /ro/teensy-loader-cli-amd64-2.1+g20180927-7/out/bin/teensy_loader_cli | grep 'program interpreter'</code></summary><pre><code>[Requesting program interpreter: /ro/glibc-amd64-2.31-4/out/lib/ld-linux-x86-64.so.2]</code></pre></details></p>

<p>Confirm the rpath is set to the package’s lib subdirectory using <code>readelf(1)</code>:
<details class="output" open><summary><code>distri0# readelf -a /ro/teensy-loader-cli-amd64-2.1+g20180927-7/out/bin/teensy_loader_cli | grep RPATH</code></summary><pre><code> 0x000000000000000f (RPATH)              Library rpath: [/ro/teensy-loader-cli-amd64-2.1+g20180927-7/lib]</code></pre></details></p>

<p>…and verify the lib subdirectory has the expected symlinks and target versions:
<details class="output"><summary><code>distri0# find /ro/teensy-loader-cli-amd64-*/lib -type f -printf '%P -&gt; %l\n'</code><pre>libc.so.6 -&gt; /ro/glibc-amd64-2.31-4/out/lib/libc-2.31.so</pre></summary><pre><code>libpthread.so.0 -&gt; /ro/glibc-amd64-2.31-4/out/lib/libpthread-2.31.so
librt.so.1 -&gt; /ro/glibc-amd64-2.31-4/out/lib/librt-2.31.so
libudev.so.1 -&gt; /ro/libudev-amd64-245-11/out/lib/libudev.so.1.6.17
libusb-0.1.so.4 -&gt; /ro/libusb-compat-amd64-0.1.5-7/out/lib/libusb-0.1.so.4.4.4
libusb-1.0.so.0 -&gt; /ro/libusb-amd64-1.0.23-8/out/lib/libusb-1.0.so.0.2.0</code></pre></details></p>

<p>To verify the correct libraries are actually loaded, you can set the <code>LD_DEBUG</code>
environment variable for <code>ld.so(8)</code>:</p>

<p><details class="output"><summary><code>distri0# LD_DEBUG=libs teensy_loader_cli</code></summary><pre><code>[…]
       678:     find library=libc.so.6 [0]; searching
       678:      search path=/ro/teensy-loader-cli-amd64-2.1+g20180927-7/lib            (RPATH from file /ro/teensy-loader-cli-amd64-2.1+g20180927-7/out/bin/teensy_loader_cli)
       678:       trying file=/ro/teensy-loader-cli-amd64-2.1+g20180927-7/lib/libc.so.6
       678:
[…]</code></pre></details></p>

<p>NSS libraries that distri ships:
<details class="output"><summary><code>find /lib/ -name &quot;libnss_*.so.2&quot; -type f -printf '%P -&gt; %l\n'</code><pre>libnss_myhostname.so.2 -&gt; ../systemd-amd64-245-11/out/lib/libnss_myhostname.so.2</pre></summary><pre><code>libnss_mymachines.so.2 -&gt; ../systemd-amd64-245-11/out/lib/libnss_mymachines.so.2
libnss_resolve.so.2 -&gt; ../systemd-amd64-245-11/out/lib/libnss_resolve.so.2
libnss_systemd.so.2 -&gt; ../systemd-amd64-245-11/out/lib/libnss_systemd.so.2
libnss_compat.so.2 -&gt; ../glibc-amd64-2.31-4/out/lib/libnss_compat.so.2
libnss_db.so.2 -&gt; ../glibc-amd64-2.31-4/out/lib/libnss_db.so.2
libnss_dns.so.2 -&gt; ../glibc-amd64-2.31-4/out/lib/libnss_dns.so.2
libnss_files.so.2 -&gt; ../glibc-amd64-2.31-4/out/lib/libnss_files.so.2
libnss_hesiod.so.2 -&gt; ../glibc-amd64-2.31-4/out/lib/libnss_hesiod.so.2</code></pre></details></p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Readiness notifications in Go]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-02-02-readiness-notifications-in-golang/"/>
    <id>https://michael.stapelberg.ch/posts/2020-02-02-readiness-notifications-in-golang/</id>
    <published>2020-02-02T00:00:00+00:00</published>
    <updated>2020-08-12T10:08:02+02:00</updated>
    <content type="html"><![CDATA[

<p>When spawning a child program, for example in an integration test, it is often
helpful to know when the child program is ready to receive requests.</p>

<h3 id="delaying">Delaying</h3>

<p>A brittle strategy is to just add a delay (say, <code>time.Sleep(2 * time.Second)</code>)
and hope the child program finishes initialization in that time. This is brittle
because it depends on timing, so when the computer running the test is slow for
whichever reason, your test starts failing. Many CI/CD systems have less
capacity (and/or are more heavily utilized) than developer machines, so timeouts
frequently need to be adjusted.</p>

<p>Also, relying on timing is a race to the bottom: your delay needs to work on the
slowest machine that runs your code. Ergo, tests waste valuable developer time
on your high-end workstation, just so that they pass on some under-powered
machine.</p>

<h3 id="polling">Polling</h3>

<p>A slightly better strategy is polling, i.e. repeatedly checking whether the
child program is ready. As an example, in the <code>dnsmasq_exporter</code> test, <a href="https://github.com/google/dnsmasq_exporter/blob/646ded9be82e26a4c6450da8d7128d12e0e11e3a/dnsmasq_test.go#L46-L61">I need
to
poll</a>
to find out when <a href="https://manpages.debian.org/dnsmasq.8"><code>dnsmasq(8)</code></a>
 is ready.</p>

<p>This approach is better because it automatically works well on both high-end and
under-powered machines, without wasting time on either.</p>

<p>Finding a good frequency with which to poll is a bit of an art, though: the more
often you poll, the less time you waste, but also the more resources you spend
on polling instead of letting your program initialize. The overhead may be
barely noticeable, but when starting lots of programs (e.g. in a microservice
architecture) or when individual polls are costly, the overhead can add up.</p>

<h3 id="readiness-notifications">Readiness notifications</h3>

<p>The most elegant approach is to use readiness notifications: you don’t waste any
time or resources.</p>

<p>It only takes a few lines of code to integrate this approach into your
application. The specifics might vary depending on your environment,
e.g. whether an environment variable is preferable to a command-line flag; my
goal with this article is to explain the approach in general, and you can take
care of the details.</p>

<p>The key idea is: the child program inherits a pipe file descriptor from the
parent and closes it once ready. The parent program knows the child program is
ready because an otherwise blocking read from the pipe returns once the pipe is
closed.</p>

<p>This is similar to using a <code>chan struct{}</code> in Go and closing it. It doesn’t have
to remain this simple, though: you can also send arbitrary data over the pipe,
ranging from a simple string being sent in one direction and culminating in
speaking a framed protocol in a client/server fashion. In <a href="https://codesearch.debian.net/">Debian Code
Search</a>, I’m <a href="https://github.com/Debian/dcs/blob/3baaecabca2d6c56799012c40c1245fc389cb6e6/internal/addrfd/addrfd.go">writing the chosen network
address</a>
before closing the pipe, so that the parent program knows where to connect to.</p>

<h4 id="parent-program">Parent Program</h4>

<p>So, how do we go about readiness notifications in Go? We create a new pipe and
specify the write end in the <code>ExtraFiles</code> field of <code>(os/exec).Cmd</code>:</p>

<pre><code>r, w, err := os.Pipe()
if err != nil {
  return err
}

child := exec.Command(&quot;child&quot;)
child.Stderr = os.Stderr
child.ExtraFiles = []*os.File{w}
</code></pre>

<p>It is good practice to explicitly specify the file descriptor number that we
passed via some sort of signaling, so that the child program does not need to be
modified when we add new file descriptors in the parent, and also because this
behavior is usually opt-in.</p>

<p>In this case, we’ll do that via an environment variable and start the child
program:</p>

<pre><code>// Go dup2()’s ExtraFiles to file descriptor 3 and counting.
// File descriptors 0, 1, 2 are stdin, stdout and stderr.
child.Env = append(os.Environ(), &quot;CHILD_READY_FD=3&quot;)

// Note child.Start(), not child.Run():
if err := child.Start(); err != nil {
  return fmt.Errorf(&quot;%v: %v&quot;, child.Args, err)
}
</code></pre>

<p>At this point, both the parent and the child process have a file descriptor
referencing the write end of the pipe. Since the pipe will only be closed once
<em>all</em> processes have closed the write end, we need to close the write end in the
parent program:</p>

<pre><code>// Close the write end of the pipe in the parent:
w.Close()
</code></pre>

<p>Now, we can blockingly read from the pipe, and know that once the read call
returns, the child program is ready to receive requests:</p>

<pre><code>// Avoid hanging forever in case the child program never becomes ready;
// this is easier to diagnose than an unspecified CI/CD test timeout.
// This timeout should be much much longer than initialization takes.
r.SetReadDeadline(time.Now().Add(1 * time.Minute))
if _, err := ioutil.ReadAll(r); err != nil {
  return fmt.Errorf(&quot;awaiting readiness: %v&quot;, err)
}

// …send requests…

// …tear down child program…
</code></pre>

<h4 id="child-program">Child Program</h4>

<p>In the child program, we need to recognize that the parent program requests a
readiness notification, and ensure our signaling doesn’t leak to child programs
of the child program:</p>

<pre><code>var readyFile *os.File

func init() {
  if fd, err := strconv.Atoi(os.Getenv(&quot;CHILD_READY_FD&quot;)); err == nil {
    readyFile = os.NewFile(uintptr(fd), &quot;readyfd&quot;)
    os.Unsetenv(&quot;CHILD_READY_FD&quot;)
  }
}

func main() {
  // …initialize…

  if readyFile != nil {
    readyFile.Close() // signal readiness
    readyFile = nil   // just to be prudent
  }
}
</code></pre>

<h3 id="conclusion">Conclusion</h3>

<p>Depending on what you’re communicating from the child to the parent, and how
your system is architected, it might be a good idea to use <a href="http://0pointer.de/blog/projects/socket-activation.html">systemd socket
activation</a> (<a href="https://vincent.bernat.ch/en/blog/2018-systemd-golang-socket-activation">socket
activation in
Go</a>). It
works similarly in concept, but passes a listening socket and readiness is
determined by the child process answering requests. We introduced this technique
in the <a href="https://i3wm.org/docs/testsuite.html#_appendix_b_socket_activation">i3
testsuite</a>
and reduced the total wallclock time from &gt;100 seconds to a mere 16 seconds back
then (even faster today).</p>

<p>The technique described in this blog post is a bit more generic than systemd’s
socket activation. In general, passing file descriptors between processes is a
powerful idea. For example, in debiman, we’re <a href="https://github.com/Debian/debiman/blob/32eac1bc6182f68c7443a56b85c33522dc3d5d70/internal/convert/mandoc.go#L118">passing individual pipe file
descriptors</a>
to a persistent <a href="https://manpages.debian.org/mandocd.8"><code>mandocd(8)</code></a>
 process to quickly
convert lots of man pages without encurring process creation overhead.</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[distri: 20x faster initramfs (initrd) from scratch]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-01-21-initramfs-from-scratch-golang/"/>
    <id>https://michael.stapelberg.ch/posts/2020-01-21-initramfs-from-scratch-golang/</id>
    <published>2020-01-21T17:50:00+01:00</published>
    <updated>2020-08-12T10:08:02+02:00</updated>
    <content type="html"><![CDATA[

<p>In case you are not yet familiar with why an initramfs (or initrd, or initial
ramdisk) is typically used when starting Linux, let me quote the <a href="https://en.wikipedia.org/wiki/Initial_ramdisk">wikipedia
definition</a>:</p>

<p>“[…] initrd is a scheme for loading a temporary root file system into memory,
which may be used as part of the Linux startup process […] to make preparations
before the real root file system can be mounted.”</p>

<p>Many Linux distributions do not compile all file system drivers into the kernel,
but instead load them on-demand from an initramfs, which saves memory.</p>

<p>Another common scenario, in which an initramfs is required, is full-disk
encryption: the disk must be unlocked from userspace, but since userspace is
encrypted, an initramfs is used.</p>

<h2 id="motivation">Motivation</h2>

<p>Thus far, building a <a href="https://distr1.org/">distri</a> disk image was quite slow:</p>

<p>This is on an AMD Ryzen 3900X 12-core processor (2019):</p>

<pre><code>distri % time make cryptimage serial=1
80.29s user 13.56s system 186% cpu 50.419 total # 19s image, 31s initrd
</code></pre>

<p>Of these 50 seconds,
<a href="https://en.wikipedia.org/wiki/Dracut_(software)"><code>dracut</code></a>’s initramfs
generation accounts for 31 seconds (62%)!</p>

<p>Initramfs generation time drops to 8.7 seconds once <code>dracut</code> no longer needs to
use the single-threaded <a href="https://manpages.debian.org/gzip.1"><code>gzip(1)</code></a>
, but the
multi-threaded replacement <a href="https://manpages.debian.org/pigz.1"><code>pigz(1)</code></a>
:</p>

<p>This brings the total time to build a distri disk image down to:</p>

<pre><code>distri % time make cryptimage serial=1
76.85s user 13.23s system 327% cpu 27.509 total # 19s image, 8.7s initrd
</code></pre>

<p>Clearly, when you use <code>dracut</code> on any modern computer, you should make pigz
available. <code>dracut</code> should fail to compile unless one explicitly opts into the
known-slower gzip. For more thoughts on optional dependencies, see <a href="/posts/2019-05-23-optional-dependencies/">“Optional
dependencies don’t work”</a>.</p>

<p>But why does it take 8.7 seconds still? Can we go faster?</p>

<p>The answer is <strong>Yes</strong>! I recently built a distri-specific initramfs I’m calling
<code>minitrd</code>. I wrote both big parts from scratch:</p>

<ol>
<li>the initramfs generator program (<a href="https://github.com/distr1/distri/blob/master/cmd/distri/initrd.go"><code>distri initrd</code></a>)</li>
<li>a custom Go userland (<a href="https://github.com/distr1/distri/blob/master/cmd/minitrd/minitrd.go"><code>cmd/minitrd</code></a>), running as <code>/init</code> in the initramfs.</li>
</ol>

<p><code>minitrd</code> generates the initramfs image in ≈400ms, bringing the total time down
to:</p>

<pre><code>distri % time make cryptimage serial=1
50.09s user 8.80s system 314% cpu 18.739 total # 18s image, 400ms initrd
</code></pre>

<p>(The remaining time is spent in preparing the file system, then installing and
configuring the distri system, i.e. preparing a disk image you can <a href="https://distr1.org/#run-distri-on-real-hardware">run on real
hardware</a>.)</p>

<p>How can <code>minitrd</code> be 20 times faster than <code>dracut</code>?</p>

<p><code>dracut</code> is mainly written in shell, with a C helper program. It drives the
generation process by spawning lots of external dependencies (e.g. <code>ldd</code> or the
<code>dracut-install</code> helper program). I assume that the combination of using an
interpreted language (shell) that spawns lots of processes and precludes a
concurrent architecture is to blame for the poor performance.</p>

<p><code>minitrd</code> is written in Go, with speed as a goal. It leverages concurrency and
uses no external dependencies; everything happens within a single process (but
with enough threads to saturate modern hardware).</p>

<p>Measuring early boot time using qemu, I measured the <code>dracut</code>-generated
initramfs taking 588ms to display the full disk encryption passphrase prompt,
whereas <code>minitrd</code> took only 195ms.</p>

<p>The rest of this article dives deeper into how <code>minitrd</code> works.</p>

<h2 id="what-does-an-initramfs-do">What does an initramfs do?</h2>

<p>Ultimately, the job of an initramfs is to make the root file system available
and continue booting the system from there. Depending on the system setup, this
involves the following 5 steps:</p>

<h3 id="1-load-kernel-modules-to-access-the-block-devices-with-the-root-file-system">1. Load kernel modules to access the block devices with the root file system</h3>

<p>Depending on the system, the block devices with the root file system might
already be present when the initramfs runs, or some kernel modules might need to
be loaded first. On my Dell XPS 9360 laptop, the NVMe system disk is already
present when the initramfs starts, whereas in qemu, we need to load the
<code>virtio_pci</code> module, followed by the <code>virtio_scsi</code> module.</p>

<p>How will our userland program know which kernel modules to load? Linux kernel
modules declare patterns for their supported hardware as an alias, e.g.:</p>

<pre><code>initrd# grep virtio_pci lib/modules/5.4.6/modules.alias
alias pci:v00001AF4d*sv*sd*bc*sc*i* virtio_pci
</code></pre>

<p>Devices in <code>sysfs</code> have a <code>modalias</code> file whose content can be matched against
these declarations to identify the module to load:</p>

<pre><code>initrd# cat /sys/devices/pci0000:00/*/modalias
pci:v00001AF4d00001005sv00001AF4sd00000004bc00scFFi00
pci:v00001AF4d00001004sv00001AF4sd00000008bc01sc00i00
[…]
</code></pre>

<p>Hence, for the initial round of module loading, it is sufficient to locate all
<code>modalias</code> files within <code>sysfs</code> and load the responsible modules.</p>

<p>Loading a kernel module can result in new devices appearing. When that happens,
the kernel sends a
<a href="https://stackoverflow.com/questions/22803469/uevent-sent-from-kernel-to-user-space-udev">uevent</a>,
which the uevent consumer in userspace receives via a netlink socket. Typically,
this consumer is <a href="https://manpages.debian.org/udev.7"><code>udev(7)</code></a>
, but in our case, it’s
<code>minitrd</code>.</p>

<p>For each uevent messages that comes with a <code>MODALIAS</code> variable, <code>minitrd</code> will
load the relevant kernel module(s).</p>

<p>When loading a kernel module, its dependencies need to be loaded
first. Dependency information is stored in the <code>modules.dep</code> file in a
<code>Makefile</code>-like syntax:</p>

<pre><code>initrd# grep virtio_pci lib/modules/5.4.6/modules.dep
kernel/drivers/virtio/virtio_pci.ko: kernel/drivers/virtio/virtio_ring.ko kernel/drivers/virtio/virtio.ko
</code></pre>

<p>To load a module, we can open its file and then call the Linux-specific <a href="https://manpages.debian.org/finit_module.2"><code>finit_module(2)</code></a>
 system call. Some modules are expected to
return an error code, e.g. <code>ENODEV</code> or <code>ENOENT</code> when some hardware device is not
actually present.</p>

<p>Side note: next to the textual versions, there are also binary versions of the
<code>modules.alias</code> and <code>modules.dep</code> files. Presumably, those can be queried more
quickly, but for simplicitly, I have not (yet?) implemented support in
<code>minitrd</code>.</p>

<h3 id="2-console-settings-font-keyboard-layout">2. Console settings: font, keyboard layout</h3>

<p>Setting a legible font is necessary for hi-dpi displays. On my Dell XPS 9360
(3200 x 1800 QHD+ display), the following works well:</p>

<pre><code>initrd# setfont latarcyrheb-sun32
</code></pre>

<p>Setting the user’s keyboard layout is necessary for entering the LUKS full-disk
encryption passphrase in their preferred keyboard layout. I use the <a href="https://www.neo-layout.org">NEO
layout</a>:</p>

<pre><code>initrd# loadkeys neo
</code></pre>

<h3 id="3-block-device-identification">3. Block device identification</h3>

<p>In the Linux kernel, block device enumeration order is not necessarily the same
on each boot. Even if it was deterministic, device order could still be changed
when users modify their computer’s device topology (e.g. connect a new disk to a
formerly unused port).</p>

<p>Hence, it is good style to refer to disks and their partitions with stable
identifiers. This also applies to boot loader configuration, and so most
distributions will set a kernel parameter such as
<code>root=UUID=1fa04de7-30a9-4183-93e9-1b0061567121</code>.</p>

<p>Identifying the block device or partition with the specified <code>UUID</code> is the
initramfs’s job.</p>

<p>Depending on what the device contains, the UUID comes from a different
place. For example, <code>ext4</code> file systems have a UUID field in their file system
superblock, whereas LUKS volumes have a UUID in their LUKS header.</p>

<p>Canonically, probing a device to extract the UUID is done by <code>libblkid</code> from the
<code>util-linux</code> package, but the logic can easily be <a href="https://github.com/distr1/distri/blob/master/cmd/minitrd/blkid.go">re-implemented in other
languages</a>
and changes rarely. <code>minitrd</code> comes with its own implementation to avoid
<a href="https://golang.org/cmd/cgo/">cgo</a> or running the <a href="https://manpages.debian.org/blkid.8"><code>blkid(8)</code></a>
 program.</p>

<h3 id="4-luks-full-disk-encryption-unlocking-only-on-encrypted-systems">4. LUKS full-disk encryption unlocking (only on encrypted systems)</h3>

<p>Unlocking a
<a href="https://en.wikipedia.org/wiki/Linux_Unified_Key_Setup">LUKS</a>-encrypted volume
is done in userspace. The kernel handles the crypto, but reading the metadata,
obtaining the passphrase (or e.g. key material from a file) and setting up the
device mapper table entries are done in user space.</p>

<pre><code>initrd# modprobe algif_skcipher
initrd# cryptsetup luksOpen /dev/sda4 cryptroot1
</code></pre>

<p>After the user entered their passphrase, the root file system can be mounted:</p>

<pre><code>initrd# mount /dev/dm-0 /mnt
</code></pre>

<h3 id="5-continuing-the-boot-process-switch-root">5. Continuing the boot process (switch_root)</h3>

<p>Now that everything is set up, we need to pass execution to the init program on
the root file system with a careful sequence of <a href="https://manpages.debian.org/chdir.2"><code>chdir(2)</code></a>
, <a href="https://manpages.debian.org/mount.2"><code>mount(2)</code></a>
, <a href="https://manpages.debian.org/chroot.2"><code>chroot(2)</code></a>
, <a href="https://manpages.debian.org/chdir.2"><code>chdir(2)</code></a>
 and <a href="https://manpages.debian.org/execve.2"><code>execve(2)</code></a>
 system calls that is explained in <a href="https://github.com/mirror/busybox/blob/9ec836c033fc6e55e80f3309b3e05acdf09bb297/util-linux/switch_root.c#L297">this busybox switch_root
comment</a>.</p>

<pre><code>initrd# mount -t devtmpfs dev /mnt/dev
initrd# exec switch_root -c /dev/console /mnt /init
</code></pre>

<p>To conserve RAM, the files in the temporary file system to which the initramfs
archive is extracted are typically deleted.</p>

<h2 id="how-is-an-initramfs-generated">How is an initramfs generated?</h2>

<p>An initramfs “image” (more accurately: archive) is a compressed
<a href="https://en.wikipedia.org/wiki/Cpio">cpio</a> archive. Typically, gzip compression
is used, but the kernel supports a bunch of different algorithms and
distributions such as <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=LZ4-Initramfs-Ubuntu-Go-Ahead">Ubuntu are switching to lz4</a>.</p>

<p>Generators typically prepare a temporary directory and feed it to the <a href="https://manpages.debian.org/cpio.1"><code>cpio(1)</code></a>
 program. In <code>minitrd</code>, we read the files into memory
and generate the cpio archive using the
<a href="https://github.com/cavaliercoder/go-cpio">go-cpio</a> package. We use the
<a href="https://github.com/klauspost/pgzip">pgzip</a> package for parallel gzip
compression.</p>

<p>The following files need to go into the cpio archive:</p>

<h3 id="minitrd-go-userland">minitrd Go userland</h3>

<p>The <code>minitrd</code> binary is copied into the cpio archive as <code>/init</code> and will be run
by the kernel after extracting the archive.</p>

<p>Like the rest of distri, <code>minitrd</code> is built statically without cgo, which means
it can be copied as-is into the cpio archive.</p>

<h3 id="linux-kernel-modules">Linux kernel modules</h3>

<p>Aside from the <code>modules.alias</code> and <code>modules.dep</code> metadata files, the kernel
modules themselves reside in e.g. <code>/lib/modules/5.4.6/kernel</code> and need to be
copied into the cpio archive.</p>

<p>Copying all modules results in a ≈80 MiB archive, so it is common to only copy
modules that are relevant to the initramfs’s features. This reduces archive size
to ≈24 MiB.</p>

<p>The filtering relies on hard-coded patterns and module names. For example, disk
encryption related modules are all kernel modules underneath <code>kernel/crypto</code>,
plus <code>kernel/drivers/md/dm-crypt.ko</code>.</p>

<p>When generating a host-only initramfs (works on precisely the computer that
generated it), some initramfs generators look at the currently loaded modules
and just copy those.</p>

<h3 id="console-fonts-and-keymaps">Console Fonts and Keymaps</h3>

<p>The <code>kbd</code> package’s <a href="https://manpages.debian.org/setfont.8"><code>setfont(8)</code></a>
 and <a href="https://manpages.debian.org/loadkeys.1"><code>loadkeys(1)</code></a>
 programs load console fonts and keymaps from
<code>/usr/share/consolefonts</code> and <code>/usr/share/keymaps</code>, respectively.</p>

<p>Hence, these directories need to be copied into the cpio archive. Depending on
whether the initramfs should be generic (work on many computers) or host-only
(works on precisely the computer/settings that generated it), the entire
directories are copied, or only the required font/keymap.</p>

<h3 id="cryptsetup-setfont-loadkeys">cryptsetup, setfont, loadkeys</h3>

<p>These programs are (currently) required because <code>minitrd</code> does not implement
their functionality.</p>

<p>As they are dynamically linked, not only the programs themselves need to be
copied, but also the ELF dynamic linking loader (path stored in the <code>.interp</code>
ELF section) and any ELF library dependencies.</p>

<p>For example, <code>cryptsetup</code> in distri declares the ELF interpreter
<code>/ro/glibc-amd64-2.27-3/out/lib/ld-linux-x86-64.so.2</code> and declares dependencies
on shared libraries <code>libcryptsetup.so.12</code>, <code>libblkid.so.1</code> and others. Luckily,
in distri, packages contain a <code>lib</code> subdirectory containing symbolic links to
the resolved shared library paths (hermetic packaging), so it is sufficient to
mirror the lib directory into the cpio archive, recursing into shared library
dependencies of shared libraries.</p>

<p><code>cryptsetup</code> also requires the GCC runtime library <code>libgcc_s.so.1</code> to be present
at runtime, and will abort with an error message about not being able to call
<a href="https://manpages.debian.org/pthread_cancel.3"><code>pthread_cancel(3)</code></a>
 if it is unavailable.</p>

<h3 id="time-zone-data">time zone data</h3>

<p>To print log messages in the correct time zone, we copy <code>/etc/localtime</code> from
the host into the cpio archive.</p>

<h2 id="minitrd-outside-of-distri">minitrd outside of distri?</h2>

<p>I currently have no desire to make <code>minitrd</code> available outside of
<a href="https://distr1.org/">distri</a>. While the technical challenges (such as extending
the generator to not rely on distri’s hermetic packages) are surmountable, I
don’t want to support people’s initramfs remotely.</p>

<p>Also, I think that people’s efforts should in general be spent on rallying
behind <code>dracut</code> and making it work faster, thereby benefiting all Linux
distributions that use dracut (increasingly more). With <code>minitrd</code>, I have
demonstrated that significant speed-ups are achievable.</p>

<h2 id="conclusion">Conclusion</h2>

<p>It was interesting to dive into how an initramfs really works. I had been
working with the concept for many years, from small tasks such as “debug why the
encrypted root file system is not unlocked” to more complicated tasks such as
“set up a root file system on DRBD for a high-availability setup”. But even with
that sort of experience, I didn’t know all the details, until I was forced to
implement every little thing.</p>

<p>As I suspected going into this exercise, <code>dracut</code> is much slower than it needs
to be. Re-implementing its generation stage in a modern language instead of
shell helps a lot.</p>

<p>Of course, my <code>minitrd</code> does a bit less than <code>dracut</code>, but not drastically
so. The overall architecture is the same.</p>

<p>I hope my effort helps with two things:</p>

<ol>
<li><p>As a teaching implementation: instead of wading through the various
components that make up a modern initramfs (udev, systemd, various shell
scripts, …), people can learn about how an initramfs works in a single place.</p></li>

<li><p>I hope the significant time difference motivates people to improve <code>dracut</code>.</p></li>
</ol>

<h2 id="appendix-qemu-development-environment">Appendix: qemu development environment</h2>

<p>Before writing any Go code, I did some manual prototyping. Learning how other
people prototype is often immensely useful to me, so I’m sharing my notes here.</p>

<p>First, I copied all kernel modules and a statically built busybox binary:</p>

<pre><code>% mkdir -p lib/modules/5.4.6
% cp -Lr /ro/lib/modules/5.4.6/* lib/modules/5.4.6/
% cp ~/busybox-1.22.0-amd64/busybox sh
</code></pre>

<p>To generate an initramfs from the current directory, I used:</p>

<pre><code>% find . | cpio -o -H newc | pigz &gt; /tmp/initrd
</code></pre>

<p>In distri’s <code>Makefile</code>, I append these flags to the <code>QEMU</code> invocation:</p>

<pre><code>-kernel /tmp/kernel \
-initrd /tmp/initrd \
-append &quot;root=/dev/mapper/cryptroot1 rdinit=/sh ro console=ttyS0,115200 rd.luks=1 rd.luks.uuid=63051f8a-54b9-4996-b94f-3cf105af2900 rd.luks.name=63051f8a-54b9-4996-b94f-3cf105af2900=cryptroot1 rd.vconsole.keymap=neo rd.vconsole.font=latarcyrheb-sun32 init=/init systemd.setenv=PATH=/bin rw vga=836&quot;
</code></pre>

<p>The <code>vga=</code> mode parameter is required for loading font <code>latarcyrheb-sun32</code>.</p>

<p>Once in the <code>busybox</code> shell, I manually prepared the required mount points and
kernel modules:</p>

<pre><code>ln -s sh mount
ln -s sh lsmod
mkdir /proc /sys /run /mnt
mount -t proc proc /proc
mount -t sysfs sys /sys
mount -t devtmpfs dev /dev
modprobe virtio_pci
modprobe virtio_scsi
</code></pre>

<p>As a next step, I copied <code>cryptsetup</code> and dependencies into the initramfs directory:</p>

<pre><code>% for f in /ro/cryptsetup-amd64-2.0.4-6/lib/*; do full=$(readlink -f $f); rel=$(echo $full | sed 's,^/,,g'); mkdir -p $(dirname $rel); install $full $rel; done
% ln -s ld-2.27.so ro/glibc-amd64-2.27-3/out/lib/ld-linux-x86-64.so.2
% cp /ro/glibc-amd64-2.27-3/out/lib/ld-2.27.so ro/glibc-amd64-2.27-3/out/lib/ld-2.27.so
% cp -r /ro/cryptsetup-amd64-2.0.4-6/lib ro/cryptsetup-amd64-2.0.4-6/
% mkdir -p ro/gcc-libs-amd64-8.2.0-3/out/lib64/
% cp /ro/gcc-libs-amd64-8.2.0-3/out/lib64/libgcc_s.so.1 ro/gcc-libs-amd64-8.2.0-3/out/lib64/libgcc_s.so.1
% ln -s /ro/gcc-libs-amd64-8.2.0-3/out/lib64/libgcc_s.so.1 ro/cryptsetup-amd64-2.0.4-6/lib
% cp -r /ro/lvm2-amd64-2.03.00-6/lib ro/lvm2-amd64-2.03.00-6/
</code></pre>

<p>In <code>busybox</code>, I used the following commands to unlock the root file system:</p>

<pre><code>modprobe algif_skcipher
./cryptsetup luksOpen /dev/sda4 cryptroot1
mount /dev/dm-0 /mnt
</code></pre>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Network Storage PC Hardware (2019)]]></title>
    <link href="https://michael.stapelberg.ch/posts/2019-10-23-nas/"/>
    <id>https://michael.stapelberg.ch/posts/2019-10-23-nas/</id>
    <published>2019-10-23T00:00:00+00:00</published>
    <updated>2020-08-12T10:08:02+02:00</updated>
    <content type="html"><![CDATA[

<p>One of my two NAS builds recently died, so I bought a new one until I find some
time to debug the old one. Since a couple of people have been asking me what I
would recommend nowadays based on my <a href="/posts/2016-11-21-gigabit-nas-coreos/">November 2016 article “Gigabit NAS
(running CoreOS)”</a>, I figured I would
share the new hardware listing:</p>

<table width="100%" style="margin-top: 1.5em; margin-bottom: 1.5em; margin-left: 2em">
<tr>
<th>Price</th>
<th>Type</th>
<th>Article</th>
</tr>

<tr>
<td>54.00 CHF</td>
<td>Case</td>
<td><a href="https://www.digitec.ch/en/s1/product/silverstone-sst-sg05bb-lite-cube-pc-cases-3525365">Silverstone SST-SG05BB-Lite (cube)</a></td>
</tr>

<tr>
<td valign="top">60.40 CHF</td>
<td valign="top">Mainboard</td>
<td><a href="https://www.digitec.ch/en/s1/product/asrock-ab350-gaming-itxac-am4-amd-b350-mini-itx-motherboards-7022839">AsRock AB350 Gaming-ITX/ac (AM4, AMD B350, Mini ITX)</a><br>
<strong>Be sure to <a href="https://www.asrock.com/MB/AMD/Fatal1ty%20AB350%20Gaming-ITXac/index.asp#BIOS">update the UEFI</a> to the latest version (6.00)!</strong></td>
</tr>

<tr>
<td>62.30 CHF</td>
<td>CPU</td>
<td><a href="https://www.digitec.ch/en/s1/product/amd-a6-9500e-2-am4-3ghz-processors-6436852">AMD A6-9500E (2, AM4, 3GHz)</a></td>
</tr>

<tr>
<td>20.10 CHF</td>
<td>Cooler</td>
<td><a href="https://www.digitec.ch/en/s1/product/arctic-alpine-690cm-cpu-coolers-11053306">Arctic Alpine AM4 Passive</a></td>
</tr>

<tr>
<td>42.80 CHF</td>
<td>RAM</td>
<td><a href="https://www.digitec.ch/en/s1/product/kingston-valueram-1x-8gb-ddr4-2400-dimm-288-memory-6149789">Kingston ValueRAM (1x, 8GB, DDR4-2400, DIMM 288)</a></td>
</tr>

<tr>
<td>29.00 CHF</td>
<td>Fan</td>
<td><a href="https://www.digitec.ch/en/s1/product/noctua-nf-s12a-uln-120mm-1x-pc-fans-2451401">Noctua Nf-s12a ULN (120mm, 1x)</a></td>
</tr>

<tr>
<td valign="top">55.00 CHF</td>
<td valign="top">PSU</td>
<td><a href="https://www.digitec.ch/en/s1/product/silverstone-st30sf-300w-sfx-300w-power-supply-computer-5808725">Silverstone ST30SF 300W SFX (300W)</a></td>
</tr>

<tr>
<td valign="top">27.50 CHF</td>
<td valign="top">System disk</td>
<td><a href="https://www.digitec.ch/en/s1/product/intenso-high-performance-120gb-25-ssd-5984710?tagIds=76-535">Intenso High Performance (120GB, 2.5") SATA</a></td>
</tr>

<tr>
<td>351.10 CHF</td>
<td colspan="2"><strong>total sum</strong></td>
</tr>
</table>

<p>In <a href="/posts/2016-11-21-gigabit-nas-coreos/">November 2016 I paid only 225 CHF</a>, i.e. 126 CHF less.</p>

<p>Why is this build so much more expensive? There are two major reasons:</p>

<h3 id="the-am4-platform">The AM4 platform</h3>

<p>The AM4 platform replaced the AM1 APU series as the cheapest broadly available
AMD platform.</p>

<p>As you might have gathered from the links in the hardware listing above, I
define “broadly available” as available at digitec, a large electronics shop in
Zürich.</p>

<p>They offer same-day orders for pick-up in their Zürich location during Weekdays
and on Saturdays, so it is kind of like being on a hardware support plan :-)</p>

<p>Unfortunately, the cheapest AM4 CPU is a lot more expensive (+ 23.31 CHF).</p>

<p>Also, there are (currently?) no AM4 mainboards with DC barrel power plugs,
meaning more expensive ATX power supplies (+ 26.30 CHF) become necessary.</p>

<h3 id="additional-components-fan-and-system-disk">Additional components: fan and system disk</h3>

<p>Definitely invest in the Noctua 120mm ULN (Ultra Low Noise) fan (+ 29.00
CHF). The fan that comes in the Silverstone case is pretty noisy, and that might
be bothersome if you don’t have the luxury of stashing your NAS away in the
basement.</p>

<p>In my last build, I had an SSD lying around that I used as system disk, this
time I had to buy one (+ 27.50 CHF).</p>

<p>Note that I intentionally picked a SATA SSD over an M.2 SSD: the M.2 slot of the
AB350 is on the back of the mainboard, so an M.2 SSD is harder to reach. The
performance disadvantage of a SATA SSD compared to an M.2 SSD might be
measurable, but irrelevant for my day-to-day usage. Quickly accessing the
physical hardware is more important.</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Debian Code Search: positional index, TurboPFor-compressed]]></title>
    <link href="https://michael.stapelberg.ch/posts/2019-09-29-dcs-positional-turbopfor-index/"/>
    <id>https://michael.stapelberg.ch/posts/2019-09-29-dcs-positional-turbopfor-index/</id>
    <published>2019-09-29T00:00:00+00:00</published>
    <updated>2020-02-03T08:54:25+01:00</updated>
    <content type="html"><![CDATA[

<style type="text/css">
.bar {
  display: inline-block;
  padding: 0.25em;
  text-align: center;
  vertical-align: middle;
}

.barcon {
  width: 40em;
  display: flex;
}
</style>

<p>See the <a href="#conclusion">Conclusion</a> for a summary if you’re impatient :-)</p>

<h3 id="motivation">Motivation</h3>

<p>Over the last few months, I have been developing a new index format for Debian
Code Search. This required a lot of careful refactoring, re-implementation,
debug tool creation and debugging.</p>

<p>Multiple factors motivated my work on a new index format:</p>

<ol>
<li><p>The existing index format has a 2G size limit, into which we have bumped a
few times, requiring manual intervention to keep the system running.</p></li>

<li><p>Debugging the existing system required creating ad-hoc debugging tools, which
made debugging sessions unnecessarily lengthy and painful.</p></li>

<li><p>I wanted to check whether <a href="https://github.com/Debian/dcs/issues/85">switching to a different integer compression
format</a> would improve performance
(it does not).</p></li>

<li><p>I wanted to check whether storing positions with the posting lists would
improve performance of identifier queries (= queries which are not using any
regular expression features), which make up 78.2% of all Debian Code Search
queries (it does).</p></li>
</ol>

<p>I figured building a new index from scratch was the easiest approach, compared
to refactoring the existing index to increase the size limit (point ①).</p>

<p>I also figured it would be a good idea to develop the debugging tool in lock
step with the index format so that I can be sure the tool works and is useful
(point ②).</p>

<h3 id="integer-compression-turbopfor">Integer compression: TurboPFor</h3>

<p>As a quick refresher, search engines typically store document IDs (representing
source code files, in our case) in an ordered list (“posting list”). It usually
makes sense to apply at least a rudimentary level of compression: our existing
system used variable integer encoding.</p>

<p><a href="https://github.com/powturbo/TurboPFor">TurboPFor</a>, the self-proclaimed “Fastest
Integer Compression” library, combines an advanced on-disk format with a
carefully tuned SIMD implementation to reach better speeds (in micro benchmarks)
at less disk usage than <a href="https://github.com/google/codesearch/blob/4fe90b597ae534f90238f82c7b5b1bb6d6d52dff/index/write.go#L561">Russ Cox’s varint implementation in
<code>github.com/google/codesearch</code></a>.</p>

<p>If you are curious about its inner workings, check out my “<a href="/posts/2019-02-05-turbopfor-analysis/">TurboPFor: an
analysis</a>”.</p>

<p>Applied on the Debian Code Search index, TurboPFor indeed compresses integers better:</p>

<h4 id="disk-space">Disk space</h4>

<p><div style="display: inline-block">
    <div class="barcon">
        <div class="bar" style="width: 100%; background-color: blue; color: white">
            &nbsp;
        </div>
    </div>
</div>
<span style="margin-right: 2em">8.9G</span>
codesearch varint index</p>

<p><div style="display: inline-block">
    <div class="barcon">
        <div class="bar" style="width: 61%; background-color: blue; color: white">
            &nbsp;
        </div>
    </div>
</div>
<span style="margin-right: 2em">5.5G</span>
TurboPFor index</p>

<p>Switching to TurboPFor (via cgo) for storing and reading the index results in a
slight speed-up of a <code>dcs replay</code> benchmark, which is more pronounced the more
i/o is required.</p>

<h4 id="query-speed-regexp-cold-page-cache">Query speed (regexp, cold page cache)</h4>

<p><div style="display: inline-block">
    <div class="barcon">
        <div class="bar" style="width: 100%; background-color: blue; color: white">
            &nbsp;
        </div>
    </div>
</div>
<span style="margin-right: 2em">18s</span>
codesearch varint index</p>

<p><div style="display: inline-block">
    <div class="barcon">
        <div class="bar" style="width: 77.7%; background-color: blue; color: white">
            &nbsp;
        </div>
    </div>
</div>
<span style="margin-right: 2em">14s</span>
TurboPFor index (cgo)</p>

<h4 id="query-speed-regexp-warm-page-cache">Query speed (regexp, warm page cache)</h4>

<p><div style="display: inline-block">
    <div class="barcon">
        <div class="bar" style="width: 100%; background-color: blue; color: white">
            &nbsp;
        </div>
    </div>
</div>
<span style="margin-right: 2em">15s</span>
codesearch varint index</p>

<p><div style="display: inline-block">
    <div class="barcon">
        <div class="bar" style="width: 93.3%; background-color: blue; color: white">
            &nbsp;
        </div>
    </div>
</div>
<span style="margin-right: 2em">14s</span>
TurboPFor index (cgo)</p>

<p>Overall, TurboPFor is an all-around improvement in efficiency, albeit with a
high cost in implementation complexity.</p>

<h3 id="positional-index-trade-more-disk-for-faster-queries">Positional index: trade more disk for faster queries</h3>

<p>This section builds on the previous section: all figures come from the TurboPFor
index, which can optionally support positions.</p>

<p>Conceptually, we’re going from:</p>

<pre><code>type docid uint32
type index map[trigram][]docid
</code></pre>

<p>…to:</p>

<pre><code>type occurrence struct {
    doc docid
    pos uint32 // byte offset in doc
}
type index map[trigram][]occurrence
</code></pre>

<p>The resulting index consumes more disk space, but can be queried faster:</p>

<ol>
<li><p>We can do fewer queries: instead of reading all the posting lists for all
the trigrams, we can read the posting lists for the query’s first and last
trigram only.
<br>
This is one of the tricks described in the paper
“<a href="https://cedric.cnam.fr/fichiers/art_3216.pdf">AS-Index: A
Structure For String Search Using n-grams and Algebraic Signatures</a>”
(PDF), and goes a long way without incurring the complexity, computational
cost and additional disk usage of calculating algebraic signatures.</p></li>

<li><p>Verifying the delta between the last and first position matches the length
of the query term significantly reduces the number of files to read (lower
false positive rate).</p></li>

<li><p>The matching phase is quicker: instead of locating the query term in the
file, we only need to compare a few bytes at a known offset for equality.</p></li>

<li><p>More data is read sequentially (from the index), which is faster.</p></li>
</ol>

<h4 id="disk-space-1">Disk space</h4>

<p>A positional index consumes significantly more disk space, but not so much as
to pose a challenge: a Hetzner EX61-NVME dedicated server (≈ 64 €/month)
provides 1 TB worth of fast NVMe flash storage.</p>

<p><div style="display: inline-block">
    <div class="barcon">
        <div class="bar" style="width: 5.2%; background-color: blue; color: white">
            &nbsp;
        </div>
    </div>
</div>
<span style="margin-right: 2em">&nbsp;6.5G</span>
non-positional</p>

<p><div style="display: inline-block">
    <div class="barcon">
        <div class="bar" style="width: 100%; background-color: blue; color: white">
            &nbsp;
        </div>
    </div>
</div>
<span style="margin-right: 2em">123G</span>
positional</p>

<p><div style="display: inline-block">
    <div class="barcon">
        <div class="bar" style="width: 75.6%; background-color: blue; color: white">
            &nbsp;
        </div>
    </div>
</div>
<span style="margin-right: 2em">&nbsp;&nbsp;93G</span>
positional (posrel)</p>

<p>The idea behind the positional index (posrel) is to not store a <code>(doc,pos)</code>
tuple on disk, but to store positions, accompanied by a stream of doc/pos
relationship bits: 1 means this position belongs to the next document, 0 means
this position belongs to the current document.</p>

<p>This is an easy way of saving some space without modifying the TurboPFor
on-disk format: the posrel technique reduces the index size to about ¾.</p>

<p>With the increase in size, the Linux page cache hit ratio will be lower for
the positional index, i.e. more data will need to be fetched from disk for
querying the index.</p>

<p>As long as the disk can deliver data as fast as you can decompress posting
lists, this only translates into one disk seek’s worth of additional
latency. This is the case with modern NVMe disks that deliver thousands of MB/s,
e.g. the Samsung 960 Pro (used in Hetzner’s aforementioned EX61-NVME server).</p>

<p>The values were measured by running <code>dcs du -h /srv/dcs/shard*/full</code>
without and with the <code>-pos</code> argument.</p>

<h4 id="bytes-read">Bytes read</h4>

<p>A positional index requires fewer queries: reading only the first and last
trigram’s posting lists and positions is sufficient to achieve a lower (!) false
positive rate than evaluating <strong>all</strong> trigram’s posting lists in a
non-positional index.</p>

<p>As a consequence, fewer files need to be read, resulting in fewer bytes required
to read from disk overall.</p>

<p>As an additional bonus, in a positional index, more data is read sequentially
(index), which is faster than random i/o, regardless of the underlying disk.</p>

<p><div style="display: inline-block">
<div class="barcon">
<div class="bar" style="width: calc(2 * 1.2em); background-color: blue; color: white">
  1.2G
</div>
<div class="bar" style="width: calc(2 * 19.8em); background-color: green; color: white">
  19.8G
</div>
</div>
</div>
<span style="margin-right: 2em">21.0G</span>
regexp queries</p>

<p><div style="display: inline-block">
<div class="barcon">
<div class="bar" style="width: calc(2 * 4.2em); background-color: blue; color: white">
  4.2G (index)
</div>
<div class="bar" style="width: calc(2 * 10.8em); background-color: green; color: white">
  10.8G (files)
</div>
</div>
</div>
<span style="margin-right: 2em">15.0G</span>
identifier queries</p>

<p>The values were measured by running <code>iostat -d 25</code> just before running
<a href="https://codesearch.debian.net/research/2019-08-03-dcs-new-index/"><code>bench.zsh</code></a>
on an otherwise idle system.</p>

<h4 id="query-speed">Query speed</h4>

<p>Even though the positional index is larger and requires more data to be read at
query time (see above), thanks to the C TurboPFor library, the 2 queries on a
positional index are roughly as fast as the n queries on a non-positional index
(≈4s instead of ≈3s).</p>

<p>This is more than made up for by the combined i/o matching stage, which shrinks
from ≈18.5s (7.1s i/o + 11.4s matching) to ≈1.3s.</p>

<p><div style="display: inline-block">
<div class="barcon">
<div class="bar" style="width: calc(2 * 3.3em); background-color: blue; color: white">
  3.3s (index)
</div>
<div class="bar" style="width: calc(2 * 7.1em); background-color: green; color: white">
  7.1s (i/o)
</div>
<div class="bar" style="width: calc(2 * 11.4em); background-color: purple; color: white">
  11.4s (matching)
</div>
</div>
</div>
<span style="margin-right: 2em">21.8s</span>
regexp queries</p>

<p><div style="display: inline-block">
<div class="barcon">
<div class="bar" style="width: calc(2 * 3.92em); background-color: blue; color: white">
  3.92s (index)
</div>
<div class="bar" style="width: calc(2 * 1.3em); background-color: green; color: white">
  ≈1.3s
</div>
</div>
</div>
<span style="margin-right: 2em">5.22s</span>
identifier queries</p>

<p>Note that identifier query i/o was sped up not just by needing to read fewer
bytes, but also by only having to verify bytes at a known offset instead of
needing to locate the identifier within the file.</p>

<h3 id="conclusion">Conclusion</h3>

<p>The new index format is overall slightly more efficient. This disk space
efficiency allows us to introduce a positional index section for the first
time.</p>

<p>Most Debian Code Search queries are positional queries (78.2%) and will be
answered much quicker by leveraging the positions.</p>

<p>Bottomline, it is beneficial to use a positional index on disk over a
non-positional index in RAM.</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[distri: a Linux distribution to research fast package management]]></title>
    <link href="https://michael.stapelberg.ch/posts/2019-08-17-introducing-distri/"/>
    <id>https://michael.stapelberg.ch/posts/2019-08-17-introducing-distri/</id>
    <published>2019-08-17T18:36:00+02:00</published>
    <updated>2020-08-12T10:08:02+02:00</updated>
    <content type="html"><![CDATA[

<p>Over the last year or so I have worked on a research linux distribution in my
spare time. It’s not a distribution for researchers (like <a href="https://en.wikipedia.org/wiki/Scientific_Linux">Scientific
Linux</a>), but my personal
playground project to research linux distribution development, i.e. try out
fresh ideas.</p>

<p>This article focuses on the package format and its advantages, but there is
more to distri, which I will <a href="#more-to-come">cover in upcoming blog posts</a>.</p>

<h3 id="motivation">Motivation</h3>

<p>I was a Debian Developer for the 7 years from 2012 to 2019, but using the
distribution often left me frustrated, ultimately <a href="/posts/2019-03-10-debian-winding-down/">resulting in me winding down
my Debian work</a>.</p>

<p>Frequently, I was noticing a large gap between the actual speed of an operation
(e.g. doing an update) and the possible speed based on back of the envelope
calculations. I wrote more about this in my blog post <a href="/posts/2019-08-17-linux-package-managers-are-slow/">“Package managers are
slow”</a>.</p>

<p>To me, this observation means that either there is potential to optimize the
package manager itself (e.g. <code>apt</code>), or what the system does is just too
complex. While I remember seeing some low-hanging fruit¹, through my work on
distri, I wanted to explore whether all the complexity we currently have in
Linux distributions such as Debian or Fedora is inherent to the problem space.</p>

<p>I have completed enough of the experiment to conclude that the complexity is not
inherent: I can build a Linux distribution for general-enough purposes which is
much less complex than existing ones.</p>

<p>① Those were low-hanging fruit from a user perspective. I’m not saying that
  fixing them is easy in the technical sense; I know too little about <code>apt</code>’s code
  base to make such a statement.</p>

<h3 id="key-idea-packages-are-images-not-archives">Key idea: packages are images, not archives</h3>

<p>One key idea is to switch from using archives to using <strong>images</strong> for package
contents. Common package managers such as <a href="https://manpages.debian.org/dpkg.1"><code>dpkg(1)</code></a>

use <a href="https://manpages.debian.org/tar.1"><code>tar(1)</code></a>
 archives with various compression
algorithms.</p>

<p>distri uses <a href="https://en.wikipedia.org/wiki/SquashFS">SquashFS images</a>, a
comparatively simple file system image format that I happen to be familiar with
from my work on the <a href="https://gokrazy.org">gokrazy Raspberry Pi 3 Go platform</a>.</p>

<p>This idea is not novel: <a href="https://en.wikipedia.org/wiki/AppImage">AppImage</a> and
<a href="https://en.wikipedia.org/wiki/Snappy_(package_manager)">snappy</a> also use
images, but only for individual, self-contained applications. distri however
uses images for distribution packages with dependencies. In particular, there is
no duplication of shared libraries in distri.</p>

<p>A nice side effect of using read-only image files is that applications are
immutable and can hence not be broken by accidental (or malicious!)
modification.</p>

<h3 id="key-idea-separate-hierarchies">Key idea: separate hierarchies</h3>

<p>Package contents are made available under a fully-qualified path. E.g., all
files provided by package <code>zsh-amd64-5.6.2-3</code> are available under
<code>/ro/zsh-amd64-5.6.2-3</code>. The mountpoint <code>/ro</code> stands for read-only, which is
short yet descriptive.</p>

<p>Perhaps surprisingly, building software with custom <code>prefix</code> values of
e.g. <code>/ro/zsh-amd64-5.6.2-3</code> is widely supported, thanks to:</p>

<ol>
<li><p>Linux distributions, which build software with <code>prefix</code> set to <code>/usr</code>,
whereas FreeBSD (and the autotools default), which build with <code>prefix</code> set to
<code>/usr/local</code>.</p></li>

<li><p>Enthusiast users in corporate or research environments, who install software
into their home directories.</p></li>
</ol>

<p>Because using a custom <code>prefix</code> is a common scenario, upstream awareness for
<code>prefix</code>-correctness is generally high, and the rarely required patch will be
quickly accepted.</p>

<h3 id="key-idea-exchange-directories">Key idea: exchange directories</h3>

<p>Software packages often exchange data by placing or locating files in well-known
directories. Here are just a few examples:</p>

<ul>
<li><a href="https://manpages.debian.org/gcc.1"><code>gcc(1)</code></a>
 locates the <a href="https://manpages.debian.org/libusb.3"><code>libusb(3)</code></a>
 headers via <code>/usr/include</code></li>
<li><a href="https://manpages.debian.org/man.1"><code>man(1)</code></a>
 locates the <a href="https://manpages.debian.org/nginx.1"><code>nginx(1)</code></a>
 manpage via <code>/usr/share/man</code>.</li>
<li><a href="https://manpages.debian.org/zsh.1"><code>zsh(1)</code></a>
 locates executable programs via <code>PATH</code> components such as <code>/bin</code></li>
</ul>

<p>In distri, these locations are called <strong>exchange directories</strong> and are provided
via FUSE in <code>/ro</code>.</p>

<p>Exchange directories come in two different flavors:</p>

<ol>
<li><p>global. The exchange directory, e.g. <code>/ro/share</code>, provides the union of the
<code>share</code> sub directory of all packages in the package store.
<br />
Global exchange directories are largely used for compatibility, <a href="#fhs-compat">see
below</a>.</p></li>

<li><p>per-package. Useful for tight coupling: e.g. <a href="https://manpages.debian.org/irssi.1"><code>irssi(1)</code></a>
 does not provide any ABI guarantees, so plugins such as <code>irssi-robustirc</code>
can declare that they want
e.g. <code>/ro/irssi-amd64-1.1.1-1/out/lib/irssi/modules</code> to be a per-package
exchange directory and contain files from their <code>lib/irssi/modules</code>.</p></li>
</ol>

<aside class="admonition note">
  <div class="note-icon">
    <svg id="exclamation-icon" width="100%" height="100%" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;">
    <path d="M0,0L24,0L24,24L0,24L0,0Z" style="fill:none;"/>
    <g transform="matrix(1.2,0,0,1.2,-2.4,-2.4)">
        <path d="M12,2C6.48,2 2,6.48 2,12C2,17.52 6.48,22 12,22C17.52,22 22,17.52 22,12C22,6.48 17.52,2 12,2ZM13,17L11,17L11,15L13,15L13,17ZM13,13L11,13L11,7L13,7L13,13Z" style="fill-rule:nonzero;"/>
    </g>
</svg>

  </div>
  <div class="admonition-content">
    <strong>Note</strong>:
Only a few exchange directories are also available in the package build
environment (as opposed to run-time).
</div>
</aside>


<h4 id="search-paths-sometimes-need-to-be-fixed">Search paths sometimes need to be fixed</h4>

<p>Programs which use exchange directories sometimes use search paths to access
multiple exchange directories. In fact, the examples above were taken from <a href="https://manpages.debian.org/gcc.1"><code>gcc(1)</code></a>
’s <code>INCLUDEPATH</code>, <a href="https://manpages.debian.org/man.1"><code>man(1)</code></a>
’s <code>MANPATH</code> and <a href="https://manpages.debian.org/zsh.1"><code>zsh(1)</code></a>
’s <code>PATH</code>. These are
prominent ones, but more examples are easy to find: <a href="https://manpages.debian.org/zsh.1"><code>zsh(1)</code></a>
 loads completion functions from its <code>FPATH</code>.</p>

<p>Some search path values are derived from <code>--datadir=/ro/share</code> and require no
further attention, but others might derive from
e.g. <code>--prefix=/ro/zsh-amd64-5.6.2-3/out</code> and need to be pointed to an exchange
directory via a specific command line flag.</p>

<aside class="admonition note">
  <div class="note-icon">
    <svg id="exclamation-icon" width="100%" height="100%" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;">
    <path d="M0,0L24,0L24,24L0,24L0,0Z" style="fill:none;"/>
    <g transform="matrix(1.2,0,0,1.2,-2.4,-2.4)">
        <path d="M12,2C6.48,2 2,6.48 2,12C2,17.52 6.48,22 12,22C17.52,22 22,17.52 22,12C22,6.48 17.52,2 12,2ZM13,17L11,17L11,15L13,15L13,17ZM13,13L11,13L11,7L13,7L13,13Z" style="fill-rule:nonzero;"/>
    </g>
</svg>

  </div>
  <div class="admonition-content">
    <strong>Note</strong>:

To create the illusion of a writable search path at package build-time,
<code>$DESTDIR/ro/share</code> and <code>$DESTDIR/ro/lib</code> are diverted to
<code>$DESTDIR/$PREFIX/share</code> and <code>$DESTDIR/$PREFIX/lib</code>,
respectively.

</div>
</aside>


<h4 id="fhs-compat">FHS compatibility</h4>

<p>Global exchange directories are used to make distri provide enough of the
<a href="https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard">Filesystem Hierarchy Standard
(FHS)</a> that
third-party software largely just works. This includes a C development
environment.</p>

<p>I successfully ran a few programs from their binary packages such as Google
Chrome, Spotify, or Microsoft’s Visual Studio Code.</p>

<h3 id="fast-package-manager">Fast package manager</h3>

<p>I previously wrote about how <a href="/posts/2019-08-17-linux-package-managers-are-slow/">Linux distribution package managers are too slow</a>.</p>

<p>distri’s package manager is extremely fast. Its main bottleneck is typically the network link, even at high speed links (I tested with a 100 Gbps link).</p>

<p>Its speed comes largely from an architecture which allows the package manager to
do less work. Specifically:</p>

<ol>
<li><p>Package images can be added atomically to the package store, so we can safely
skip <a href="https://manpages.debian.org/fsync.2"><code>fsync(2)</code></a>
. Corruption will be cleaned up
automatically, and durability is not important: if an interactive
installation is interrupted, the user can just repeat it, as it will be fresh
on their mind.</p></li>

<li><p>Because all packages are co-installable thanks to separate hierarchies, there
are no conflicts at the package store level, and no dependency resolution (an
optimization problem requiring <a href="https://research.swtch.com/version-sat">SAT
solving</a>) is required at all.
<br />
In exchange directories, we resolve conflicts by selecting the package with the
highest monotonically increasing distri revision number.</p></li>

<li><p>distri proves that we can build a useful Linux distribution <a href="/posts/2019-07-20-hooks-and-triggers/">entirely without
hooks and triggers</a>. Not having to
serialize hook execution allows us to download packages into the package
store with maximum concurrency.</p></li>

<li><p>Because we are using images instead of archives, we do not need to unpack
anything. This means installing a package is really just writing its package
image and metadata to the package store. Sequential writes are typically the
fastest kind of storage usage pattern.</p></li>
</ol>

<p>Fast installation also make other use-cases more bearable, such as creating disk
images, be it for testing them in <a href="https://manpages.debian.org/qemu.1"><code>qemu(1)</code></a>
, booting
them on real hardware from a USB drive, or for cloud providers such as Google
Cloud.</p>

<aside class="admonition note">
  <div class="note-icon">
    <svg id="exclamation-icon" width="100%" height="100%" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;">
    <path d="M0,0L24,0L24,24L0,24L0,0Z" style="fill:none;"/>
    <g transform="matrix(1.2,0,0,1.2,-2.4,-2.4)">
        <path d="M12,2C6.48,2 2,6.48 2,12C2,17.52 6.48,22 12,22C17.52,22 22,17.52 22,12C22,6.48 17.52,2 12,2ZM13,17L11,17L11,15L13,15L13,17ZM13,13L11,13L11,7L13,7L13,13Z" style="fill-rule:nonzero;"/>
    </g>
</svg>

  </div>
  <div class="admonition-content">
    <strong>Note</strong>:
To saturate links above 1 Gbps, transfer packages without compression.
</div>
</aside>


<h3 id="fast-package-builder">Fast package builder</h3>

<p>Contrary to how distribution package builders are usually implemented, the
distri package builder does not actually install any packages into the build
environment.</p>

<p>Instead, distri makes available a filtered view of the package store (only
declared dependencies are available) at <code>/ro</code> in the build environment.</p>

<p>This means that even for large dependency trees, setting up a build environment
happens in a fraction of a second! Such a low latency really makes a difference
in how comfortable it is to iterate on distribution packages.</p>

<h3 id="package-stores">Package stores</h3>

<p>In distri, package images are installed from a remote <strong>package store</strong> into the
local system package store <code>/roimg</code>, which backs the <code>/ro</code> mount.</p>

<p>A package store is implemented as a directory of package images and their
associated metadata files.</p>

<p>You can easily make available a package store by using <code>distri export</code>.</p>

<p>To provide a mirror for your local network, you can periodically <code>distri update</code>
from the package store you want to mirror, and then <code>distri export</code> your local
copy. Special tooling (e.g. <code>debmirror</code> in Debian) is not required because
<code>distri install</code> is atomic (and <code>update</code> uses <code>install</code>).</p>

<p>Producing derivatives is easy: just add your own packages to a copy of the
package store.</p>

<p>The package store is intentionally kept simple to manage and distribute. Its
files could be exchanged via peer-to-peer file systems, or synchronized from an
offline medium.</p>

<h3 id="distri-s-first-release">distri’s first release</h3>

<p>distri works well enough to demonstrate the ideas explained above. I have
branched this state into <a href="https://github.com/distr1/distri/tree/jackherer">branch
<code>jackherer</code></a>, distri’s first
release code name. This way, I can keep experimenting in the distri repository
without breaking your installation.</p>

<p>From the branch contents, our autobuilder creates:</p>

<ol>
<li><p><a href="https://repo.distr1.org/distri/jackherer/img/">disk images</a>, which…</p>

<ul>
<li>can be <a href="https://github.com/distr1/distri#run-distri-on-real-hardware">tested on real hardware</a></li>
<li>can be <a href="https://github.com/distr1/distri#run-distri-in-qemu">tested in qemu</a></li>
<li>can be <a href="https://github.com/distr1/distri#run-distri-in-virtualbox">tested in virtualbox</a></li>
<li>can be <a href="https://github.com/distr1/distri#run-distri-in-docker">tested in docker</a></li>
<li>can be <a href="https://github.com/distr1/distri#run-distri-on-google-cloud">tested on Google Cloud</a></li>
</ul></li>

<li><p>a <a href="https://repo.distr1.org/distri/jackherer/pkg/">package repository</a>. Installations can pick up new packages with
<code>distri update</code>.</p></li>

<li><p><a href="https://repo.distr1.org/distri/jackherer/docs/">documentation for the release</a>.</p>

<ul>
<li>Definitely check out the <a href="https://github.com/distr1/distri#cool-things-to-try">“Cool things to
try”</a> README section.</li>
</ul></li>
</ol>

<p>The project website can be found at <a href="https://distr1.org">https://distr1.org</a>. The website is just the
README for now, but we can improve that later.</p>

<p>The repository can be found at <a href="https://github.com/distr1/distri">https://github.com/distr1/distri</a></p>

<h3 id="project-outlook">Project outlook</h3>

<p>Right now, distri is mainly a vehicle for my spare-time Linux distribution
research. <strong>I don’t recommend anyone use distri for anything but research,</strong> and
there are no medium-term plans of that changing. At the very least, please
contact me before basing anything serious on distri so that we can talk about
limitations and expectations.</p>

<p>I expect the distri project to live for as long as I have blog posts to publish,
and we’ll see what happens afterwards. Note that this is a hobby for me: I will
continue to explore, at my own pace, parts that I find interesting.</p>

<p>My hope is that established distributions might get a useful idea or two from
distri.</p>

<h3 id="more-to-come">There’s more to come: subscribe to the distri feed</h3>

<p>I don’t want to make this post too long, but there is much more!</p>

<p>Please subscribe to the following URL in your feed reader to get all posts about
distri:</p>

<p><a href="https://michael.stapelberg.ch/posts/tags/distri/feed.xml">https://michael.stapelberg.ch/posts/tags/distri/feed.xml</a></p>

<p>Next in my queue are articles about hermetic packages and good package
maintainer experience (including declarative packaging).</p>

<h3 id="feedback-or-questions">Feedback or questions?</h3>

<p>I’d love to discuss these ideas in case you’re interested!</p>

<p>Please send feedback to the <a href="https://www.freelists.org/list/distri">distri mailing
list</a> so that everyone can participate!</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Linux package managers are slow]]></title>
    <link href="https://michael.stapelberg.ch/posts/2019-08-17-linux-package-managers-are-slow/"/>
    <id>https://michael.stapelberg.ch/posts/2019-08-17-linux-package-managers-are-slow/</id>
    <published>2019-08-17T18:27:00+02:00</published>
    <updated>2020-10-01T09:49:53+02:00</updated>
    <content type="html"><![CDATA[

<p>I measured how long the most popular Linux distribution’s package manager take
to install small and large packages (the
<a href="https://manpages.debian.org/ack.1p"><code>ack(1p)</code></a> source code search Perl script
and <a href="https://en.wikipedia.org/wiki/QEMU">qemu</a>, respectively).</p>

<p>Where required, my measurements include metadata updates such as transferring an
up-to-date package list. For me, requiring a metadata update is the more common
case, particularly on live systems or within Docker containers.</p>

<p>All measurements were taken on an <code>Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz</code>
running Docker 1.13.1 on Linux 4.19, backed by a Samsung 970 Pro NVMe drive
boasting many hundreds of MB/s write performance. The machine is located in
Zürich and connected to the Internet with a 1 Gigabit fiber connection, so the
expected top download speed is ≈115 MB/s.</p>

<p>See <a href="#appendix-c">Appendix C</a> for details on the measurement method and command
outputs.</p>

<h3 id="measurements">Measurements</h3>

<p>Keep in mind that these are one-time measurements. They should be indicative of
actual performance, but your experience may vary.</p>

<h4 id="ack-small-perl-program">ack (small Perl program)</h4>

<table>
<thead>
<tr>
<th>distribution</th>
<th>package manager</th>
<th>data</th>
<th>wall-clock time</th>
<th>rate</th>
</tr>
</thead>

<tbody>
<tr>
<td>Fedora</td>
<td>dnf</td>
<td>114 MB</td>
<td>33s</td>
<td>3.4 MB/s</td>
</tr>

<tr>
<td>Debian</td>
<td>apt</td>
<td>16 MB</td>
<td>10s</td>
<td>1.6 MB/s</td>
</tr>

<tr>
<td>NixOS</td>
<td>Nix</td>
<td>15 MB</td>
<td>5s</td>
<td>3.0 MB/s</td>
</tr>

<tr>
<td>Arch Linux</td>
<td>pacman</td>
<td>6.5 MB</td>
<td>3s</td>
<td>2.1 MB/s</td>
</tr>

<tr>
<td>Alpine</td>
<td>apk</td>
<td>10 MB</td>
<td>1s</td>
<td>10.0 MB/s</td>
</tr>
</tbody>
</table>

<h4 id="qemu-large-c-program">qemu (large C program)</h4>

<table>
<thead>
<tr>
<th>distribution</th>
<th>package manager</th>
<th>data</th>
<th>wall-clock time</th>
<th>rate</th>
</tr>
</thead>

<tbody>
<tr>
<td>Fedora</td>
<td>dnf</td>
<td>226 MB</td>
<td>4m37s</td>
<td>1.2 MB/s</td>
</tr>

<tr>
<td>Debian</td>
<td>apt</td>
<td>224 MB</td>
<td>1m35s</td>
<td>2.3 MB/s</td>
</tr>

<tr>
<td>Arch Linux</td>
<td>pacman</td>
<td>142 MB</td>
<td>44s</td>
<td>3.2 MB/s</td>
</tr>

<tr>
<td>NixOS</td>
<td>Nix</td>
<td>180 MB</td>
<td>34s</td>
<td>5.2 MB/s</td>
</tr>

<tr>
<td>Alpine</td>
<td>apk</td>
<td>26 MB</td>
<td>2.4s</td>
<td>10.8 MB/s</td>
</tr>
</tbody>
</table>

<p><br>
(Looking for older measurements? See <a href="#appendix-b">Appendix B (2019)</a>.</p>

<p>The difference between the slowest and fastest package managers is 30x!</p>

<p>How can Alpine’s apk and Arch Linux’s pacman be an order of magnitude faster
than the rest? They are doing a lot less than the others, and more efficiently,
too.</p>

<h4 id="pain-point-too-much-metadata">Pain point: too much metadata</h4>

<p>For example, Fedora transfers a lot more data than others because its main
package list is 60 MB (compressed!) alone. Compare that with Alpine’s 734 KB
<code>APKINDEX.tar.gz</code>.</p>

<p>Of course the extra metadata which Fedora provides helps some use case,
otherwise they hopefully would have removed it altogether. The amount of
metadata seems excessive for the use case of installing a single package, which
I consider the main use-case of an interactive package manager.</p>

<p>I expect any modern Linux distribution to <strong>only transfer absolutely required
data</strong> to complete my task.</p>

<h4 id="pain-point-no-concurrency">Pain point: no concurrency</h4>

<p>Because they need to sequence executing arbitrary package maintainer-provided
code (hooks and triggers), all tested package managers need to install packages
sequentially (one after the other) instead of concurrently (all at the same
time).</p>

<p>In my blog post <a href="/posts/2019-07-20-hooks-and-triggers/">“Can we do without hooks and
triggers?”</a>, I outline that hooks and
triggers are not strictly necessary to build a working Linux distribution.</p>

<h3 id="thought-experiment-further-speed-ups">Thought experiment: further speed-ups</h3>

<p>Strictly speaking, the only required feature of a package manager is to make
available the package contents so that the package can be used: a program can be
started, a kernel module can be loaded, etc.</p>

<p>By only implementing what’s needed for this feature, and nothing more, a package
manager could likely beat <code>apk</code>’s performance. It could, for example:</p>

<ul>
<li>skip archive extraction by mounting file system images (like AppImage or snappy)</li>
<li>use compression which is light on CPU, as networks are fast (like <code>apk</code>)</li>
<li>skip fsync when it is safe to do so, i.e.:

<ul>
<li>package installations don’t modify system state</li>
<li>atomic package installation (e.g. an append-only package store)</li>
<li>automatically clean up the package store after crashes</li>
</ul></li>
</ul>

<h3 id="current-landscape">Current landscape</h3>

<p>Here’s a table outlining how the various package managers listed on Wikipedia’s
<a href="https://en.wikipedia.org/wiki/List_of_software_package_management_systems#Linux">list of software package management
systems</a>
fare:</p>

<table>
<thead>
<tr>
<th>name</th>
<th>scope</th>
<th>package file format</th>
<th>hooks/triggers</th>
</tr>
</thead>

<tbody>
<tr>
<td>AppImage</td>
<td>apps</td>
<td>image: ISO9660, SquashFS</td>
<td>no</td>
</tr>

<tr>
<td><a href="https://snapcraft.io/">snappy</a></td>
<td>apps</td>
<td>image: SquashFS</td>
<td>yes: <a href="https://docs.snapcraft.io/build-snaps/hooks">hooks</a></td>
</tr>

<tr>
<td>FlatPak</td>
<td>apps</td>
<td>archive: <a href="https://ostree.readthedocs.io/en/latest/">OSTree</a></td>
<td>no</td>
</tr>

<tr>
<td>0install</td>
<td>apps</td>
<td>archive: tar.bz2</td>
<td>no</td>
</tr>

<tr>
<td>nix, guix</td>
<td>distro</td>
<td>archive: nar.{bz2,xz}</td>
<td><a href="https://github.com/NixOS/nixos/blob/master/modules/system/activation/activation-script.nix">activation script</a></td>
</tr>

<tr>
<td>dpkg</td>
<td>distro</td>
<td>archive: tar.{gz,xz,bz2} in ar(1)</td>
<td>yes</td>
</tr>

<tr>
<td>rpm</td>
<td>distro</td>
<td>archive: cpio.{bz2,lz,xz}</td>
<td><a href="https://fedoraproject.org/wiki/Packaging:Scriptlets">scriptlets</a></td>
</tr>

<tr>
<td>pacman</td>
<td>distro</td>
<td>archive: tar.xz</td>
<td><a href="https://wiki.archlinux.org/index.php/PKGBUILD#install">install</a></td>
</tr>

<tr>
<td>slackware</td>
<td>distro</td>
<td>archive: tar.{gz,xz}</td>
<td>yes: doinst.sh</td>
</tr>

<tr>
<td>apk</td>
<td>distro</td>
<td>archive: tar.gz</td>
<td>yes: .post-install</td>
</tr>

<tr>
<td>Entropy</td>
<td>distro</td>
<td>archive: tar.bz2</td>
<td>yes</td>
</tr>

<tr>
<td>ipkg, opkg</td>
<td>distro</td>
<td>archive: tar{,.gz}</td>
<td>yes</td>
</tr>
</tbody>
</table>

<h3 id="conclusion">Conclusion</h3>

<p>As per the <a href="#current-landscape">current landscape</a>, there is no
distribution-scoped package manager which uses images and leaves out hooks and
triggers, not even in smaller Linux distributions.</p>

<p>I think that space is really interesting, as it uses a minimal design to achieve
significant real-world speed-ups.</p>

<p>I have explored this idea in much more detail, and am happy to talk more about
it in my post “Introducing the distri research linux distribution&quot;.</p>

<h3 id="appendix-a-related-work">Appendix A: related work</h3>

<p>There are a couple of recent developments going into the same direction:</p>

<ul>
<li><a href="http://0pointer.net/blog/revisiting-how-we-put-together-linux-systems.html">“Revisiting How We Put Together Linux Systems”</a> describes mounting app bundles</li>
<li><a href="https://android.googlesource.com/platform/system/apex/+/refs/heads/master/docs/README.md">Android Q uses ext4 loopback images</a></li>
<li>The Haiku Operating System’s package manager <a href="https://en.wikipedia.org/wiki/Haiku_Depot">Haiku
Depot</a> uses images</li>
</ul>

<h3 id="appendix-c">Appendix C: measurement details (2020)</h3>

<h4 id="ack">ack</h4>

<p>You can expand each of these:</p>

<p><details>
<summary>
Fedora’s dnf takes almost 33 seconds to fetch and unpack 114 MB.
</summary></p>

<pre><code>% docker run -t -i fedora /bin/bash
[root@62d3cae2e2f9 /]# time dnf install -y ack
Fedora 32 openh264 (From Cisco) - x86_64     1.9 kB/s | 2.5 kB     00:01
Fedora Modular 32 - x86_64                   6.8 MB/s | 4.9 MB     00:00
Fedora Modular 32 - x86_64 - Updates         5.6 MB/s | 3.7 MB     00:00
Fedora 32 - x86_64 - Updates                 9.9 MB/s |  23 MB     00:02
Fedora 32 - x86_64                            39 MB/s |  70 MB     00:01
[…]
real	0m32.898s
user	0m25.121s
sys	0m1.408s
</code></pre>

<p></details></p>

<p><details>
<summary>
NixOS’s Nix takes a little over 5s to fetch and unpack 15 MB.
</summary></p>

<pre><code>% docker run -t -i nixos/nix
39e9186422ba:/# time sh -c 'nix-channel --update &amp;&amp; nix-env -iA nixpkgs.ack'
unpacking channels...
created 1 symlinks in user environment
installing 'perl5.32.0-ack-3.3.1'
these paths will be fetched (15.55 MiB download, 85.51 MiB unpacked):
  /nix/store/34l8jdg76kmwl1nbbq84r2gka0kw6rc8-perl5.32.0-ack-3.3.1-man
  /nix/store/9df65igwjmf2wbw0gbrrgair6piqjgmi-glibc-2.31
  /nix/store/9fd4pjaxpjyyxvvmxy43y392l7yvcwy1-perl5.32.0-File-Next-1.18
  /nix/store/czc3c1apx55s37qx4vadqhn3fhikchxi-libunistring-0.9.10
  /nix/store/dj6n505iqrk7srn96a27jfp3i0zgwa1l-acl-2.2.53
  /nix/store/ifayp0kvijq0n4x0bv51iqrb0yzyz77g-perl-5.32.0
  /nix/store/w9wc0d31p4z93cbgxijws03j5s2c4gyf-coreutils-8.31
  /nix/store/xim9l8hym4iga6d4azam4m0k0p1nw2rm-libidn2-2.3.0
  /nix/store/y7i47qjmf10i1ngpnsavv88zjagypycd-attr-2.4.48
  /nix/store/z45mp61h51ksxz28gds5110rf3wmqpdc-perl5.32.0-ack-3.3.1
copying path '/nix/store/34l8jdg76kmwl1nbbq84r2gka0kw6rc8-perl5.32.0-ack-3.3.1-man' from 'https://cache.nixos.org'...
copying path '/nix/store/czc3c1apx55s37qx4vadqhn3fhikchxi-libunistring-0.9.10' from 'https://cache.nixos.org'...
copying path '/nix/store/9fd4pjaxpjyyxvvmxy43y392l7yvcwy1-perl5.32.0-File-Next-1.18' from 'https://cache.nixos.org'...
copying path '/nix/store/xim9l8hym4iga6d4azam4m0k0p1nw2rm-libidn2-2.3.0' from 'https://cache.nixos.org'...
copying path '/nix/store/9df65igwjmf2wbw0gbrrgair6piqjgmi-glibc-2.31' from 'https://cache.nixos.org'...
copying path '/nix/store/y7i47qjmf10i1ngpnsavv88zjagypycd-attr-2.4.48' from 'https://cache.nixos.org'...
copying path '/nix/store/dj6n505iqrk7srn96a27jfp3i0zgwa1l-acl-2.2.53' from 'https://cache.nixos.org'...
copying path '/nix/store/w9wc0d31p4z93cbgxijws03j5s2c4gyf-coreutils-8.31' from 'https://cache.nixos.org'...
copying path '/nix/store/ifayp0kvijq0n4x0bv51iqrb0yzyz77g-perl-5.32.0' from 'https://cache.nixos.org'...
copying path '/nix/store/z45mp61h51ksxz28gds5110rf3wmqpdc-perl5.32.0-ack-3.3.1' from 'https://cache.nixos.org'...
building '/nix/store/m0rl62grplq7w7k3zqhlcz2hs99y332l-user-environment.drv'...
created 49 symlinks in user environment
real	0m 5.60s
user	0m 3.21s
sys	0m 1.66s
</code></pre>

<p></details></p>

<p><details>
<summary>
Debian’s apt takes almost 10 seconds to fetch and unpack 16 MB.
</summary></p>

<pre><code>% docker run -t -i debian:sid
root@1996bb94a2d1:/# time (apt update &amp;&amp; apt install -y ack-grep)
Get:1 http://deb.debian.org/debian sid InRelease [146 kB]
Get:2 http://deb.debian.org/debian sid/main amd64 Packages [8400 kB]
Fetched 8546 kB in 1s (8088 kB/s)
[…]
The following NEW packages will be installed:
  ack libfile-next-perl libgdbm-compat4 libgdbm6 libperl5.30 netbase perl perl-modules-5.30
0 upgraded, 8 newly installed, 0 to remove and 23 not upgraded.
Need to get 7341 kB of archives.
After this operation, 46.7 MB of additional disk space will be used.
[…]
real	0m9.544s
user	0m2.839s
sys	0m0.775s
</code></pre>

<p></details></p>

<p><details>
<summary>
Arch Linux’s pacman takes a little under 3s to fetch and unpack 6.5 MB.
</summary></p>

<pre><code>% docker run -t -i archlinux/base
[root@9f6672688a64 /]# time (pacman -Sy &amp;&amp; pacman -S --noconfirm ack)
:: Synchronizing package databases...
 core            130.8 KiB  1090 KiB/s 00:00
 extra          1655.8 KiB  3.48 MiB/s 00:00
 community         5.2 MiB  6.11 MiB/s 00:01
resolving dependencies...
looking for conflicting packages...

Packages (2) perl-file-next-1.18-2  ack-3.4.0-1

Total Download Size:   0.07 MiB
Total Installed Size:  0.19 MiB
[…]
real	0m2.936s
user	0m0.375s
sys	0m0.160s
</code></pre>

<p></details></p>

<p><details>
<summary>
Alpine’s apk takes a little over 1 second to fetch and unpack 10 MB.
</summary></p>

<pre><code>% docker run -t -i alpine
fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.12/community/x86_64/APKINDEX.tar.gz
(1/4) Installing libbz2 (1.0.8-r1)
(2/4) Installing perl (5.30.3-r0)
(3/4) Installing perl-file-next (1.18-r0)
(4/4) Installing ack (3.3.1-r0)
Executing busybox-1.31.1-r16.trigger
OK: 43 MiB in 18 packages
real	0m 1.24s
user	0m 0.40s
sys	0m 0.15s
</code></pre>

<p></details></p>

<h4 id="qemu">qemu</h4>

<p>You can expand each of these:</p>

<p><details>
<summary>
Fedora’s dnf takes over 4 minutes to fetch and unpack 226 MB.
</summary></p>

<pre><code>% docker run -t -i fedora /bin/bash
[root@6a52ecfc3afa /]# time dnf install -y qemu
Fedora 32 openh264 (From Cisco) - x86_64     3.1 kB/s | 2.5 kB     00:00
Fedora Modular 32 - x86_64                   6.3 MB/s | 4.9 MB     00:00
Fedora Modular 32 - x86_64 - Updates         6.0 MB/s | 3.7 MB     00:00
Fedora 32 - x86_64 - Updates                 334 kB/s |  23 MB     01:10
Fedora 32 - x86_64                            33 MB/s |  70 MB     00:02
[…]

Total download size: 181 M
Downloading Packages:
[…]

real	4m37.652s
user	0m38.239s
sys	0m6.321s
</code></pre>

<p></details></p>

<p><details>
<summary>
NixOS’s Nix takes almost 34s to fetch and unpack 180 MB.
</summary></p>

<pre><code>% docker run -t -i nixos/nix
83971cf79f7e:/# time sh -c 'nix-channel --update &amp;&amp; nix-env -iA nixpkgs.qemu'
unpacking channels...
created 1 symlinks in user environment
installing 'qemu-5.1.0'
these paths will be fetched (180.70 MiB download, 1146.92 MiB unpacked):
[…]
real	0m 33.64s
user	0m 16.96s
sys	0m 3.05s
</code></pre>

<p></details></p>

<p><details>
<summary>
Debian’s apt takes over 95 seconds to fetch and unpack 224 MB.
</summary></p>

<pre><code>% docker run -t -i debian:sid
root@b7cc25a927ab:/# time (apt update &amp;&amp; apt install -y qemu-system-x86)
Get:1 http://deb.debian.org/debian sid InRelease [146 kB]
Get:2 http://deb.debian.org/debian sid/main amd64 Packages [8400 kB]
Fetched 8546 kB in 1s (5998 kB/s)
[…]
Fetched 216 MB in 43s (5006 kB/s)
[…]
real	1m25.375s
user	0m29.163s
sys	0m12.835s
</code></pre>

<p></details></p>

<p><details>
<summary>
Arch Linux’s pacman takes almost 44s to fetch and unpack 142 MB.
</summary></p>

<pre><code>% docker run -t -i archlinux/base
[root@58c78bda08e8 /]# time (pacman -Sy &amp;&amp; pacman -S --noconfirm qemu)
:: Synchronizing package databases...
 core          130.8 KiB  1055 KiB/s 00:00
 extra        1655.8 KiB  3.70 MiB/s 00:00
 community       5.2 MiB  7.89 MiB/s 00:01
[…]
Total Download Size:   135.46 MiB
Total Installed Size:  661.05 MiB
[…]
real	0m43.901s
user	0m4.980s
sys	0m2.615s
</code></pre>

<p></details></p>

<p><details>
<summary>
Alpine’s apk takes only about 2.4 seconds to fetch and unpack 26 MB.
</summary></p>

<pre><code>% docker run -t -i alpine
/ # time apk add qemu-system-x86_64
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/community/x86_64/APKINDEX.tar.gz
[…]
OK: 78 MiB in 95 packages
real	0m 2.43s
user	0m 0.46s
sys	0m 0.09s
</code></pre>

<p></details></p>

<h3 id="appendix-b">Appendix B: measurement details (2019)</h3>

<h4 id="ack-1">ack</h4>

<p>You can expand each of these:</p>

<p><details>
<summary>
Fedora’s dnf takes almost 30 seconds to fetch and unpack 107 MB.
</summary></p>

<pre><code>% docker run -t -i fedora /bin/bash
[root@722e6df10258 /]# time dnf install -y ack
Fedora Modular 30 - x86_64            4.4 MB/s | 2.7 MB     00:00
Fedora Modular 30 - x86_64 - Updates  3.7 MB/s | 2.4 MB     00:00
Fedora 30 - x86_64 - Updates           17 MB/s |  19 MB     00:01
Fedora 30 - x86_64                     31 MB/s |  70 MB     00:02
[…]
Install  44 Packages

Total download size: 13 M
Installed size: 42 M
[…]
real	0m29.498s
user	0m22.954s
sys	0m1.085s
</code></pre>

<p></details></p>

<p><details>
<summary>
NixOS’s Nix takes 14s to fetch and unpack 15 MB.
</summary></p>

<pre><code>% docker run -t -i nixos/nix
39e9186422ba:/# time sh -c 'nix-channel --update &amp;&amp; nix-env -i perl5.28.2-ack-2.28'
unpacking channels...
created 2 symlinks in user environment
installing 'perl5.28.2-ack-2.28'
these paths will be fetched (14.91 MiB download, 80.83 MiB unpacked):
  /nix/store/57iv2vch31v8plcjrk97lcw1zbwb2n9r-perl-5.28.2
  /nix/store/89gi8cbp8l5sf0m8pgynp2mh1c6pk1gk-attr-2.4.48
  /nix/store/gkrpl3k6s43fkg71n0269yq3p1f0al88-perl5.28.2-ack-2.28-man
  /nix/store/iykxb0bmfjmi7s53kfg6pjbfpd8jmza6-glibc-2.27
  /nix/store/k8lhqzpaaymshchz8ky3z4653h4kln9d-coreutils-8.31
  /nix/store/svgkibi7105pm151prywndsgvmc4qvzs-acl-2.2.53
  /nix/store/x4knf14z1p0ci72gl314i7vza93iy7yc-perl5.28.2-File-Next-1.16
  /nix/store/zfj7ria2kwqzqj9dh91kj9kwsynxdfk0-perl5.28.2-ack-2.28
copying path '/nix/store/gkrpl3k6s43fkg71n0269yq3p1f0al88-perl5.28.2-ack-2.28-man' from 'https://cache.nixos.org'...
copying path '/nix/store/iykxb0bmfjmi7s53kfg6pjbfpd8jmza6-glibc-2.27' from 'https://cache.nixos.org'...
copying path '/nix/store/x4knf14z1p0ci72gl314i7vza93iy7yc-perl5.28.2-File-Next-1.16' from 'https://cache.nixos.org'...
copying path '/nix/store/89gi8cbp8l5sf0m8pgynp2mh1c6pk1gk-attr-2.4.48' from 'https://cache.nixos.org'...
copying path '/nix/store/svgkibi7105pm151prywndsgvmc4qvzs-acl-2.2.53' from 'https://cache.nixos.org'...
copying path '/nix/store/k8lhqzpaaymshchz8ky3z4653h4kln9d-coreutils-8.31' from 'https://cache.nixos.org'...
copying path '/nix/store/57iv2vch31v8plcjrk97lcw1zbwb2n9r-perl-5.28.2' from 'https://cache.nixos.org'...
copying path '/nix/store/zfj7ria2kwqzqj9dh91kj9kwsynxdfk0-perl5.28.2-ack-2.28' from 'https://cache.nixos.org'...
building '/nix/store/q3243sjg91x1m8ipl0sj5gjzpnbgxrqw-user-environment.drv'...
created 56 symlinks in user environment
real	0m 14.02s
user	0m 8.83s
sys	0m 2.69s
</code></pre>

<p></details></p>

<p><details>
<summary>
Debian’s apt takes almost 10 seconds to fetch and unpack 16 MB.
</summary></p>

<pre><code>% docker run -t -i debian:sid
root@b7cc25a927ab:/# time (apt update &amp;&amp; apt install -y ack-grep)
Get:1 http://cdn-fastly.deb.debian.org/debian sid InRelease [233 kB]
Get:2 http://cdn-fastly.deb.debian.org/debian sid/main amd64 Packages [8270 kB]
Fetched 8502 kB in 2s (4764 kB/s)
[…]
The following NEW packages will be installed:
  ack ack-grep libfile-next-perl libgdbm-compat4 libgdbm5 libperl5.26 netbase perl perl-modules-5.26
The following packages will be upgraded:
  perl-base
1 upgraded, 9 newly installed, 0 to remove and 60 not upgraded.
Need to get 8238 kB of archives.
After this operation, 42.3 MB of additional disk space will be used.
[…]
real	0m9.096s
user	0m2.616s
sys	0m0.441s
</code></pre>

<p></details></p>

<p><details>
<summary>
Arch Linux’s pacman takes a little over 3s to fetch and unpack 6.5 MB.
</summary></p>

<pre><code>% docker run -t -i archlinux/base
[root@9604e4ae2367 /]# time (pacman -Sy &amp;&amp; pacman -S --noconfirm ack)
:: Synchronizing package databases...
 core            132.2 KiB  1033K/s 00:00
 extra          1629.6 KiB  2.95M/s 00:01
 community         4.9 MiB  5.75M/s 00:01
[…]
Total Download Size:   0.07 MiB
Total Installed Size:  0.19 MiB
[…]
real	0m3.354s
user	0m0.224s
sys	0m0.049s
</code></pre>

<p></details></p>

<p><details>
<summary>
Alpine’s apk takes only about 1 second to fetch and unpack 10 MB.
</summary></p>

<pre><code>% docker run -t -i alpine
/ # time apk add ack
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/community/x86_64/APKINDEX.tar.gz
(1/4) Installing perl-file-next (1.16-r0)
(2/4) Installing libbz2 (1.0.6-r7)
(3/4) Installing perl (5.28.2-r1)
(4/4) Installing ack (3.0.0-r0)
Executing busybox-1.30.1-r2.trigger
OK: 44 MiB in 18 packages
real	0m 0.96s
user	0m 0.25s
sys	0m 0.07s
</code></pre>

<p></details></p>

<h4 id="qemu-1">qemu</h4>

<p>You can expand each of these:</p>

<p><details>
<summary>
Fedora’s dnf takes over a minute to fetch and unpack 266 MB.
</summary></p>

<pre><code>% docker run -t -i fedora /bin/bash
[root@722e6df10258 /]# time dnf install -y qemu
Fedora Modular 30 - x86_64            3.1 MB/s | 2.7 MB     00:00
Fedora Modular 30 - x86_64 - Updates  2.7 MB/s | 2.4 MB     00:00
Fedora 30 - x86_64 - Updates           20 MB/s |  19 MB     00:00
Fedora 30 - x86_64                     31 MB/s |  70 MB     00:02
[…]
Install  262 Packages
Upgrade    4 Packages

Total download size: 172 M
[…]
real	1m7.877s
user	0m44.237s
sys	0m3.258s
</code></pre>

<p></details></p>

<p><details>
<summary>
NixOS’s Nix takes 38s to fetch and unpack 262 MB.
</summary></p>

<pre><code>% docker run -t -i nixos/nix
39e9186422ba:/# time sh -c 'nix-channel --update &amp;&amp; nix-env -i qemu-4.0.0'
unpacking channels...
created 2 symlinks in user environment
installing 'qemu-4.0.0'
these paths will be fetched (262.18 MiB download, 1364.54 MiB unpacked):
[…]
real	0m 38.49s
user	0m 26.52s
sys	0m 4.43s
</code></pre>

<p></details></p>

<p><details>
<summary>
Debian’s apt takes 51 seconds to fetch and unpack 159 MB.
</summary></p>

<pre><code>% docker run -t -i debian:sid
root@b7cc25a927ab:/# time (apt update &amp;&amp; apt install -y qemu-system-x86)
Get:1 http://cdn-fastly.deb.debian.org/debian sid InRelease [149 kB]
Get:2 http://cdn-fastly.deb.debian.org/debian sid/main amd64 Packages [8426 kB]
Fetched 8574 kB in 1s (6716 kB/s)
[…]
Fetched 151 MB in 2s (64.6 MB/s)
[…]
real	0m51.583s
user	0m15.671s
sys	0m3.732s
</code></pre>

<p></details></p>

<p><details>
<summary>
Arch Linux’s pacman takes 1m2s to fetch and unpack 124 MB.
</summary></p>

<pre><code>% docker run -t -i archlinux/base
[root@9604e4ae2367 /]# time (pacman -Sy &amp;&amp; pacman -S --noconfirm qemu)
:: Synchronizing package databases...
 core       132.2 KiB   751K/s 00:00
 extra     1629.6 KiB  3.04M/s 00:01
 community    4.9 MiB  6.16M/s 00:01
[…]
Total Download Size:   123.20 MiB
Total Installed Size:  587.84 MiB
[…]
real	1m2.475s
user	0m9.272s
sys	0m2.458s
</code></pre>

<p></details></p>

<p><details>
<summary>
Alpine’s apk takes only about 2.4 seconds to fetch and unpack 26 MB.
</summary></p>

<pre><code>% docker run -t -i alpine
/ # time apk add qemu-system-x86_64
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/community/x86_64/APKINDEX.tar.gz
[…]
OK: 78 MiB in 95 packages
real	0m 2.43s
user	0m 0.46s
sys	0m 0.09s
</code></pre>

<p></details></p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Linux distributions: Can we do without hooks and triggers?]]></title>
    <link href="https://michael.stapelberg.ch/posts/2019-07-20-hooks-and-triggers/"/>
    <id>https://michael.stapelberg.ch/posts/2019-07-20-hooks-and-triggers/</id>
    <published>2019-07-20T00:00:00+00:00</published>
    <updated>2020-08-12T10:08:02+02:00</updated>
    <content type="html"><![CDATA[

<p>Hooks are an extension feature provided by all package managers that are used in
larger Linux distributions. For example, Debian uses apt, which has various
<a href="https://www.debian.org/doc/debian-policy/ap-flowcharts.html">maintainer
scripts</a>. Fedora
uses rpm, which has
<a href="https://fedoraproject.org/wiki/Packaging:Scriptlets">scriptlets</a>. Different
package managers use different names for the concept, but all of them offer
package maintainers the ability to run arbitrary code during package
installation and upgrades. Example hook use cases include adding daemon user
accounts to your system (e.g. <code>postgres</code>), or generating/updating cache files.</p>

<p>Triggers are a kind of hook which run when <em>other</em> packages are installed. For
example, on Debian, the <a href="https://manpages.debian.org/man.1"><code>man(1)</code></a> package
comes with a trigger which regenerates the search database index whenever any
package installs a manpage. When, for example, the
<a href="https://manpages.debian.org/nginx.8"><code>nginx(8)</code></a> package is installed, a
trigger provided by the <a href="https://manpages.debian.org/man.1"><code>man(1)</code></a> package
runs.</p>

<p>Over the past few decades, Open Source software has become more and more
uniform: instead of each piece of software defining its own rules, a small
number of build systems are now widely adopted.</p>

<p>Hence, I think it makes sense to revisit whether offering extension via hooks
and triggers is a net win or net loss.</p>

<h3 id="hooks-preclude-concurrent-package-installation">Hooks preclude concurrent package installation</h3>

<p>Package managers commonly can make very little assumptions about what hooks do,
what preconditions they require, and which conflicts might be caused by running
multiple package’s hooks concurrently.</p>

<p>Hence, package managers cannot concurrently install packages. At least the
hook/trigger part of the installation needs to happen in sequence.</p>

<p>While it seems technically feasible to retrofit package manager hooks with
concurrency primitives such as locks for mutual exclusion between different hook
processes, the required overhaul of all hooks¹ seems like such a daunting task
that it might be better to just get rid of the hooks instead. Only deleting code
frees you from the burden of maintenance, automated testing and debugging.</p>

<p>① In Debian, there are 8620 non-generated maintainer scripts, as reported by
   <code>find shard*/src/*/debian -regex &quot;.*\(pre\|post\)\(inst\|rm\)$&quot;</code> on a Debian
   Code Search instance.</p>

<h3 id="triggers-slow-down-installing-updating-other-packages">Triggers slow down installing/updating other packages</h3>

<p>Personally, I never use the
<a href="https://manpages.debian.org/apropos.1"><code>apropos(1)</code></a> command, so I don’t
appreciate the <a href="https://manpages.debian.org/man.1"><code>man(1)</code></a> package’s trigger
which updates the database used by
<a href="https://manpages.debian.org/apropos.1"><code>apropos(1)</code></a>. The process takes a long
time and, because hooks and triggers must be executed serially (see previous
section), blocks my installation or update.</p>

<p>When I tell people this, they are often surprised to learn about the existance
of the <a href="https://manpages.debian.org/apropos.1"><code>apropos(1)</code></a> command. I suggest
adopting an opt-in model.</p>

<h3 id="unnecessary-work-if-programs-are-not-used-between-updates">Unnecessary work if programs are not used between updates</h3>

<p>Hooks run when packages are installed. If a package’s contents are not used
between two updates, running the hook in the first update could have been
skipped. Running the hook lazily when the package contents are used reduces
unnecessary work.</p>

<p>As a welcome side-effect, lazy hook evaluation automatically makes the hook work
in operating system images, such as live USB thumb drives or SD card images for
the Raspberry Pi. Such images must not ship the same crypto keys (e.g. OpenSSH
host keys) to all machines, but instead generate a different key on each
machine.</p>

<p>Why do users keep packages installed they don’t use? It’s extra work to remember
and clean up those packages after use. Plus, users might not realize or value
that having fewer packages installed has benefits such as faster updates.</p>

<p>I can also imagine that there are people for whom the cost of re-installing
packages incentivizes them to just keep packages installed—you never know when
you might need the program again…</p>

<h3 id="implemented-in-an-interpreted-language">Implemented in an interpreted language</h3>

<p>While working on hermetic packages (more on that in another blog post), where
the contained programs are started with modified environment variables
(e.g. <code>PATH</code>) via a wrapper bash script, I noticed that the overhead of those
wrapper bash scripts quickly becomes significant. For example, when using the
excellent <a href="https://magit.vc/">magit</a> interface for Git in Emacs, I encountered
second-long delays² when using hermetic packages compared to standard
packages. Re-implementing wrappers in a compiled language provided a significant
speed-up.</p>

<p>Similarly, getting rid of an extension point which mandates using shell scripts
allows us to build an efficient and fast implementation of a predefined set of
primitives, where you can reason about their effects and interactions.</p>

<p>② magit needs to run git a few times for displaying the full status, so small
   overhead quickly adds up.</p>

<h3 id="incentivizing-more-upstream-standardization">Incentivizing more upstream standardization</h3>

<p>Hooks are an escape hatch for distribution maintainers to express anything which
their packaging system cannot express.</p>

<p>Distributions should only rely on well-established interfaces such as autoconf’s
classic <code>./configure &amp;&amp; make &amp;&amp; make install</code> (including commonly used flags) to
build a distribution package. Integrating upstream software into a distribution
should not require custom hooks. For example, instead of requiring a hook which
updates a cache of schema files, the library used to interact with those files
should transparently (re-)generate the cache or fall back to a slower code path.</p>

<p>Distribution maintainers are hard to come by, so we should value their time. In
particular, there is a 1:n relationship of packages to distribution package
maintainers (software is typically available in multiple Linux distributions),
so it makes sense to spend the work in the 1 and have the n benefit.</p>

<h3 id="can-we-do-without-them">Can we do without them?</h3>

<p>If we want to get rid of hooks, we need another mechanism to achieve what we
currently achieve with hooks.</p>

<p>If the hook is not specific to the package, it can be moved to the package
manager. The desired system state should either be derived from the package
contents (e.g. required system users can be discovered from systemd service
files) or declaratively specified in the package build instructions—more on that
in another blog post. This turns hooks (arbitrary code) into configuration,
which allows the package manager to collapse and sequence the required state
changes. E.g., when 5 packages are installed which each need a new system user,
the package manager could update <code>/etc/passwd</code> just once.</p>

<p>If the hook is specific to the package, it should be moved into the package
contents. This typically means moving the functionality into the program start
(or the systemd service file if we are talking about a daemon). If (while?)
upstream is not convinced, you can either wrap the program or patch it. Note
that this case is relatively rare: I have worked with hundreds of packages and
the only package-specific functionality I came across was automatically
generating host keys before starting OpenSSH’s
<a href="https://manpages.debian.org/sshd.8"><code>sshd(8)</code></a>³.</p>

<p>There is one exception where moving the hook doesn’t work: packages which modify
state outside of the system, such as bootloaders or kernel images.</p>

<p>③ Even that can be moved out of a package-specific hook, <a href="https://src.fedoraproject.org/rpms/openssh/blob/30922f629cc135e3233e263d5e3eb346f9251c4e/f/sshd-keygen%40.service">as Fedora
demonstrates</a>.</p>

<h3 id="conclusion">Conclusion</h3>

<p>Global state modifications performed as part of package installation today use
hooks, an overly expressive extension mechanism.</p>

<p>Instead, all modifications should be driven by configuration. This is feasible
because there are only a few different kinds of desired state
modifications. This makes it possible for package managers to optimize package
installation.</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Optional dependencies don’t work]]></title>
    <link href="https://michael.stapelberg.ch/posts/2019-05-23-optional-dependencies/"/>
    <id>https://michael.stapelberg.ch/posts/2019-05-23-optional-dependencies/</id>
    <published>2019-05-23T00:00:00+00:00</published>
    <updated>2020-08-12T10:08:02+02:00</updated>
    <content type="html"><![CDATA[

<p>In the i3 projects, we have always tried hard to avoid optional
dependencies. There are a number of reasons behind it, and as I have recently
encountered some of the downsides of optional dependencies firsthand, I
summarized my thoughts in this article.</p>

<h3 id="what-is-a-compile-time-optional-dependency">What is a (compile-time) optional dependency?</h3>

<p>When building software from source, most programming languages and build systems
support conditional compilation: different parts of the source code are compiled
based on certain conditions.</p>

<p>An optional dependency is conditional compilation hooked up directly to a knob
(e.g. command line flag, configuration file, …), with the effect that the
software can now be built without an otherwise required dependency.</p>

<p>Let’s walk through a few issues with optional dependencies.</p>

<h3 id="inconsistent-experience-in-different-environments">Inconsistent experience in different environments</h3>

<p>Software is usually not built by end users, but by packagers, at least when we
are talking about Open Source.</p>

<p>Hence, end users don’t see the knob for the optional dependency, they are just
presented with the fait accompli: their version of the software behaves
differently than other versions of the same software.</p>

<p>Depending on the kind of software, this situation can be made obvious to the
user: for example, if the optional dependency is needed to print documents, the
program can produce an appropriate error message when the user tries to print a
document.</p>

<p>Sometimes, this isn’t possible: when i3 introduced an optional dependency on
cairo and pangocairo, the behavior itself (rendering window titles) worked in
all configurations, but non-ASCII characters might break depending on whether i3
was compiled with cairo.</p>

<p>For users, it is frustrating to only discover in conversation that a program has
a feature that the user is interested in, but it’s not available on their
computer. For support, this situation can be hard to detect, and even harder to
resolve to the user’s satisfaction.</p>

<h3 id="packaging-is-more-complicated">Packaging is more complicated</h3>

<p>Unfortunately, many build systems don’t stop the build when optional
dependencies are not present. Instead, you sometimes end up with a broken build,
or, even worse: with a successful build that does not work correctly at runtime.</p>

<p>This means that packagers need to closely examine the build output to know which
dependencies to make available. In the best case, there is a summary of
available and enabled options, clearly outlining what this build will
contain. In the worst case, you need to infer the features from the checks that
are done, or work your way through the <code>--help</code> output.</p>

<p>The better alternative is to configure your build system such that it stops when
<em>any</em> dependency was not found, and thereby have packagers acknowledge each
optional dependency by explicitly disabling the option.</p>

<h3 id="untested-code-paths-bit-rot">Untested code paths bit rot</h3>

<p>Code paths which are not used will inevitably bit rot. If you have optional
dependencies, you need to test both the code path without the dependency and the
code path with the dependency. It doesn’t matter whether the tests are automated
or manual, the test matrix must cover both paths.</p>

<p>Interestingly enough, this principle seems to apply to all kinds of software
projects (but it slows down as change slows down): one might think that
important Open Source building blocks should have enough users to cover all
sorts of configurations.</p>

<p>However, consider this example: building cairo without libxrender results in all
GTK application windows, menus, etc. being displayed as empty grey
surfaces. Cairo does not fail to build without libxrender, but the code path
clearly is broken without libxrender.</p>

<h3 id="can-we-do-without-them">Can we do without them?</h3>

<p>I’m not saying optional dependencies should <em>never</em> be used. In fact, for
bootstrapping, disabling dependencies can save a lot of work and can sometimes
allow breaking circular dependencies. For example, in an early bootstrapping
stage, binutils can be compiled with <code>--disable-nls</code> to disable
internationalization.</p>

<p>However, optional dependencies are broken so often that I conclude they are
overused. Read on and see for yourself whether you would rather commit to best
practices or not introduce an optional dependency.</p>

<h3 id="best-practices">Best practices</h3>

<p>If you do decide to make dependencies optional, please:</p>

<ol>
<li>Set up automated testing for <strong>all</strong> code path combinations.</li>
<li>Fail the build until packagers explicitly pass a <code>--disable</code> flag.</li>
<li>Tell users their version is missing a dependency at runtime, e.g. in <code>--version</code>.</li>
</ol>
]]></content>
  </entry>
</feed>
