<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Michael Stapelbergs Website: posts tagged distri</title>
  <link href="https://michael.stapelberg.ch/posts/tags/distri/feed.xml" rel="self"/>
  <link href="https://michael.stapelberg.ch/posts/tags/distri/"/>
  <updated>2020-01-21T17:50:00+01:00</updated>
  <id>https://michael.stapelberg.ch/posts/tags/distri/</id>
  <generator>Hugo -- gohugo.io</generator>
  <entry>
    <title type="html"><![CDATA[distri: 20x faster initramfs (initrd) from scratch]]></title>
    <link href="https://michael.stapelberg.ch/posts/2020-01-21-initramfs-from-scratch-golang/"/>
    <id>https://michael.stapelberg.ch/posts/2020-01-21-initramfs-from-scratch-golang/</id>
    <published>2020-01-21T17:50:00+01:00</published>
    <updated>2020-01-21T18:20:06+01:00</updated>
    <content type="html"><![CDATA[

<p>In case you are not yet familiar with why an initramfs (or initrd, or initial
ramdisk) is typically used when starting Linux, let me quote the <a href="https://en.wikipedia.org/wiki/Initial_ramdisk">wikipedia
definition</a>:</p>

<p>“[…] initrd is a scheme for loading a temporary root file system into memory,
which may be used as part of the Linux startup process […] to make preparations
before the real root file system can be mounted.”</p>

<p>Many Linux distributions do not compile all file system drivers into the kernel,
but instead load them on-demand from an initramfs, which saves memory.</p>

<p>Another common scenario, in which an initramfs is required, is full-disk
encryption: the disk must be unlocked from userspace, but since userspace is
encrypted, an initramfs is used.</p>

<h2 id="motivation">Motivation</h2>

<p>Thus far, building a <a href="https://distr1.org/">distri</a> disk image was quite slow:</p>

<p>This is on an AMD Ryzen 3900X 12-core processor (2019):</p>

<pre><code>distri % time make cryptimage serial=1
80.29s user 13.56s system 186% cpu 50.419 total # 19s image, 31s initrd
</code></pre>

<p>Of these 50 seconds,
<a href="https://en.wikipedia.org/wiki/Dracut_(software)"><code>dracut</code></a>’s initramfs
generation accounts for 31 seconds (62%)!</p>

<p>Initramfs generation time drops to 8.7 seconds once <code>dracut</code> no longer needs to
use the single-threaded <a href="https://manpages.debian.org/gzip.1"><code>gzip(1)</code></a>
, but the
multi-threaded replacement <a href="https://manpages.debian.org/pigz.1"><code>pigz(1)</code></a>
:</p>

<p>This brings the total time to build a distri disk image down to:</p>

<pre><code>distri % time make cryptimage serial=1
76.85s user 13.23s system 327% cpu 27.509 total # 19s image, 8.7s initrd
</code></pre>

<p>Clearly, when you use <code>dracut</code> on any modern computer, you should make pigz
available. <code>dracut</code> should fail to compile unless one explicitly opts into the
known-slower gzip. For more thoughts on optional dependencies, see <a href="/posts/2019-05-23-optional-dependencies/">“Optional
dependencies don’t work”</a>.</p>

<p>But why does it take 8.7 seconds still? Can we go faster?</p>

<p>The answer is <strong>Yes</strong>! I recently built a distri-specific initramfs I’m calling
<code>minitrd</code>. I wrote both big parts from scratch:</p>

<ol>
<li>the initramfs generator program (<a href="https://github.com/distr1/distri/blob/master/cmd/distri/initrd.go"><code>distri initrd</code></a>)</li>
<li>a custom Go userland (<a href="https://github.com/distr1/distri/blob/master/cmd/minitrd/minitrd.go"><code>cmd/minitrd</code></a>), running as <code>/init</code> in the initramfs.</li>
</ol>

<p><code>minitrd</code> generates the initramfs image in ≈400ms, bringing the total time down
to:</p>

<pre><code>distri % time make cryptimage serial=1
50.09s user 8.80s system 314% cpu 18.739 total # 18s image, 400ms initrd
</code></pre>

<p>(The remaining time is spent in preparing the file system, then installing and
configuring the distri system, i.e. preparing a disk image you can <a href="https://distr1.org/#run-distri-on-real-hardware">run on real
hardware</a>.)</p>

<p>How can <code>minitrd</code> be 20 times faster than <code>dracut</code>?</p>

<p><code>dracut</code> is mainly written in shell, with a C helper program. It drives the
generation process by spawning lots of external dependencies (e.g. <code>ldd</code> or the
<code>dracut-install</code> helper program). I assume that the combination of using an
interpreted language (shell) that spawns lots of processes and precludes a
concurrent architecture is to blame for the poor performance.</p>

<p><code>minitrd</code> is written in Go, with speed as a goal. It leverages concurrency and
uses no external dependencies; everything happens within a single process (but
with enough threads to saturate modern hardware).</p>

<p>Measuring early boot time using qemu, I measured the <code>dracut</code>-generated
initramfs taking 588ms to display the full disk encryption passphrase prompt,
whereas <code>minitrd</code> took only 195ms.</p>

<p>The rest of this article dives deeper into how <code>minitrd</code> works.</p>

<h2 id="what-does-an-initramfs-do">What does an initramfs do?</h2>

<p>Ultimately, the job of an initramfs is to make the root file system available
and continue booting the system from there. Depending on the system setup, this
involves the following 5 steps:</p>

<h3 id="1-load-kernel-modules-to-access-the-block-devices-with-the-root-file-system">1. Load kernel modules to access the block devices with the root file system</h3>

<p>Depending on the system, the block devices with the root file system might
already be present when the initramfs runs, or some kernel modules might need to
be loaded first. On my Dell XPS 9360 laptop, the NVMe system disk is already
present when the initramfs starts, whereas in qemu, we need to load the
<code>virtio_pci</code> module, followed by the <code>virtio_scsi</code> module.</p>

<p>How will our userland program know which kernel modules to load? Linux kernel
modules declare patterns for their supported hardware as an alias, e.g.:</p>

<pre><code>initrd# grep virtio_pci lib/modules/5.4.6/modules.alias
alias pci:v00001AF4d*sv*sd*bc*sc*i* virtio_pci
</code></pre>

<p>Devices in <code>sysfs</code> have a <code>modalias</code> file whose content can be matched against
these declarations to identify the module to load:</p>

<pre><code>initrd# cat /sys/devices/pci0000:00/*/modalias
pci:v00001AF4d00001005sv00001AF4sd00000004bc00scFFi00
pci:v00001AF4d00001004sv00001AF4sd00000008bc01sc00i00
[…]
</code></pre>

<p>Hence, for the initial round of module loading, it is sufficient to locate all
<code>modalias</code> files within <code>sysfs</code> and load the responsible modules.</p>

<p>Loading a kernel module can result in new devices appearing. When that happens,
the kernel sends a
<a href="https://stackoverflow.com/questions/22803469/uevent-sent-from-kernel-to-user-space-udev">uevent</a>,
which the uevent consumer in userspace receives via a netlink socket. Typically,
this consumer is <a href="https://manpages.debian.org/udev.7"><code>udev(7)</code></a>
, but in our case, it’s
<code>minitrd</code>.</p>

<p>For each uevent messages that comes with a <code>MODALIAS</code> variable, <code>minitrd</code> will
load the relevant kernel module(s).</p>

<p>When loading a kernel module, its dependencies need to be loaded
first. Dependency information is stored in the <code>modules.dep</code> file in a
<code>Makefile</code>-like syntax:</p>

<pre><code>initrd# grep virtio_pci lib/modules/5.4.6/modules.dep
kernel/drivers/virtio/virtio_pci.ko: kernel/drivers/virtio/virtio_ring.ko kernel/drivers/virtio/virtio.ko
</code></pre>

<p>To load a module, we can open its file and then call the Linux-specific <a href="https://manpages.debian.org/finit_module.2"><code>finit_module(2)</code></a>
 system call. Some modules are expected to
return an error code, e.g. <code>ENODEV</code> or <code>ENOENT</code> when some hardware device is not
actually present.</p>

<p>Side note: next to the textual versions, there are also binary versions of the
<code>modules.alias</code> and <code>modules.dep</code> files. Presumably, those can be queried more
quickly, but for simplicitly, I have not (yet?) implemented support in
<code>minitrd</code>.</p>

<h3 id="2-console-settings-font-keyboard-layout">2. Console settings: font, keyboard layout</h3>

<p>Setting a legible font is necessary for hi-dpi displays. On my Dell XPS 9360
(3200 x 1800 QHD+ display), the following works well:</p>

<pre><code>initrd# setfont latarcyrheb-sun32
</code></pre>

<p>Setting the user’s keyboard layout is necessary for entering the LUKS full-disk
encryption passphrase in their preferred keyboard layout. I use the <a href="https://www.neo-layout.org">NEO
layout</a>:</p>

<pre><code>initrd# loadkeys neo
</code></pre>

<h3 id="3-block-device-identification">3. Block device identification</h3>

<p>In the Linux kernel, block device enumeration order is not necessarily the same
on each boot. Even if it was deterministic, device order could still be changed
when users modify their computer’s device topology (e.g. connect a new disk to a
formerly unused port).</p>

<p>Hence, it is good style to refer to disks and their partitions with stable
identifiers. This also applies to boot loader configuration, and so most
distributions will set a kernel parameter such as
<code>root=UUID=1fa04de7-30a9-4183-93e9-1b0061567121</code>.</p>

<p>Identifying the block device or partition with the specified <code>UUID</code> is the
initramfs’s job.</p>

<p>Depending on what the device contains, the UUID comes from a different
place. For example, <code>ext4</code> file systems have a UUID field in their file system
superblock, whereas LUKS volumes have a UUID in their LUKS header.</p>

<p>Canonically, probing a device to extract the UUID is done by <code>libblkid</code> from the
<code>util-linux</code> package, but the logic can easily be <a href="https://github.com/distr1/distri/blob/master/cmd/minitrd/blkid.go">re-implemented in other
languages</a>
and changes rarely. <code>minitrd</code> comes with its own implementation to avoid
<a href="https://golang.org/cmd/cgo/">cgo</a> or running the <a href="https://manpages.debian.org/blkid.8"><code>blkid(8)</code></a>
 program.</p>

<h3 id="4-luks-full-disk-encryption-unlocking-only-on-encrypted-systems">4. LUKS full-disk encryption unlocking (only on encrypted systems)</h3>

<p>Unlocking a
<a href="https://en.wikipedia.org/wiki/Linux_Unified_Key_Setup">LUKS</a>-encrypted volume
is done in userspace. The kernel handles the crypto, but reading the metadata,
obtaining the passphrase (or e.g. key material from a file) and setting up the
device mapper table entries are done in user space.</p>

<pre><code>initrd# modprobe algif_skcipher
initrd# cryptsetup luksOpen /dev/sda4 cryptroot1
</code></pre>

<p>After the user entered their passphrase, the root file system can be mounted:</p>

<pre><code>initrd# mount /dev/dm-0 /mnt
</code></pre>

<h3 id="5-continuing-the-boot-process-switch-root">5. Continuing the boot process (switch_root)</h3>

<p>Now that everything is set up, we need to pass execution to the init program on
the root file system with a careful sequence of <a href="https://manpages.debian.org/chdir.2"><code>chdir(2)</code></a>
, <a href="https://manpages.debian.org/mount.2"><code>mount(2)</code></a>
, <a href="https://manpages.debian.org/chroot.2"><code>chroot(2)</code></a>
, <a href="https://manpages.debian.org/chdir.2"><code>chdir(2)</code></a>
 and <a href="https://manpages.debian.org/execve.2"><code>execve(2)</code></a>
 system calls that is explained in <a href="https://github.com/mirror/busybox/blob/9ec836c033fc6e55e80f3309b3e05acdf09bb297/util-linux/switch_root.c#L297">this busybox switch_root
comment</a>.</p>

<pre><code>initrd# mount -t devtmpfs dev /mnt/dev
initrd# exec switch_root -c /dev/console /mnt /init
</code></pre>

<p>To conserve RAM, the files in the temporary file system to which the initramfs
archive is extracted are typically deleted.</p>

<h2 id="how-is-an-initramfs-generated">How is an initramfs generated?</h2>

<p>An initramfs “image” (more accurately: archive) is a compressed
<a href="https://en.wikipedia.org/wiki/Cpio">cpio</a> archive. Typically, gzip compression
is used, but the kernel supports a bunch of different algorithms and
distributions such as <a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=LZ4-Initramfs-Ubuntu-Go-Ahead">Ubuntu are switching to lz4</a>.</p>

<p>Generators typically prepare a temporary directory and feed it to the <a href="https://manpages.debian.org/cpio.1"><code>cpio(1)</code></a>
 program. In <code>minitrd</code>, we read the files into memory
and generate the cpio archive using the
<a href="https://github.com/cavaliercoder/go-cpio">go-cpio</a> package. We use the
<a href="https://github.com/klauspost/pgzip">pgzip</a> package for parallel gzip
compression.</p>

<p>The following files need to go into the cpio archive:</p>

<h3 id="minitrd-go-userland">minitrd Go userland</h3>

<p>The <code>minitrd</code> binary is copied into the cpio archive as <code>/init</code> and will be run
by the kernel after extracting the archive.</p>

<p>Like the rest of distri, <code>minitrd</code> is built statically without cgo, which means
it can be copied as-is into the cpio archive.</p>

<h3 id="linux-kernel-modules">Linux kernel modules</h3>

<p>Aside from the <code>modules.alias</code> and <code>modules.dep</code> metadata files, the kernel
modules themselves reside in e.g. <code>/lib/modules/5.4.6/kernel</code> and need to be
copied into the cpio archive.</p>

<p>Copying all modules results in a ≈80 MiB archive, so it is common to only copy
modules that are relevant to the initramfs’s features. This reduces archive size
to ≈24 MiB.</p>

<p>The filtering relies on hard-coded patterns and module names. For example, disk
encryption related modules are all kernel modules underneath <code>kernel/crypto</code>,
plus <code>kernel/drivers/md/dm-crypt.ko</code>.</p>

<p>When generating a host-only initramfs (works on precisely the computer that
generated it), some initramfs generators look at the currently loaded modules
and just copy those.</p>

<h3 id="console-fonts-and-keymaps">Console Fonts and Keymaps</h3>

<p>The <code>kbd</code> package’s <a href="https://manpages.debian.org/setfont.8"><code>setfont(8)</code></a>
 and <a href="https://manpages.debian.org/loadkeys.1"><code>loadkeys(1)</code></a>
 programs load console fonts and keymaps from
<code>/usr/share/consolefonts</code> and <code>/usr/share/keymaps</code>, respectively.</p>

<p>Hence, these directories need to be copied into the cpio archive. Depending on
whether the initramfs should be generic (work on many computers) or host-only
(works on precisely the computer/settings that generated it), the entire
directories are copied, or only the required font/keymap.</p>

<h3 id="cryptsetup-setfont-loadkeys">cryptsetup, setfont, loadkeys</h3>

<p>These programs are (currently) required because <code>minitrd</code> does not implement
their functionality.</p>

<p>As they are dynamically linked, not only the programs themselves need to be
copied, but also the ELF dynamic linking loader (path stored in the <code>.interp</code>
ELF section) and any ELF library dependencies.</p>

<p>For example, <code>cryptsetup</code> in distri declares the ELF interpreter
<code>/ro/glibc-amd64-2.27-3/out/lib/ld-linux-x86-64.so.2</code> and declares dependencies
on shared libraries <code>libcryptsetup.so.12</code>, <code>libblkid.so.1</code> and others. Luckily,
in distri, packages contain a <code>lib</code> subdirectory containing symbolic links to
the resolved shared library paths (hermetic packaging), so it is sufficient to
mirror the lib directory into the cpio archive, recursing into shared library
dependencies of shared libraries.</p>

<p><code>cryptsetup</code> also requires the GCC runtime library <code>libgcc_s.so.1</code> to be present
at runtime, and will abort with an error message about not being able to call
<a href="https://manpages.debian.org/pthread_cancel.3"><code>pthread_cancel(3)</code></a>
 if it is unavailable.</p>

<h3 id="time-zone-data">time zone data</h3>

<p>To print log messages in the correct time zone, we copy <code>/etc/localtime</code> from
the host into the cpio archive.</p>

<h2 id="minitrd-outside-of-distri">minitrd outside of distri?</h2>

<p>I currently have no desire to make <code>minitrd</code> available outside of
<a href="https://distr1.org/">distri</a>. While the technical challenges (such as extending
the generator to not rely on distri’s hermetic packages) are surmountable, I
don’t want to support people’s initramfs remotely.</p>

<p>Also, I think that people’s efforts should in general be spent on rallying
behind <code>dracut</code> and making it work faster, thereby benefiting all Linux
distributions that use dracut (increasingly more). With <code>minitrd</code>, I have
demonstrated that significant speed-ups are achievable.</p>

<h2 id="conclusion">Conclusion</h2>

<p>It was interesting to dive into how an initramfs really works. I had been
working with the concept for many years, from small tasks such as “debug why the
encrypted root file system is not unlocked” to more complicated tasks such as
“set up a root file system on DRBD for a high-availability setup”. But even with
that sort of experience, I didn’t know all the details, until I was forced to
implement every little thing.</p>

<p>As I suspected going into this exercise, <code>dracut</code> is much slower than it needs
to be. Re-implementing its generation stage in a modern language instead of
shell helps a lot.</p>

<p>Of course, my <code>minitrd</code> does a bit less than <code>dracut</code>, but not drastically
so. The overall architecture is the same.</p>

<p>I hope my effort helps with two things:</p>

<ol>
<li><p>As a teaching implementation: instead of wading through the various
components that make up a modern initramfs (udev, systemd, various shell
scripts, …), people can learn about how an initramfs works in a single place.</p></li>

<li><p>I hope the significant time difference motivates people to improve <code>dracut</code>.</p></li>
</ol>

<h2 id="appendix-qemu-development-environment">Appendix: qemu development environment</h2>

<p>Before writing any Go code, I did some manual prototyping. Learning how other
people prototype is often immensely useful to me, so I’m sharing my notes here.</p>

<p>First, I copied all kernel modules and a statically built busybox binary:</p>

<pre><code>% mkdir -p lib/modules/5.4.6
% cp -Lr /ro/lib/modules/5.4.6/* lib/modules/5.4.6/
% cp ~/busybox-1.22.0-amd64/busybox sh
</code></pre>

<p>To generate an initramfs from the current directory, I used:</p>

<pre><code>% find . | cpio -o -H newc | pigz &gt; /tmp/initrd
</code></pre>

<p>In distri’s <code>Makefile</code>, I append these flags to the <code>QEMU</code> invocation:</p>

<pre><code>-kernel /tmp/kernel \
-initrd /tmp/initrd \
-append &quot;root=/dev/mapper/cryptroot1 rdinit=/sh ro console=ttyS0,115200 rd.luks=1 rd.luks.uuid=63051f8a-54b9-4996-b94f-3cf105af2900 rd.luks.name=63051f8a-54b9-4996-b94f-3cf105af2900=cryptroot1 rd.vconsole.keymap=neo rd.vconsole.font=latarcyrheb-sun32 init=/init systemd.setenv=PATH=/bin rw vga=836&quot;
</code></pre>

<p>The <code>vga=</code> mode parameter is required for loading font <code>latarcyrheb-sun32</code>.</p>

<p>Once in the <code>busybox</code> shell, I manually prepared the required mount points and
kernel modules:</p>

<pre><code>ln -s sh mount
ln -s sh lsmod
mkdir /proc /sys /run /mnt
mount -t proc proc /proc
mount -t sysfs sys /sys
mount -t devtmpfs dev /dev
modprobe virtio_pci
modprobe virtio_scsi
</code></pre>

<p>As a next step, I copied <code>cryptsetup</code> and dependencies into the initramfs directory:</p>

<pre><code>% for f in /ro/cryptsetup-amd64-2.0.4-6/lib/*; do full=$(readlink -f $f); rel=$(echo $full | sed 's,^/,,g'); mkdir -p $(dirname $rel); install $full $rel; done
% ln -s ld-2.27.so ro/glibc-amd64-2.27-3/out/lib/ld-linux-x86-64.so.2
% cp /ro/glibc-amd64-2.27-3/out/lib/ld-2.27.so ro/glibc-amd64-2.27-3/out/lib/ld-2.27.so
% cp -r /ro/cryptsetup-amd64-2.0.4-6/lib ro/cryptsetup-amd64-2.0.4-6/
% mkdir -p ro/gcc-libs-amd64-8.2.0-3/out/lib64/
% cp /ro/gcc-libs-amd64-8.2.0-3/out/lib64/libgcc_s.so.1 ro/gcc-libs-amd64-8.2.0-3/out/lib64/libgcc_s.so.1
% ln -s /ro/gcc-libs-amd64-8.2.0-3/out/lib64/libgcc_s.so.1 ro/cryptsetup-amd64-2.0.4-6/lib
% cp -r /ro/lvm2-amd64-2.03.00-6/lib ro/lvm2-amd64-2.03.00-6/
</code></pre>

<p>In <code>busybox</code>, I used the following commands to unlock the root file system:</p>

<pre><code>modprobe algif_skcipher
./cryptsetup luksOpen /dev/sda4 cryptroot1
mount /dev/dm-0 /mnt
</code></pre>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[distri: a Linux distribution to research fast package management]]></title>
    <link href="https://michael.stapelberg.ch/posts/2019-08-17-introducing-distri/"/>
    <id>https://michael.stapelberg.ch/posts/2019-08-17-introducing-distri/</id>
    <published>2019-08-17T18:36:00+02:00</published>
    <updated>2019-08-17T18:36:31+02:00</updated>
    <content type="html"><![CDATA[

<p>Over the last year or so I have worked on a research linux distribution in my
spare time. It’s not a distribution for researchers (like <a href="https://en.wikipedia.org/wiki/Scientific_Linux">Scientific
Linux</a>), but my personal
playground project to research linux distribution development, i.e. try out
fresh ideas.</p>

<p>This article focuses on the package format and its advantages, but there is
more to distri, which I will <a href="#more-to-come">cover in upcoming blog posts</a>.</p>

<h3 id="motivation">Motivation</h3>

<p>I was a Debian Developer for the 7 years from 2012 to 2019, but using the
distribution often left me frustrated, ultimately <a href="/posts/2019-03-10-debian-winding-down/">resulting in me winding down
my Debian work</a>.</p>

<p>Frequently, I was noticing a large gap between the actual speed of an operation
(e.g. doing an update) and the possible speed based on back of the envelope
calculations. I wrote more about this in my blog post <a href="/posts/2019-08-17-linux-package-managers-are-slow/">“Package managers are
slow”</a>.</p>

<p>To me, this observation means that either there is potential to optimize the
package manager itself (e.g. <code>apt</code>), or what the system does is just too
complex. While I remember seeing some low-hanging fruit¹, through my work on
distri, I wanted to explore whether all the complexity we currently have in
Linux distributions such as Debian or Fedora is inherent to the problem space.</p>

<p>I have completed enough of the experiment to conclude that the complexity is not
inherent: I can build a Linux distribution for general-enough purposes which is
much less complex than existing ones.</p>

<p>① Those were low-hanging fruit from a user perspective. I’m not saying that
  fixing them is easy in the technical sense; I know too little about <code>apt</code>’s code
  base to make such a statement.</p>

<h3 id="key-idea-packages-are-images-not-archives">Key idea: packages are images, not archives</h3>

<p>One key idea is to switch from using archives to using <strong>images</strong> for package
contents. Common package managers such as <a href="https://manpages.debian.org/dpkg.1"><code>dpkg(1)</code></a>

use <a href="https://manpages.debian.org/tar.1"><code>tar(1)</code></a>
 archives with various compression
algorithms.</p>

<p>distri uses <a href="https://en.wikipedia.org/wiki/SquashFS">SquashFS images</a>, a
comparatively simple file system image format that I happen to be familiar with
from my work on the <a href="https://gokrazy.org">gokrazy Raspberry Pi 3 Go platform</a>.</p>

<p>This idea is not novel: <a href="https://en.wikipedia.org/wiki/AppImage">AppImage</a> and
<a href="https://en.wikipedia.org/wiki/Snappy_(package_manager)">snappy</a> also use
images, but only for individual, self-contained applications. distri however
uses images for distribution packages with dependencies. In particular, there is
no duplication of shared libraries in distri.</p>

<p>A nice side effect of using read-only image files is that applications are
immutable and can hence not be broken by accidental (or malicious!)
modification.</p>

<h3 id="key-idea-separate-hierarchies">Key idea: separate hierarchies</h3>

<p>Package contents are made available under a fully-qualified path. E.g., all
files provided by package <code>zsh-amd64-5.6.2-3</code> are available under
<code>/ro/zsh-amd64-5.6.2-3</code>. The mountpoint <code>/ro</code> stands for read-only, which is
short yet descriptive.</p>

<p>Perhaps surprisingly, building software with custom <code>prefix</code> values of
e.g. <code>/ro/zsh-amd64-5.6.2-3</code> is widely supported, thanks to:</p>

<ol>
<li><p>Linux distributions, which build software with <code>prefix</code> set to <code>/usr</code>,
whereas FreeBSD (and the autotools default), which build with <code>prefix</code> set to
<code>/usr/local</code>.</p></li>

<li><p>Enthusiast users in corporate or research environments, who install software
into their home directories.</p></li>
</ol>

<p>Because using a custom <code>prefix</code> is a common scenario, upstream awareness for
<code>prefix</code>-correctness is generally high, and the rarely required patch will be
quickly accepted.</p>

<h3 id="key-idea-exchange-directories">Key idea: exchange directories</h3>

<p>Software packages often exchange data by placing or locating files in well-known
directories. Here are just a few examples:</p>

<ul>
<li><a href="https://manpages.debian.org/gcc.1"><code>gcc(1)</code></a>
 locates the <a href="https://manpages.debian.org/libusb.3"><code>libusb(3)</code></a>
 headers via <code>/usr/include</code></li>
<li><a href="https://manpages.debian.org/man.1"><code>man(1)</code></a>
 locates the <a href="https://manpages.debian.org/nginx.1"><code>nginx(1)</code></a>
 manpage via <code>/usr/share/man</code>.</li>
<li><a href="https://manpages.debian.org/zsh.1"><code>zsh(1)</code></a>
 locates executable programs via <code>PATH</code> components such as <code>/bin</code></li>
</ul>

<p>In distri, these locations are called <strong>exchange directories</strong> and are provided
via FUSE in <code>/ro</code>.</p>

<p>Exchange directories come in two different flavors:</p>

<ol>
<li><p>global. The exchange directory, e.g. <code>/ro/share</code>, provides the union of the
<code>share</code> sub directory of all packages in the package store.
<br />
Global exchange directories are largely used for compatibility, <a href="#fhs-compat">see
below</a>.</p></li>

<li><p>per-package. Useful for tight coupling: e.g. <a href="https://manpages.debian.org/irssi.1"><code>irssi(1)</code></a>
 does not provide any ABI guarantees, so plugins such as <code>irssi-robustirc</code>
can declare that they want
e.g. <code>/ro/irssi-amd64-1.1.1-1/out/lib/irssi/modules</code> to be a per-package
exchange directory and contain files from their <code>lib/irssi/modules</code>.</p></li>
</ol>

<aside class="admonition note">
  <div class="note-icon">
    <svg id="exclamation-icon" width="100%" height="100%" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;">
    <path d="M0,0L24,0L24,24L0,24L0,0Z" style="fill:none;"/>
    <g transform="matrix(1.2,0,0,1.2,-2.4,-2.4)">
        <path d="M12,2C6.48,2 2,6.48 2,12C2,17.52 6.48,22 12,22C17.52,22 22,17.52 22,12C22,6.48 17.52,2 12,2ZM13,17L11,17L11,15L13,15L13,17ZM13,13L11,13L11,7L13,7L13,13Z" style="fill-rule:nonzero;"/>
    </g>
</svg>

  </div>
  <div class="admonition-content">
    <strong>Note</strong>:
Only a few exchange directories are also available in the package build
environment (as opposed to run-time).
</div>
</aside>


<h4 id="search-paths-sometimes-need-to-be-fixed">Search paths sometimes need to be fixed</h4>

<p>Programs which use exchange directories sometimes use search paths to access
multiple exchange directories. In fact, the examples above were taken from <a href="https://manpages.debian.org/gcc.1"><code>gcc(1)</code></a>
’s <code>INCLUDEPATH</code>, <a href="https://manpages.debian.org/man.1"><code>man(1)</code></a>
’s <code>MANPATH</code> and <a href="https://manpages.debian.org/zsh.1"><code>zsh(1)</code></a>
’s <code>PATH</code>. These are
prominent ones, but more examples are easy to find: <a href="https://manpages.debian.org/zsh.1"><code>zsh(1)</code></a>
 loads completion functions from its <code>FPATH</code>.</p>

<p>Some search path values are derived from <code>--datadir=/ro/share</code> and require no
further attention, but others might derive from
e.g. <code>--prefix=/ro/zsh-amd64-5.6.2-3/out</code> and need to be pointed to an exchange
directory via a specific command line flag.</p>

<aside class="admonition note">
  <div class="note-icon">
    <svg id="exclamation-icon" width="100%" height="100%" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;">
    <path d="M0,0L24,0L24,24L0,24L0,0Z" style="fill:none;"/>
    <g transform="matrix(1.2,0,0,1.2,-2.4,-2.4)">
        <path d="M12,2C6.48,2 2,6.48 2,12C2,17.52 6.48,22 12,22C17.52,22 22,17.52 22,12C22,6.48 17.52,2 12,2ZM13,17L11,17L11,15L13,15L13,17ZM13,13L11,13L11,7L13,7L13,13Z" style="fill-rule:nonzero;"/>
    </g>
</svg>

  </div>
  <div class="admonition-content">
    <strong>Note</strong>:

To create the illusion of a writable search path at package build-time,
<code>$DESTDIR/ro/share</code> and <code>$DESTDIR/ro/lib</code> are diverted to
<code>$DESTDIR/$PREFIX/share</code> and <code>$DESTDIR/$PREFIX/lib</code>,
respectively.

</div>
</aside>


<h4 id="fhs-compat">FHS compatibility</h4>

<p>Global exchange directories are used to make distri provide enough of the
<a href="https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard">Filesystem Hierarchy Standard
(FHS)</a> that
third-party software largely just works. This includes a C development
environment.</p>

<p>I successfully ran a few programs from their binary packages such as Google
Chrome, Spotify, or Microsoft’s Visual Studio Code.</p>

<h3 id="fast-package-manager">Fast package manager</h3>

<p>I previously wrote about how <a href="/posts/2019-08-17-linux-package-managers-are-slow/">Linux distribution package managers are too slow</a>.</p>

<p>distri’s package manager is extremely fast. Its main bottleneck is typically the network link, even at high speed links (I tested with a 100 Gbps link).</p>

<p>Its speed comes largely from an architecture which allows the package manager to
do less work. Specifically:</p>

<ol>
<li><p>Package images can be added atomically to the package store, so we can safely
skip <a href="https://manpages.debian.org/fsync.2"><code>fsync(2)</code></a>
. Corruption will be cleaned up
automatically, and durability is not important: if an interactive
installation is interrupted, the user can just repeat it, as it will be fresh
on their mind.</p></li>

<li><p>Because all packages are co-installable thanks to separate hierarchies, there
are no conflicts at the package store level, and no dependency resolution (an
optimization problem requiring <a href="https://research.swtch.com/version-sat">SAT
solving</a>) is required at all.
<br />
In exchange directories, we resolve conflicts by selecting the package with the
highest monotonically increasing distri revision number.</p></li>

<li><p>distri proves that we can build a useful Linux distribution <a href="/posts/2019-07-20-hooks-and-triggers/">entirely without
hooks and triggers</a>. Not having to
serialize hook execution allows us to download packages into the package
store with maximum concurrency.</p></li>

<li><p>Because we are using images instead of archives, we do not need to unpack
anything. This means installing a package is really just writing its package
image and metadata to the package store. Sequential writes are typically the
fastest kind of storage usage pattern.</p></li>
</ol>

<p>Fast installation also make other use-cases more bearable, such as creating disk
images, be it for testing them in <a href="https://manpages.debian.org/qemu.1"><code>qemu(1)</code></a>
, booting
them on real hardware from a USB drive, or for cloud providers such as Google
Cloud.</p>

<aside class="admonition note">
  <div class="note-icon">
    <svg id="exclamation-icon" width="100%" height="100%" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;">
    <path d="M0,0L24,0L24,24L0,24L0,0Z" style="fill:none;"/>
    <g transform="matrix(1.2,0,0,1.2,-2.4,-2.4)">
        <path d="M12,2C6.48,2 2,6.48 2,12C2,17.52 6.48,22 12,22C17.52,22 22,17.52 22,12C22,6.48 17.52,2 12,2ZM13,17L11,17L11,15L13,15L13,17ZM13,13L11,13L11,7L13,7L13,13Z" style="fill-rule:nonzero;"/>
    </g>
</svg>

  </div>
  <div class="admonition-content">
    <strong>Note</strong>:
To saturate links above 1 Gbps, transfer packages without compression.
</div>
</aside>


<h3 id="fast-package-builder">Fast package builder</h3>

<p>Contrary to how distribution package builders are usually implemented, the
distri package builder does not actually install any packages into the build
environment.</p>

<p>Instead, distri makes available a filtered view of the package store (only
declared dependencies are available) at <code>/ro</code> in the build environment.</p>

<p>This means that even for large dependency trees, setting up a build environment
happens in a fraction of a second! Such a low latency really makes a difference
in how comfortable it is to iterate on distribution packages.</p>

<h3 id="package-stores">Package stores</h3>

<p>In distri, package images are installed from a remote <strong>package store</strong> into the
local system package store <code>/roimg</code>, which backs the <code>/ro</code> mount.</p>

<p>A package store is implemented as a directory of package images and their
associated metadata files.</p>

<p>You can easily make available a package store by using <code>distri export</code>.</p>

<p>To provide a mirror for your local network, you can periodically <code>distri update</code>
from the package store you want to mirror, and then <code>distri export</code> your local
copy. Special tooling (e.g. <code>debmirror</code> in Debian) is not required because
<code>distri install</code> is atomic (and <code>update</code> uses <code>install</code>).</p>

<p>Producing derivatives is easy: just add your own packages to a copy of the
package store.</p>

<p>The package store is intentionally kept simple to manage and distribute. Its
files could be exchanged via peer-to-peer file systems, or synchronized from an
offline medium.</p>

<h3 id="distri-s-first-release">distri’s first release</h3>

<p>distri works well enough to demonstrate the ideas explained above. I have
branched this state into <a href="https://github.com/distr1/distri/tree/jackherer">branch
<code>jackherer</code></a>, distri’s first
release code name. This way, I can keep experimenting in the distri repository
without breaking your installation.</p>

<p>From the branch contents, our autobuilder creates:</p>

<ol>
<li><p><a href="https://repo.distr1.org/distri/jackherer/img/">disk images</a>, which…</p>

<ul>
<li>can be <a href="https://github.com/distr1/distri#run-distri-on-real-hardware">tested on real hardware</a></li>
<li>can be <a href="https://github.com/distr1/distri#run-distri-in-qemu">tested in qemu</a></li>
<li>can be <a href="https://github.com/distr1/distri#run-distri-in-virtualbox">tested in virtualbox</a></li>
<li>can be <a href="https://github.com/distr1/distri#run-distri-in-docker">tested in docker</a></li>
<li>can be <a href="https://github.com/distr1/distri#run-distri-on-google-cloud">tested on Google Cloud</a></li>
</ul></li>

<li><p>a <a href="https://repo.distr1.org/distri/jackherer/pkg/">package repository</a>. Installations can pick up new packages with
<code>distri update</code>.</p></li>

<li><p><a href="https://repo.distr1.org/distri/jackherer/docs/">documentation for the release</a>.</p>

<ul>
<li>Definitely check out the <a href="https://github.com/distr1/distri#cool-things-to-try">“Cool things to
try”</a> README section.</li>
</ul></li>
</ol>

<p>The project website can be found at <a href="https://distr1.org">https://distr1.org</a>. The website is just the
README for now, but we can improve that later.</p>

<p>The repository can be found at <a href="https://github.com/distr1/distri">https://github.com/distr1/distri</a></p>

<h3 id="project-outlook">Project outlook</h3>

<p>Right now, distri is mainly a vehicle for my spare-time Linux distribution
research. <strong>I don’t recommend anyone use distri for anything but research,</strong> and
there are no medium-term plans of that changing. At the very least, please
contact me before basing anything serious on distri so that we can talk about
limitations and expectations.</p>

<p>I expect the distri project to live for as long as I have blog posts to publish,
and we’ll see what happens afterwards. Note that this is a hobby for me: I will
continue to explore, at my own pace, parts that I find interesting.</p>

<p>My hope is that established distributions might get a useful idea or two from
distri.</p>

<h3 id="more-to-come">There’s more to come: subscribe to the distri feed</h3>

<p>I don’t want to make this post too long, but there is much more!</p>

<p>Please subscribe to the following URL in your feed reader to get all posts about
distri:</p>

<p><a href="https://michael.stapelberg.ch/posts/tags/distri/feed.xml">https://michael.stapelberg.ch/posts/tags/distri/feed.xml</a></p>

<p>Next in my queue are articles about hermetic packages and good package
maintainer experience (including declarative packaging).</p>

<h3 id="feedback-or-questions">Feedback or questions?</h3>

<p>I’d love to discuss these ideas in case you’re interested!</p>

<p>Please send feedback to the <a href="https://www.freelists.org/list/distri">distri mailing
list</a> so that everyone can participate!</p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Linux package managers are slow]]></title>
    <link href="https://michael.stapelberg.ch/posts/2019-08-17-linux-package-managers-are-slow/"/>
    <id>https://michael.stapelberg.ch/posts/2019-08-17-linux-package-managers-are-slow/</id>
    <published>2019-08-17T18:27:00+02:00</published>
    <updated>2019-08-17T18:36:31+02:00</updated>
    <content type="html"><![CDATA[

<p>I measured how long the most popular Linux distribution’s package manager take
to install small and large packages (the
<a href="https://manpages.debian.org/ack.1p"><code>ack(1p)</code></a> source code search Perl script
and <a href="https://en.wikipedia.org/wiki/QEMU">qemu</a>, respectively).</p>

<p>Where required, my measurements include metadata updates such as transferring an
up-to-date package list. For me, requiring a metadata update is the more common
case, particularly on live systems or within Docker containers.</p>

<p>All measurements were taken on an <code>Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz</code>
running Docker 1.13.1 on Linux 4.19, backed by a Samsung 970 Pro NVMe
drive boasting many hundreds of MB/s write performance.</p>

<p>See <a href="#appendix-b">Appendix B</a> for details on the measurement method and command
outputs.</p>

<h3 id="measurements">Measurements</h3>

<p>Keep in mind that these are one-time measurements. They should be indicative of
actual performance, but your experience may vary.</p>

<h4 id="ack-small-perl-program">ack (small Perl program)</h4>

<table>
<thead>
<tr>
<th>distribution</th>
<th>package manager</th>
<th>data</th>
<th>wall-clock time</th>
<th>rate</th>
</tr>
</thead>

<tbody>
<tr>
<td>Fedora</td>
<td>dnf</td>
<td>107 MB</td>
<td>29s</td>
<td>3.7 MB/s</td>
</tr>

<tr>
<td>NixOS</td>
<td>Nix</td>
<td>15 MB</td>
<td>14s</td>
<td>1.1 MB/s</td>
</tr>

<tr>
<td>Debian</td>
<td>apt</td>
<td>15 MB</td>
<td>4s</td>
<td>3.7 MB/s</td>
</tr>

<tr>
<td>Arch Linux</td>
<td>pacman</td>
<td>6.5 MB</td>
<td>3s</td>
<td>2.1 MB/s</td>
</tr>

<tr>
<td>Alpine</td>
<td>apk</td>
<td>10 MB</td>
<td>1s</td>
<td>10.0 MB/s</td>
</tr>
</tbody>
</table>

<h4 id="qemu-large-c-program">qemu (large C program)</h4>

<table>
<thead>
<tr>
<th>distribution</th>
<th>package manager</th>
<th>data</th>
<th>wall-clock time</th>
<th>rate</th>
</tr>
</thead>

<tbody>
<tr>
<td>Fedora</td>
<td>dnf</td>
<td>266 MB</td>
<td>1m8s</td>
<td>3.9 MB/s</td>
</tr>

<tr>
<td>Arch Linux</td>
<td>pacman</td>
<td>124 MB</td>
<td>1m2s</td>
<td>2.0 MB/s</td>
</tr>

<tr>
<td>Debian</td>
<td>apt</td>
<td>159 MB</td>
<td>51s</td>
<td>3.1 MB/s</td>
</tr>

<tr>
<td>NixOS</td>
<td>Nix</td>
<td>262 MB</td>
<td>38s</td>
<td>6.8 MB/s</td>
</tr>

<tr>
<td>Alpine</td>
<td>apk</td>
<td>26 MB</td>
<td>2.4s</td>
<td>10.8 MB/s</td>
</tr>
</tbody>
</table>

<p><br>
The difference between the slowest and fastest package managers is 30x!</p>

<p>How can Alpine’s apk and Arch Linux’s pacman be an order of magnitude faster
than the rest? They are doing a lot less than the others, and more efficiently,
too.</p>

<h4 id="pain-point-too-much-metadata">Pain point: too much metadata</h4>

<p>For example, Fedora transfers a lot more data than others because its main
package list is 60 MB (compressed!) alone. Compare that with Alpine’s 734 KB
<code>APKINDEX.tar.gz</code>.</p>

<p>Of course the extra metadata which Fedora provides helps some use case,
otherwise they hopefully would have removed it altogether. The amount of
metadata seems excessive for the use case of installing a single package, which
I consider the main use-case of an interactive package manager.</p>

<p>I expect any modern Linux distribution to <strong>only transfer absolutely required
data</strong> to complete my task.</p>

<h4 id="pain-point-no-concurrency">Pain point: no concurrency</h4>

<p>Because they need to sequence executing arbitrary package maintainer-provided
code (hooks and triggers), all tested package managers need to install packages
sequentially (one after the other) instead of concurrently (all at the same
time).</p>

<p>In my blog post <a href="/posts/2019-07-20-hooks-and-triggers/">“Can we do without hooks and
triggers?”</a>, I outline that hooks and
triggers are not strictly necessary to build a working Linux distribution.</p>

<h3 id="thought-experiment-further-speed-ups">Thought experiment: further speed-ups</h3>

<p>Strictly speaking, the only required feature of a package manager is to make
available the package contents so that the package can be used: a program can be
started, a kernel module can be loaded, etc.</p>

<p>By only implementing what’s needed for this feature, and nothing more, a package
manager could likely beat <code>apk</code>’s performance. It could, for example:</p>

<ul>
<li>skip archive extraction by mounting file system images (like AppImage or snappy)</li>
<li>use compression which is light on CPU, as networks are fast (like <code>apk</code>)</li>
<li>skip fsync when it is safe to do so, i.e.:

<ul>
<li>package installations don’t modify system state</li>
<li>atomic package installation (e.g. an append-only package store)</li>
<li>automatically clean up the package store after crashes</li>
</ul></li>
</ul>

<h3 id="current-landscape">Current landscape</h3>

<p>Here’s a table outlining how the various package managers listed on Wikipedia’s
<a href="https://en.wikipedia.org/wiki/List_of_software_package_management_systems#Linux">list of software package management
systems</a>
fare:</p>

<table>
<thead>
<tr>
<th>name</th>
<th>scope</th>
<th>package file format</th>
<th>hooks/triggers</th>
</tr>
</thead>

<tbody>
<tr>
<td>AppImage</td>
<td>apps</td>
<td>image: ISO9660, SquashFS</td>
<td>no</td>
</tr>

<tr>
<td><a href="https://snapcraft.io/">snappy</a></td>
<td>apps</td>
<td>image: SquashFS</td>
<td>yes: <a href="https://docs.snapcraft.io/build-snaps/hooks">hooks</a></td>
</tr>

<tr>
<td>FlatPak</td>
<td>apps</td>
<td>archive: <a href="https://ostree.readthedocs.io/en/latest/">OSTree</a></td>
<td>no</td>
</tr>

<tr>
<td>0install</td>
<td>apps</td>
<td>archive: tar.bz2</td>
<td>no</td>
</tr>

<tr>
<td>nix, guix</td>
<td>distro</td>
<td>archive: nar.{bz2,xz}</td>
<td><a href="https://github.com/NixOS/nixos/blob/master/modules/system/activation/activation-script.nix">activation script</a></td>
</tr>

<tr>
<td>dpkg</td>
<td>distro</td>
<td>archive: tar.{gz,xz,bz2} in ar(1)</td>
<td>yes</td>
</tr>

<tr>
<td>rpm</td>
<td>distro</td>
<td>archive: cpio.{bz2,lz,xz}</td>
<td><a href="https://fedoraproject.org/wiki/Packaging:Scriptlets">scriptlets</a></td>
</tr>

<tr>
<td>pacman</td>
<td>distro</td>
<td>archive: tar.xz</td>
<td><a href="https://wiki.archlinux.org/index.php/PKGBUILD#install">install</a></td>
</tr>

<tr>
<td>slackware</td>
<td>distro</td>
<td>archive: tar.{gz,xz}</td>
<td>yes: doinst.sh</td>
</tr>

<tr>
<td>apk</td>
<td>distro</td>
<td>archive: tar.gz</td>
<td>yes: .post-install</td>
</tr>

<tr>
<td>Entropy</td>
<td>distro</td>
<td>archive: tar.bz2</td>
<td>yes</td>
</tr>

<tr>
<td>ipkg, opkg</td>
<td>distro</td>
<td>archive: tar{,.gz}</td>
<td>yes</td>
</tr>
</tbody>
</table>

<h3 id="conclusion">Conclusion</h3>

<p>As per the <a href="#current-landscape">current landscape</a>, there is no
distribution-scoped package manager which uses images and leaves out hooks and
triggers, not even in smaller Linux distributions.</p>

<p>I think that space is really interesting, as it uses a minimal design to achieve
significant real-world speed-ups.</p>

<p>I have explored this idea in much more detail, and am happy to talk more about
it in my post “Introducing the distri research linux distribution&quot;.</p>

<h3 id="appendix-a-related-work">Appendix A: related work</h3>

<p>There are a couple of recent developments going into the same direction:</p>

<ul>
<li><a href="http://0pointer.net/blog/revisiting-how-we-put-together-linux-systems.html">“Revisiting How We Put Together Linux Systems”</a> describes mounting app bundles</li>
<li><a href="https://android.googlesource.com/platform/system/apex/+/refs/heads/master/docs/README.md">Android Q uses ext4 loopback images</a></li>
<li>The Haiku Operating System’s package manager <a href="https://en.wikipedia.org/wiki/Haiku_Depot">Haiku
Depot</a> uses images</li>
</ul>

<h3 id="appendix-b">Appendix B: measurement details</h3>

<h4 id="ack">ack</h4>

<p>You can expand each of these:</p>

<p><details>
<summary>
Fedora’s dnf takes almost 30 seconds to fetch and unpack 107 MB.
</summary></p>

<pre><code>% docker run -t -i fedora /bin/bash
[root@722e6df10258 /]# time dnf install -y ack
Fedora Modular 30 - x86_64            4.4 MB/s | 2.7 MB     00:00
Fedora Modular 30 - x86_64 - Updates  3.7 MB/s | 2.4 MB     00:00
Fedora 30 - x86_64 - Updates           17 MB/s |  19 MB     00:01
Fedora 30 - x86_64                     31 MB/s |  70 MB     00:02
[…]
Install  44 Packages

Total download size: 13 M
Installed size: 42 M
[…]
real	0m29.498s
user	0m22.954s
sys	0m1.085s
</code></pre>

<p></details></p>

<p><details>
<summary>
NixOS’s Nix takes 14s to fetch and unpack 15 MB.
</summary></p>

<pre><code>% docker run -t -i nixos/nix
39e9186422ba:/# time sh -c 'nix-channel --update &amp;&amp; nix-env -i perl5.28.2-ack-2.28'
unpacking channels...
created 2 symlinks in user environment
installing 'perl5.28.2-ack-2.28'
these paths will be fetched (14.91 MiB download, 80.83 MiB unpacked):
  /nix/store/57iv2vch31v8plcjrk97lcw1zbwb2n9r-perl-5.28.2
  /nix/store/89gi8cbp8l5sf0m8pgynp2mh1c6pk1gk-attr-2.4.48
  /nix/store/gkrpl3k6s43fkg71n0269yq3p1f0al88-perl5.28.2-ack-2.28-man
  /nix/store/iykxb0bmfjmi7s53kfg6pjbfpd8jmza6-glibc-2.27
  /nix/store/k8lhqzpaaymshchz8ky3z4653h4kln9d-coreutils-8.31
  /nix/store/svgkibi7105pm151prywndsgvmc4qvzs-acl-2.2.53
  /nix/store/x4knf14z1p0ci72gl314i7vza93iy7yc-perl5.28.2-File-Next-1.16
  /nix/store/zfj7ria2kwqzqj9dh91kj9kwsynxdfk0-perl5.28.2-ack-2.28
copying path '/nix/store/gkrpl3k6s43fkg71n0269yq3p1f0al88-perl5.28.2-ack-2.28-man' from 'https://cache.nixos.org'...
copying path '/nix/store/iykxb0bmfjmi7s53kfg6pjbfpd8jmza6-glibc-2.27' from 'https://cache.nixos.org'...
copying path '/nix/store/x4knf14z1p0ci72gl314i7vza93iy7yc-perl5.28.2-File-Next-1.16' from 'https://cache.nixos.org'...
copying path '/nix/store/89gi8cbp8l5sf0m8pgynp2mh1c6pk1gk-attr-2.4.48' from 'https://cache.nixos.org'...
copying path '/nix/store/svgkibi7105pm151prywndsgvmc4qvzs-acl-2.2.53' from 'https://cache.nixos.org'...
copying path '/nix/store/k8lhqzpaaymshchz8ky3z4653h4kln9d-coreutils-8.31' from 'https://cache.nixos.org'...
copying path '/nix/store/57iv2vch31v8plcjrk97lcw1zbwb2n9r-perl-5.28.2' from 'https://cache.nixos.org'...
copying path '/nix/store/zfj7ria2kwqzqj9dh91kj9kwsynxdfk0-perl5.28.2-ack-2.28' from 'https://cache.nixos.org'...
building '/nix/store/q3243sjg91x1m8ipl0sj5gjzpnbgxrqw-user-environment.drv'...
created 56 symlinks in user environment
real	0m 14.02s
user	0m 8.83s
sys	0m 2.69s
</code></pre>

<p></details></p>

<p><details>
<summary>
Debian’s apt takes almost 10 seconds to fetch and unpack 16 MB.
</summary></p>

<pre><code>% docker run -t -i debian:sid
root@b7cc25a927ab:/# time (apt update &amp;&amp; apt install -y ack-grep)
Get:1 http://cdn-fastly.deb.debian.org/debian sid InRelease [233 kB]
Get:2 http://cdn-fastly.deb.debian.org/debian sid/main amd64 Packages [8270 kB]
Fetched 8502 kB in 2s (4764 kB/s)
[…]
The following NEW packages will be installed:
  ack ack-grep libfile-next-perl libgdbm-compat4 libgdbm5 libperl5.26 netbase perl perl-modules-5.26
The following packages will be upgraded:
  perl-base
1 upgraded, 9 newly installed, 0 to remove and 60 not upgraded.
Need to get 8238 kB of archives.
After this operation, 42.3 MB of additional disk space will be used.
[…]
real	0m9.096s
user	0m2.616s
sys	0m0.441s
</code></pre>

<p></details></p>

<p><details>
<summary>
Arch Linux’s pacman takes a little over 3s to fetch and unpack 6.5 MB.
</summary></p>

<pre><code>% docker run -t -i archlinux/base
[root@9604e4ae2367 /]# time (pacman -Sy &amp;&amp; pacman -S --noconfirm ack)
:: Synchronizing package databases...
 core            132.2 KiB  1033K/s 00:00
 extra          1629.6 KiB  2.95M/s 00:01
 community         4.9 MiB  5.75M/s 00:01
[…]
Total Download Size:   0.07 MiB
Total Installed Size:  0.19 MiB
[…]
real	0m3.354s
user	0m0.224s
sys	0m0.049s
</code></pre>

<p></details></p>

<p><details>
<summary>
Alpine’s apk takes only about 1 second to fetch and unpack 10 MB.
</summary></p>

<pre><code>% docker run -t -i alpine
/ # time apk add ack
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/community/x86_64/APKINDEX.tar.gz
(1/4) Installing perl-file-next (1.16-r0)
(2/4) Installing libbz2 (1.0.6-r7)
(3/4) Installing perl (5.28.2-r1)
(4/4) Installing ack (3.0.0-r0)
Executing busybox-1.30.1-r2.trigger
OK: 44 MiB in 18 packages
real	0m 0.96s
user	0m 0.25s
sys	0m 0.07s
</code></pre>

<p></details></p>

<h4 id="qemu">qemu</h4>

<p>You can expand each of these:</p>

<p><details>
<summary>
Fedora’s dnf takes over a minute to fetch and unpack 266 MB.
</summary></p>

<pre><code>% docker run -t -i fedora /bin/bash
[root@722e6df10258 /]# time dnf install -y qemu
Fedora Modular 30 - x86_64            3.1 MB/s | 2.7 MB     00:00
Fedora Modular 30 - x86_64 - Updates  2.7 MB/s | 2.4 MB     00:00
Fedora 30 - x86_64 - Updates           20 MB/s |  19 MB     00:00
Fedora 30 - x86_64                     31 MB/s |  70 MB     00:02
[…]
Install  262 Packages
Upgrade    4 Packages

Total download size: 172 M
[…]
real	1m7.877s
user	0m44.237s
sys	0m3.258s
</code></pre>

<p></details></p>

<p><details>
<summary>
NixOS’s Nix takes 38s to fetch and unpack 262 MB.
</summary></p>

<pre><code>% docker run -t -i nixos/nix
39e9186422ba:/# time sh -c 'nix-channel --update &amp;&amp; nix-env -i qemu-4.0.0'
unpacking channels...
created 2 symlinks in user environment
installing 'qemu-4.0.0'
these paths will be fetched (262.18 MiB download, 1364.54 MiB unpacked):
[…]
real	0m 38.49s
user	0m 26.52s
sys	0m 4.43s
</code></pre>

<p></details></p>

<p><details>
<summary>
Debian’s apt takes 51 seconds to fetch and unpack 159 MB.
</summary></p>

<pre><code>% docker run -t -i debian:sid
root@b7cc25a927ab:/# time (apt update &amp;&amp; apt install -y qemu-system-x86)
Get:1 http://cdn-fastly.deb.debian.org/debian sid InRelease [149 kB]
Get:2 http://cdn-fastly.deb.debian.org/debian sid/main amd64 Packages [8426 kB]
Fetched 8574 kB in 1s (6716 kB/s)
[…]
Fetched 151 MB in 2s (64.6 MB/s)
[…]
real	0m51.583s
user	0m15.671s
sys	0m3.732s
</code></pre>

<p></details></p>

<p><details>
<summary>
Arch Linux’s pacman takes 1m2s to fetch and unpack 124 MB.
</summary></p>

<pre><code>% docker run -t -i archlinux/base
[root@9604e4ae2367 /]# time (pacman -Sy &amp;&amp; pacman -S --noconfirm qemu)
:: Synchronizing package databases...
 core       132.2 KiB   751K/s 00:00
 extra     1629.6 KiB  3.04M/s 00:01
 community    4.9 MiB  6.16M/s 00:01
[…]
Total Download Size:   123.20 MiB
Total Installed Size:  587.84 MiB
[…]
real	1m2.475s
user	0m9.272s
sys	0m2.458s
</code></pre>

<p></details></p>

<p><details>
<summary>
Alpine’s apk takes only about 2.4 seconds to fetch and unpack 26 MB.
</summary></p>

<pre><code>% docker run -t -i alpine
/ # time apk add qemu-system-x86_64
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.10/community/x86_64/APKINDEX.tar.gz
[…]
OK: 78 MiB in 95 packages
real	0m 2.43s
user	0m 0.46s
sys	0m 0.09s
</code></pre>

<p></details></p>
]]></content>
  </entry>
  <entry>
    <title type="html"><![CDATA[Linux distributions: Can we do without hooks and triggers?]]></title>
    <link href="https://michael.stapelberg.ch/posts/2019-07-20-hooks-and-triggers/"/>
    <id>https://michael.stapelberg.ch/posts/2019-07-20-hooks-and-triggers/</id>
    <published>2019-07-20T00:00:00+00:00</published>
    <updated>2019-08-17T18:47:29+02:00</updated>
    <content type="html"><![CDATA[

<p>Hooks are an extension feature provided by all package managers that are used in
larger Linux distributions. For example, Debian uses apt, which has various
<a href="https://www.debian.org/doc/debian-policy/ap-flowcharts.html">maintainer
scripts</a>. Fedora
uses rpm, which has
<a href="https://fedoraproject.org/wiki/Packaging:Scriptlets">scriptlets</a>. Different
package managers use different names for the concept, but all of them offer
package maintainers the ability to run arbitrary code during package
installation and upgrades. Example hook use cases include adding daemon user
accounts to your system (e.g. <code>postgres</code>), or generating/updating cache files.</p>

<p>Triggers are a kind of hook which run when <em>other</em> packages are installed. For
example, on Debian, the <a href="https://manpages.debian.org/man.1"><code>man(1)</code></a> package
comes with a trigger which regenerates the search database index whenever any
package installs a manpage. When, for example, the
<a href="https://manpages.debian.org/nginx.8"><code>nginx(8)</code></a> package is installed, a
trigger provided by the <a href="https://manpages.debian.org/man.1"><code>man(1)</code></a> package
runs.</p>

<p>Over the past few decades, Open Source software has become more and more
uniform: instead of each piece of software defining its own rules, a small
number of build systems are now widely adopted.</p>

<p>Hence, I think it makes sense to revisit whether offering extension via hooks
and triggers is a net win or net loss.</p>

<h3 id="hooks-preclude-concurrent-package-installation">Hooks preclude concurrent package installation</h3>

<p>Package managers commonly can make very little assumptions about what hooks do,
what preconditions they require, and which conflicts might be caused by running
multiple package’s hooks concurrently.</p>

<p>Hence, package managers cannot concurrently install packages. At least the
hook/trigger part of the installation needs to happen in sequence.</p>

<p>While it seems technically feasible to retrofit package manager hooks with
concurrency primitives such as locks for mutual exclusion between different hook
processes, the required overhaul of all hooks¹ seems like such a daunting task
that it might be better to just get rid of the hooks instead. Only deleting code
frees you from the burden of maintenance, automated testing and debugging.</p>

<p>① In Debian, there are 8620 non-generated maintainer scripts, as reported by
   <code>find shard*/src/*/debian -regex &quot;.*\(pre\|post\)\(inst\|rm\)$&quot;</code> on a Debian
   Code Search instance.</p>

<h3 id="triggers-slow-down-installing-updating-other-packages">Triggers slow down installing/updating other packages</h3>

<p>Personally, I never use the
<a href="https://manpages.debian.org/apropos.1"><code>apropos(1)</code></a> command, so I don’t
appreciate the <a href="https://manpages.debian.org/man.1"><code>man(1)</code></a> package’s trigger
which updates the database used by
<a href="https://manpages.debian.org/apropos.1"><code>apropos(1)</code></a>. The process takes a long
time and, because hooks and triggers must be executed serially (see previous
section), blocks my installation or update.</p>

<p>When I tell people this, they are often surprised to learn about the existance
of the <a href="https://manpages.debian.org/apropos.1"><code>apropos(1)</code></a> command. I suggest
adopting an opt-in model.</p>

<h3 id="unnecessary-work-if-programs-are-not-used-between-updates">Unnecessary work if programs are not used between updates</h3>

<p>Hooks run when packages are installed. If a package’s contents are not used
between two updates, running the hook in the first update could have been
skipped. Running the hook lazily when the package contents are used reduces
unnecessary work.</p>

<p>As a welcome side-effect, lazy hook evaluation automatically makes the hook work
in operating system images, such as live USB thumb drives or SD card images for
the Raspberry Pi. Such images must not ship the same crypto keys (e.g. OpenSSH
host keys) to all machines, but instead generate a different key on each
machine.</p>

<p>Why do users keep packages installed they don’t use? It’s extra work to remember
and clean up those packages after use. Plus, users might not realize or value
that having fewer packages installed has benefits such as faster updates.</p>

<p>I can also imagine that there are people for whom the cost of re-installing
packages incentivizes them to just keep packages installed—you never know when
you might need the program again…</p>

<h3 id="implemented-in-an-interpreted-language">Implemented in an interpreted language</h3>

<p>While working on hermetic packages (more on that in another blog post), where
the contained programs are started with modified environment variables
(e.g. <code>PATH</code>) via a wrapper bash script, I noticed that the overhead of those
wrapper bash scripts quickly becomes significant. For example, when using the
excellent <a href="https://magit.vc/">magit</a> interface for Git in Emacs, I encountered
second-long delays² when using hermetic packages compared to standard
packages. Re-implementing wrappers in a compiled language provided a significant
speed-up.</p>

<p>Similarly, getting rid of an extension point which mandates using shell scripts
allows us to build an efficient and fast implementation of a predefined set of
primitives, where you can reason about their effects and interactions.</p>

<p>② magit needs to run git a few times for displaying the full status, so small
   overhead quickly adds up.</p>

<h3 id="incentivizing-more-upstream-standardization">Incentivizing more upstream standardization</h3>

<p>Hooks are an escape hatch for distribution maintainers to express anything which
their packaging system cannot express.</p>

<p>Distributions should only rely on well-established interfaces such as autoconf’s
classic <code>./configure &amp;&amp; make &amp;&amp; make install</code> (including commonly used flags) to
build a distribution package. Integrating upstream software into a distribution
should not require custom hooks. For example, instead of requiring a hook which
updates a cache of schema files, the library used to interact with those files
should transparently (re-)generate the cache or fall back to a slower code path.</p>

<p>Distribution maintainers are hard to come by, so we should value their time. In
particular, there is a 1:n relationship of packages to distribution package
maintainers (software is typically available in multiple Linux distributions),
so it makes sense to spend the work in the 1 and have the n benefit.</p>

<h3 id="can-we-do-without-them">Can we do without them?</h3>

<p>If we want to get rid of hooks, we need another mechanism to achieve what we
currently achieve with hooks.</p>

<p>If the hook is not specific to the package, it can be moved to the package
manager. The desired system state should either be derived from the package
contents (e.g. required system users can be discovered from systemd service
files) or declaratively specified in the package build instructions—more on that
in another blog post. This turns hooks (arbitrary code) into configuration,
which allows the package manager to collapse and sequence the required state
changes. E.g., when 5 packages are installed which each need a new system user,
the package manager could update <code>/etc/passwd</code> just once.</p>

<p>If the hook is specific to the package, it should be moved into the package
contents. This typically means moving the functionality into the program start
(or the systemd service file if we are talking about a daemon). If (while?)
upstream is not convinced, you can either wrap the program or patch it. Note
that this case is relatively rare: I have worked with hundreds of packages and
the only package-specific functionality I came across was automatically
generating host keys before starting OpenSSH’s
<a href="https://manpages.debian.org/sshd.8"><code>sshd(8)</code></a>³.</p>

<p>There is one exception where moving the hook doesn’t work: packages which modify
state outside of the system, such as bootloaders or kernel images.</p>

<p>③ Even that can be moved out of a package-specific hook, <a href="https://src.fedoraproject.org/rpms/openssh/blob/30922f629cc135e3233e263d5e3eb346f9251c4e/f/sshd-keygen%40.service">as Fedora
demonstrates</a>.</p>

<h3 id="conclusion">Conclusion</h3>

<p>Global state modifications performed as part of package installation today use
hooks, an overly expressive extension mechanism.</p>

<p>Instead, all modifications should be driven by configuration. This is feasible
because there are only a few different kinds of desired state
modifications. This makes it possible for package managers to optimize package
installation.</p>
]]></content>
  </entry>
</feed>
